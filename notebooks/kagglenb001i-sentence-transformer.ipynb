{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Directory settings","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nINPUT_DIR = '../input/us-patent-phrase-to-phrase-matching/'\nOUTPUT_DIR = './'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:27.191597Z","iopub.execute_input":"2022-05-20T23:30:27.191998Z","iopub.status.idle":"2022-05-20T23:30:27.216686Z","shell.execute_reply.started":"2022-05-20T23:30:27.191897Z","shell.execute_reply":"2022-05-20T23:30:27.215956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFG","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    num_workers=4\n    path=\"../input/kagglenb001-sentence-transformer/\"\n    config_path=path+'config.pth'\n    #model=\"AI-Growth-Lab/PatentSBERTa\"\n    model = 'sentence-transformers/paraphrase-MiniLM-L6-v2'\n    batch_size=32\n    fc_dropout=0.2\n    target_size=1\n    max_len=125\n    seed=42\n    n_fold=4\n    trn_fold=[0, 1, 2, 3]","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:27.218506Z","iopub.execute_input":"2022-05-20T23:30:27.219049Z","iopub.status.idle":"2022-05-20T23:30:27.225332Z","shell.execute_reply.started":"2022-05-20T23:30:27.219009Z","shell.execute_reply":"2022-05-20T23:30:27.224512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport shutil\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nprint(f\"torch.__version__: {torch.__version__}\")\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:27.227229Z","iopub.execute_input":"2022-05-20T23:30:27.227801Z","iopub.status.idle":"2022-05-20T23:30:29.67918Z","shell.execute_reply.started":"2022-05-20T23:30:27.22776Z","shell.execute_reply":"2022-05-20T23:30:29.678327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedGroupKFold","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:29.680882Z","iopub.execute_input":"2022-05-20T23:30:29.681717Z","iopub.status.idle":"2022-05-20T23:30:29.687526Z","shell.execute_reply.started":"2022-05-20T23:30:29.68167Z","shell.execute_reply":"2022-05-20T23:30:29.686626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install -U sentence-transformers\nos.system('python -m pip install --no-index --find-links=../input/kagglenb000-pip-wheels sentence-transformers')\nfrom sentence_transformers import SentenceTransformer","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:29.688887Z","iopub.execute_input":"2022-05-20T23:30:29.689295Z","iopub.status.idle":"2022-05-20T23:30:47.303764Z","shell.execute_reply.started":"2022-05-20T23:30:29.689254Z","shell.execute_reply":"2022-05-20T23:30:47.302892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.306054Z","iopub.execute_input":"2022-05-20T23:30:47.306342Z","iopub.status.idle":"2022-05-20T23:30:47.367401Z","shell.execute_reply.started":"2022-05-20T23:30:47.306303Z","shell.execute_reply":"2022-05-20T23:30:47.366514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = sp.stats.pearsonr(y_true, y_pred)[0]\n    return score\n\n\ndef get_logger(filename=OUTPUT_DIR+'train'):\n    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=f\"{filename}.log\")\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = get_logger()\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.369365Z","iopub.execute_input":"2022-05-20T23:30:47.369913Z","iopub.status.idle":"2022-05-20T23:30:47.384931Z","shell.execute_reply.started":"2022-05-20T23:30:47.369869Z","shell.execute_reply":"2022-05-20T23:30:47.384119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# OOF","metadata":{}},{"cell_type":"code","source":"oof_df = pd.read_pickle(CFG.path+'oof_df.pkl')\nlabels = oof_df['score'].values\npreds = oof_df['pred'].values\nscore = get_score(labels, preds)\nLOGGER.info(f'CV Score: {score:<.4f}')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.386658Z","iopub.execute_input":"2022-05-20T23:30:47.386981Z","iopub.status.idle":"2022-05-20T23:30:47.505248Z","shell.execute_reply.started":"2022-05-20T23:30:47.386923Z","shell.execute_reply":"2022-05-20T23:30:47.5043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loading","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntest = pd.read_csv(INPUT_DIR+'test.csv')\nsubmission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\nprint(f\"test.shape: {test.shape}\")\nprint(f\"submission.shape: {submission.shape}\")\ndisplay(test.head())\ndisplay(submission.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.506828Z","iopub.execute_input":"2022-05-20T23:30:47.507112Z","iopub.status.idle":"2022-05-20T23:30:47.559625Z","shell.execute_reply.started":"2022-05-20T23:30:47.507073Z","shell.execute_reply":"2022-05-20T23:30:47.558816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CPC Data\n# ====================================================\ncpc_texts = torch.load(CFG.path+\"cpc_texts.pth\")\ntest['context_text'] = test['context'].map(cpc_texts)\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.564303Z","iopub.execute_input":"2022-05-20T23:30:47.564766Z","iopub.status.idle":"2022-05-20T23:30:47.593722Z","shell.execute_reply.started":"2022-05-20T23:30:47.564721Z","shell.execute_reply":"2022-05-20T23:30:47.592843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n# train['text'] = train['anchor'] + '</s>' + train['target'] + '</s>'  + train['context_text']\ntest['text'] = test['anchor'] + '</s>' + test['target'] + '</s>'  + test['context_text']\n# display(train.head())\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.595052Z","iopub.execute_input":"2022-05-20T23:30:47.595345Z","iopub.status.idle":"2022-05-20T23:30:47.636248Z","shell.execute_reply.started":"2022-05-20T23:30:47.595303Z","shell.execute_reply":"2022-05-20T23:30:47.634458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV split","metadata":{}},{"cell_type":"markdown","source":"# tokenizer","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\nCFG.tokenizer = AutoTokenizer.from_pretrained(CFG.path+'tokenizer/')","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.644632Z","iopub.execute_input":"2022-05-20T23:30:47.645163Z","iopub.status.idle":"2022-05-20T23:30:47.718188Z","shell.execute_reply.started":"2022-05-20T23:30:47.645117Z","shell.execute_reply":"2022-05-20T23:30:47.716663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Dataset\n# ====================================================\ndef prepare_input(cfg, text):\n    inputs = cfg.tokenizer(text,\n                           add_special_tokens=True,\n                           max_length=cfg.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\nclass TestDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.texts = df['text'].values\n\n    def __len__(self):\n        return len(self.texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, self.texts[item])\n        return inputs","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.720706Z","iopub.execute_input":"2022-05-20T23:30:47.721432Z","iopub.status.idle":"2022-05-20T23:30:47.736477Z","shell.execute_reply.started":"2022-05-20T23:30:47.721359Z","shell.execute_reply":"2022-05-20T23:30:47.734526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Model\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, config_path=None, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        if config_path is None:\n            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n        else:\n            self.config = torch.load(config_path)\n        if pretrained:\n            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n        else:\n            self.model = AutoModel.from_config(self.config)\n        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n        self._init_weights(self.fc)\n        self.attention = nn.Sequential(\n            nn.Linear(self.config.hidden_size, 512),\n            nn.Tanh(),\n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )\n        self._init_weights(self.attention)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        # feature = torch.mean(last_hidden_states, 1)\n        weights = self.attention(last_hidden_states)\n        feature = torch.sum(weights * last_hidden_states, dim=1)\n        return feature\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.738371Z","iopub.execute_input":"2022-05-20T23:30:47.73896Z","iopub.status.idle":"2022-05-20T23:30:47.761426Z","shell.execute_reply.started":"2022-05-20T23:30:47.738901Z","shell.execute_reply":"2022-05-20T23:30:47.760616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ~~Helper functions~~\n# inference","metadata":{}},{"cell_type":"code","source":"# # ====================================================\n# # Helper functions\n# # ====================================================\n# class AverageMeter(object):\n#     \"\"\"Computes and stores the average and current value\"\"\"\n#     def __init__(self):\n#         self.reset()\n\n#     def reset(self):\n#         self.val = 0\n#         self.avg = 0\n#         self.sum = 0\n#         self.count = 0\n\n#     def update(self, val, n=1):\n#         self.val = val\n#         self.sum += val * n\n#         self.count += n\n#         self.avg = self.sum / self.count\n\n\n# def asMinutes(s):\n#     m = math.floor(s / 60)\n#     s -= m * 60\n#     return '%dm %ds' % (m, s)\n\n\n# def timeSince(since, percent):\n#     now = time.time()\n#     s = now - since\n#     es = s / (percent)\n#     rs = es - s\n#     return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\n# def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n#     model.train()\n#     scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n#     losses = AverageMeter()\n#     start = end = time.time()\n#     global_step = 0\n#     for step, (inputs, labels) in enumerate(train_loader):\n#         for k, v in inputs.items():\n#             inputs[k] = v.to(device)\n#         labels = labels.to(device)\n#         batch_size = labels.size(0)\n#         with torch.cuda.amp.autocast(enabled=CFG.apex):\n#             y_preds = model(inputs)\n#         loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n#         if CFG.gradient_accumulation_steps > 1:\n#             loss = loss / CFG.gradient_accumulation_steps\n#         losses.update(loss.item(), batch_size)\n#         scaler.scale(loss).backward()\n#         grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n#         if (step + 1) % CFG.gradient_accumulation_steps == 0:\n#             scaler.step(optimizer)\n#             scaler.update()\n#             optimizer.zero_grad()\n#             global_step += 1\n#             if CFG.batch_scheduler:\n#                 scheduler.step()\n#         end = time.time()\n#         if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n#             print('Epoch: [{0}][{1}/{2}] '\n#                   'Elapsed {remain:s} '\n#                   'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n#                   'Grad: {grad_norm:.4f}  '\n#                   'LR: {lr:.8f}  '\n#                   .format(epoch+1, step, len(train_loader), \n#                           remain=timeSince(start, float(step+1)/len(train_loader)),\n#                           loss=losses,\n#                           grad_norm=grad_norm,\n#                           lr=scheduler.get_lr()[0]))\n#         if CFG.wandb:\n#             wandb.log({f\"[fold{fold}] loss\": losses.val,\n#                        f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n#     return losses.avg\n\n\n# def valid_fn(valid_loader, model, criterion, device):\n#     losses = AverageMeter()\n#     model.eval()\n#     preds = []\n#     start = end = time.time()\n#     for step, (inputs, labels) in enumerate(valid_loader):\n#         for k, v in inputs.items():\n#             inputs[k] = v.to(device)\n#         labels = labels.to(device)\n#         batch_size = labels.size(0)\n#         with torch.no_grad():\n#             y_preds = model(inputs)\n#         loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n#         if CFG.gradient_accumulation_steps > 1:\n#             loss = loss / CFG.gradient_accumulation_steps\n#         losses.update(loss.item(), batch_size)\n#         preds.append(y_preds.sigmoid().to('cpu').numpy())\n#         end = time.time()\n#         if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n#             print('EVAL: [{0}/{1}] '\n#                   'Elapsed {remain:s} '\n#                   'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n#                   .format(step, len(valid_loader),\n#                           loss=losses,\n#                           remain=timeSince(start, float(step+1)/len(valid_loader))))\n#     predictions = np.concatenate(preds)\n#     predictions = np.concatenate(predictions)\n#     return losses.avg, predictions\n\n\n# def inference_fn(test_loader, model, device):\n#     preds = []\n#     model.eval()\n#     model.to(device)\n#     tk0 = tqdm(test_loader, total=len(test_loader))\n#     for inputs in tk0:\n#         for k, v in inputs.items():\n#             inputs[k] = v.to(device)\n#         with torch.no_grad():\n#             y_preds = model(inputs)\n#         preds.append(y_preds.sigmoid().to('cpu').numpy())\n#     predictions = np.concatenate(preds)\n#     return predictions\n\n\n# ====================================================\n# inference\n# ====================================================\ndef inference_fn(test_loader, model, device):\n    preds = []\n    model.eval()\n    model.to(device)\n    tk0 = tqdm(test_loader, total=len(test_loader))\n    for inputs in tk0:\n        for k, v in inputs.items():\n            inputs[k] = v.to(device)\n        with torch.no_grad():\n            y_preds = model(inputs)\n        preds.append(y_preds.sigmoid().to('cpu').numpy())\n    predictions = np.concatenate(preds)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.763149Z","iopub.execute_input":"2022-05-20T23:30:47.763865Z","iopub.status.idle":"2022-05-20T23:30:47.78036Z","shell.execute_reply.started":"2022-05-20T23:30:47.763822Z","shell.execute_reply":"2022-05-20T23:30:47.779513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# if __name__ == '__main__':\n    \n#     def get_result(oof_df):\n#         labels = oof_df['score'].values\n#         preds = oof_df['pred'].values\n#         score = get_score(labels, preds)\n#         LOGGER.info(f'Score: {score:<.4f}')\n    \n#     if CFG.train:\n#         oof_df = pd.DataFrame()\n#         for fold in range(CFG.n_fold):\n#             if fold in CFG.trn_fold:\n#                 _oof_df = train_loop(train, fold)\n#                 oof_df = pd.concat([oof_df, _oof_df])\n#                 LOGGER.info(f\"========== fold: {fold} result ==========\")\n#                 get_result(_oof_df)\n#         oof_df = oof_df.reset_index(drop=True)\n#         LOGGER.info(f\"========== CV ==========\")\n#         get_result(oof_df)\n#         oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n        \n#     if CFG.wandb:\n#         wandb.finish()\n\n\n\ntest_dataset = TestDataset(CFG, test)\ntest_loader = DataLoader(test_dataset,\n                         batch_size=CFG.batch_size,\n                         shuffle=False,\n                         num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\npredictions = []\nfor fold in CFG.trn_fold:\n    model = CustomModel(CFG, config_path=CFG.config_path, pretrained=False)\n    state = torch.load(CFG.path+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n                       map_location=torch.device('cpu'))\n    model.load_state_dict(state['model'])\n    prediction = inference_fn(test_loader, model, device)\n    predictions.append(prediction)\n    del model, state, prediction; gc.collect()\n    torch.cuda.empty_cache()\npredictions = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:30:47.781864Z","iopub.execute_input":"2022-05-20T23:30:47.782584Z","iopub.status.idle":"2022-05-20T23:31:45.411969Z","shell.execute_reply.started":"2022-05-20T23:30:47.782544Z","shell.execute_reply":"2022-05-20T23:31:45.411063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"submission['score'] = predictions\ndisplay(submission.head())\nsubmission[['id', 'score']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-20T23:31:45.414007Z","iopub.execute_input":"2022-05-20T23:31:45.414462Z","iopub.status.idle":"2022-05-20T23:31:45.457622Z","shell.execute_reply.started":"2022-05-20T23:31:45.414418Z","shell.execute_reply":"2022-05-20T23:31:45.456854Z"},"trusted":true},"execution_count":null,"outputs":[]}]}