{"cells":[{"cell_type":"markdown","metadata":{"id":"e460cbb5"},"source":["# About this notebook\n","- tokenizer(anchor[SEP]target | CPC)\n","- Deberta-v3-large starter code\n","- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/pppm-pip-wheels)\n","- Inference notebook is [here](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n","\n","If this notebook is helpful, feel free to upvote :)"]},{"cell_type":"markdown","metadata":{"id":"xONchFYMvMMf"},"source":["# Directory settings"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2974,"status":"ok","timestamp":1655595902993,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"fa3b873b","outputId":"2e48e848-98c4-443d-fb44-e8a8cb663ef9"},"outputs":[{"name":"stdout","output_type":"stream","text":["3.7.13 (default, Apr 24 2022, 01:04:09) \n","[GCC 7.5.0]\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/colab_notebooks/kaggle/us-patent-phrase-to-phrase-matching/notebooks\n"]}],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","comp_name = 'us-patent-phrase-to-phrase-matching'\n","nb_name = 'nb005t-deberta-v3-large'\n","\n","import sys\n","print(sys.version)\n","if \"google.colab\" in sys.modules:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    base = f\"/content/drive/MyDrive/colab_notebooks/kaggle/{comp_name}/notebooks\"\n","    %cd {base}\n","\n","\n","import os\n","INPUT_DIR = f'../input/{comp_name}/'\n","if 'kaggle_web_client' in sys.modules:\n","    OUTPUT_DIR = './'\n","else:\n","    OUTPUT_DIR = f'../input/{nb_name}/'\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"1d0c4430"},"source":["# CFG"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1655595902994,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"48dd82bb"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    wandb=True\n","    wandbproject=comp_name\n","    wandbgroup=nb_name\n","    wandbname='exp003.002'\n","    _wandb_kernel='riow1983'\n","    apex=True\n","    print_freq=100\n","    num_workers=8\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    #### AWP\n","    adv_lr=1e-6\n","    adv_eps=1e-3\n","    #### AWPAWP\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]\n","    CFG.wandb = False"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":965},"executionInfo":{"elapsed":18896,"status":"ok","timestamp":1655595921880,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"b88c983e","outputId":"0ffa6887-a4a1-4925-cebb-1d8feb407bf5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.12.18-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 15.1 MB/s \n","\u001b[?25hCollecting GitPython\u003e=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 72.7 MB/s \n","\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting shortuuid\u003e=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Collecting sentry-sdk\u003e=1.0.0\n","  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 69.7 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Collecting docker-pycreds\u003e=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Requirement already satisfied: protobuf\u003c4.0dev,\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.1.1)\n","Collecting gitdb\u003c5,\u003e=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n","\u001b[?25hCollecting smmap\u003c6,\u003e=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=043c0a1838e0e021a714bce031d383df8f9754a0cb965141d7dd3c18e29f2925\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.18\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W\u0026B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mriow1983\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.18"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e../input/nb005t-deberta-v3-large/wandb/run-20220618_234513-kci59mo9\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching/runs/kci59mo9\" target=\"_blank\"\u003eexp003.002\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["wandb run id: kci59mo9\n"]}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    if 'google.colab' in sys.modules:\n","        !pip install wandb\n","    import wandb\n","\n","    try:\n","        if 'kaggle_web_client' in sys.modules:\n","            from kaggle_secrets import UserSecretsClient\n","            user_secrets = UserSecretsClient()\n","            secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        else:\n","            import json\n","            f = open(\"../../wandb.json\", \"r\")\n","            json_data = json.load(f)\n","            secret_value_0 = json_data[\"wandb_api\"]\n","        wandb.login(key=secret_value_0)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W\u0026B account, go to Add-ons -\u003e Secrets and provide your W\u0026B access token. Use the Label name as wandb_api. \\nGet your W\u0026B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","    \n","    run = wandb.init(\n","        dir=OUTPUT_DIR,\n","        project=CFG.wandbproject,\n","        group=CFG.wandbgroup,\n","        name=CFG.wandbname, \n","        config=class2dict(CFG),\n","        job_type=\"train\",\n","        anonymous=anony)\n","    print(f\"wandb run id: {run.id}\")"]},{"cell_type":"markdown","metadata":{"id":"f2ed8ef2"},"source":["# Library"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18356,"status":"ok","timestamp":1655595940229,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"35916341","outputId":"1c4bd9f1-b33c-4db9-b81f-dfd26b0004eb"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.11.0+cu113\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.18.0\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","\n","# # PyTorchのバージョンを1.10.1に下げる (Google Colabなのでpipでやる)\n","# os.system('pip uninstall -y torch torchvision torchaudio')\n","# os.system('pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html')\n","\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","os.system('pip uninstall -y transformers')\n","os.system('pip uninstall -y tokenizers')\n","os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels transformers')\n","os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels tokenizers')\n","# os.system('python -m pip install transformers')\n","# os.system('python -m pip install tokenizers')\n","os.system('pip install sentencepiece')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"fd586614"},"source":["# Utils"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":59,"status":"ok","timestamp":1655595940230,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"d5c0ccc6"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"cb3d8e1e"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":60,"status":"ok","timestamp":1655595940233,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"bef012d3","outputId":"fe3e376c-2247-4580-989d-203ae93facf8"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (36473, 5)\n","test.shape: (36, 4)\n","submission.shape: (36, 2)\n"]},{"data":{"text/html":["\n","  \u003cdiv id=\"df-c017d478-3cda-4888-93f0-3e0d9da02109\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c017d478-3cda-4888-93f0-3e0d9da02109')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-c017d478-3cda-4888-93f0-3e0d9da02109 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c017d478-3cda-4888-93f0-3e0d9da02109');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-50d07a18-0a84-4bb5-b874-238e40871e89\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50d07a18-0a84-4bb5-b874-238e40871e89')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-50d07a18-0a84-4bb5-b874-238e40871e89 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-50d07a18-0a84-4bb5-b874-238e40871e89');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n","2  36baf228038e314b      lower trunnion                 lower locating     B60\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-df61a7f3-b20f-4d68-b44f-4ada28ec1166\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-df61a7f3-b20f-4d68-b44f-4ada28ec1166')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-df61a7f3-b20f-4d68-b44f-4ada28ec1166 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-df61a7f3-b20f-4d68-b44f-4ada28ec1166');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id  score\n","0  4112d61851461f60      0\n","1  09e418c93a776564      0\n","2  36baf228038e314b      0\n","3  1f37ead645e7f0c8      0\n","4  71a5b6ad068d531f      0"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","# #### AUG\n","# # train = pd.read_csv(INPUT_DIR+'train.csv')\n","# train = pd.read_csv('../input/kagglenb006-back-translate-aug-data/train.csv')\n","# #### AUGAUG\n","train = pd.read_csv(INPUT_DIR+'train.csv')\n","test = pd.read_csv(INPUT_DIR+'test.csv')\n","submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n","print(f\"train.shape: {train.shape}\")\n","print(f\"test.shape: {test.shape}\")\n","print(f\"submission.shape: {submission.shape}\")\n","display(train.head())\n","display(test.head())\n","display(submission.head())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":613},"executionInfo":{"elapsed":835,"status":"ok","timestamp":1655595941033,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"UCsnldv5vMMq","outputId":"a7501744-6435-4e3f-9d0d-ebe1667a4552"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-a4d3149a-1ad2-42ca-a853-2e5ca99aed6b\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a4d3149a-1ad2-42ca-a853-2e5ca99aed6b')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-a4d3149a-1ad2-42ca-a853-2e5ca99aed6b button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a4d3149a-1ad2-42ca-a853-2e5ca99aed6b');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-2758ddf8-bb16-45b1-8ccc-56eec992d22a\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2758ddf8-bb16-45b1-8ccc-56eec992d22a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-2758ddf8-bb16-45b1-8ccc-56eec992d22a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2758ddf8-bb16-45b1-8ccc-56eec992d22a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","def get_cpc_texts():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('../input/cpc-data/CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'../input/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","cpc_texts = get_cpc_texts()\n","torch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\n","train['context_text'] = train['context'].map(cpc_texts)\n","test['context_text'] = test['context'].map(cpc_texts)\n","display(train.head())\n","display(test.head())"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1655595941042,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"PJvUJQujvMMr","outputId":"5cba6888-bb2e-4588-8c2c-2eeaa210e4eb"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-76674423-7503-41d8-92ff-e95a6133a6ee\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","      \u003cth\u003etext2\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]abatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]act of abating\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]active catalyst\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]eliminating process\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]forest region\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-76674423-7503-41d8-92ff-e95a6133a6ee')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-76674423-7503-41d8-92ff-e95a6133a6ee button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-76674423-7503-41d8-92ff-e95a6133a6ee');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text                                  text                                              text2\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]abatement of pollution  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          abatement[SEP]act of abating  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...         abatement[SEP]active catalyst  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     abatement[SEP]eliminating process  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...           abatement[SEP]forest region  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-2880fa83-2c94-4fbe-ae07-50d32c1bbf16\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","      \u003cth\u003etext2\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","      \u003ctd\u003eopc drum[SEP]inorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow[SEP]altering gas flow\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","      \u003ctd\u003elower trunnion[SEP]lower locating\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","      \u003ctd\u003ecap component[SEP]upper portion\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation[SEP]artificial neural network\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2880fa83-2c94-4fbe-ae07-50d32c1bbf16')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-2880fa83-2c94-4fbe-ae07-50d32c1bbf16 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2880fa83-2c94-4fbe-ae07-50d32c1bbf16');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text                                              text                                              text2\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS        opc drum[SEP]inorganic photoconductor drum                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...             adjust gas flow[SEP]altering gas flow  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...                 lower trunnion[SEP]lower locating  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...                   cap component[SEP]upper portion  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE  neural stimulation[SEP]artificial neural network      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n","\n","train['text'] = train['anchor'] + '[SEP]' + train['target']\n","test['text'] = test['anchor'] + '[SEP]' + test['target']\n","\n","train['text2'] = train['context_text']\n","test['text2'] = test['context_text']\n","\n","\n","display(train.head())\n","display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"zuhGVmnivMMs"},"source":["# EDA"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"elapsed":170,"status":"ok","timestamp":1655595941043,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"CdwSw4u5vMMs","outputId":"1535de0e-aa23-4a3c-f485-789bf0655549"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7fee04635e90\u003e"]},"execution_count":9,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["train['score'].hist()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":164,"status":"ok","timestamp":1655595941045,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"GJBRJnjevMMs","outputId":"a868b0a9-2c1e-4728-ef39-3566700f4c04"},"outputs":[{"data":{"text/plain":["B    8019\n","H    6195\n","G    6013\n","C    5288\n","A    4094\n","F    4054\n","E    1531\n","D    1279\n","Name: context, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"62MFTSvavMMt"},"source":["- Y is not in training data, but may be in test data?"]},{"cell_type":"markdown","metadata":{"id":"9e05b6c4"},"source":["# CV split"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2715,"status":"ok","timestamp":1655595944169,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"3ba287c4","outputId":"43277414-457c-422c-9d95-e7f04a382959"},"outputs":[{"name":"stdout","output_type":"stream","text":["660 73\n","660 73\n","659 74\n","659 74\n","660 73\n","659 74\n","660 73\n","660 73\n","660 73\n","660 73\n","0    3954\n","9    3947\n","4    3902\n","6    3647\n","1    3634\n","3    3604\n","2    3524\n","5    3517\n","8    3487\n","7    3257\n","Name: fold, dtype: int64\n"]}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","# Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","# train['fold'] = train['fold'].astype(int)\n","# display(train.groupby('fold').size())\n","\n","\n","# #### AUG\n","# aug = train[train['is_aug']==1].reset_index(drop=True)\n","# train = train[train['is_aug']==0].reset_index(drop=True)\n","# #### AUGAUG\n","\n","\n","# Credits to https://www.kaggle.com/code/hannes82/pppm-deberta-v3-large-closing-the-cv-lb-gap/notebook#CV-split\n","#credits to: https://www.kaggle.com/code/abhishek/creating-folds-properly-hopefully-p\n","\n","!pip install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train = train.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")\n","del dfx\n","\n","\n","\n","# #### AUG\n","# res = []\n","# for fold in range(CFG.n_fold):\n","#     val_ids = train.loc[train['fold']==fold, 'id'].values\n","#     to_add_aug = aug[~aug['id'].isin(val_ids)].reset_index(drop=True)\n","#     to_add_aug['fold'] = fold+10\n","#     res.append(to_add_aug)\n","\n","# to_add_aug = pd.concat(res, axis=0, ignore_index=True)\n","# train = pd.concat([train, to_add_aug], axis=0, ignore_index=True)\n","# del aug, to_add_aug, res, val_ids\n","# #### AUGAUG\n","\n","print(train.fold.value_counts())"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":34,"status":"ok","timestamp":1655595944172,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"4c3ce877"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"918a28aa"},"source":["# tokenizer"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3269,"status":"ok","timestamp":1655595947416,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"H4pgQRxAvMMv","outputId":"e9a2bc92-aba0-4e54-d3e8-0bd2dc3903ca"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"14da40cf"},"source":["# Dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131},"executionInfo":{"elapsed":7684,"status":"ok","timestamp":1655595955054,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"c00327b0","outputId":"772d7e25-17fe-4689-a4be-c73756253800"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9d7bdd5ea15243b0a272a1c8846cddbe","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/136 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bd8ec0d8060144f0abcc2faf45c24328","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"505290ab262d424f934afb4b8ba39596","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_len: 133\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","# CFG.max_len = max(max(lengths_dict['anchor'])+max(lengths_dict['target'])+3, max(lengths_dict['context_text'])+2)\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":158,"status":"ok","timestamp":1655595955060,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"9f791a19"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text, text2):\n","    inputs = cfg.tokenizer(text, text2,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.texts2 = df['text2'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item], self.texts2[item])\n","        #inputs2 = prepare_input(self.cfg, self.texts2[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        #return inputs, inputs2, label\n","        return inputs, label"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":178,"status":"ok","timestamp":1655595955090,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"a200bd5b","outputId":"c480d282-4198-4ecb-901e-c42e9b68449b"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_dataset = TrainDataset(CFG, train)\\ninputs, label = train_dataset[0]\\nprint(inputs)\\nprint(label)\\n'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","train_dataset = TrainDataset(CFG, train)\n","inputs, label = train_dataset[0]\n","print(inputs)\n","print(label)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"e04d6363"},"source":["# Model"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":176,"status":"ok","timestamp":1655595955095,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"4c5bab44"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        \n","        # outputs2 = self.model(**inputs2)\n","        # last_hidden_states2 = outputs2[0]\n","        \n","        # feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        #feature2 = torch.mean(last_hidden_states2, dim=1)\n","        #feature += feature2\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"deee9675"},"source":["# Helpler functions"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":177,"status":"ok","timestamp":1655595955097,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"c8263b0c"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","#### AWP\n","#def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler, score, awp):\n","#### AWPAWP\n","    model.train()\n","    # AWP\n","    #scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    # AWPAWP\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs2.items():\n","        #     inputs2[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","\n","        #### AWP\n","        if score \u003e 0.75:\n","            awp.attack_backward(inputs['input_ids'], labels, inputs['attention_mask'], step) \n","        #### AWPAWP\n","\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs2.items():\n","        #     inputs2[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs[1].items():\n","        #     inputs[1][k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":176,"status":"ok","timestamp":1655595955098,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"CI1gkNrPRgan"},"outputs":[],"source":["#### AWP\n","class AWP:\n","    def __init__(\n","        self,\n","        model,\n","        optimizer,\n","        adv_param=\"weight\",\n","        adv_lr=1,\n","        adv_eps=0.2,\n","        start_epoch=0,\n","        adv_step=1,\n","        scaler=None\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.start_epoch = start_epoch\n","        self.adv_step = adv_step\n","        self.backup = {}\n","        self.backup_eps = {}\n","        self.scaler = scaler\n","\n","    def attack_backward(self, x, y, attention_mask,epoch):\n","        if (self.adv_lr == 0) or (epoch \u003c self.start_epoch):\n","            return None\n","\n","        self._save() \n","        for i in range(self.adv_step):\n","            self._attack_step() \n","            with torch.cuda.amp.autocast():\n","                adv_loss, tr_logits = self.model(input_ids=x, attention_mask=attention_mask, labels=y)\n","                adv_loss = adv_loss.mean()\n","            self.optimizer.zero_grad()\n","            self.scaler.scale(adv_loss).backward()\n","            \n","        self._restore()\n","\n","    def _attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","                # param.data.clamp_(*self.backup_eps[name])\n","\n","    def _save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def _restore(self,):\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}\n","\n","#### AWPAWP"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":175,"status":"ok","timestamp":1655595955098,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"bed940e1"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    \n","    # #### AUG\n","    # train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    # train_folds_aug = train_folds[train_folds['fold']==fold+10].reset_index(drop=True)\n","    # train_folds_base = train_folds[train_folds['fold']\u003c10].reset_index(drop=True)\n","    # train_folds = pd.concat([train_folds_base, train_folds_aug], axis=0, ignore_index=True)\n","    # del train_folds_aug, train_folds_base\n","    # #### AUGAUG\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model \u0026 optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = 0.\n","    #### AWP\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    awp = AWP(model,\n","              optimizer,\n","              adv_lr=CFG.adv_lr,\n","              adv_eps=CFG.adv_eps,\n","              start_epoch=num_train_steps/CFG.epochs,\n","              scaler=scaler)\n","    score = 0.\n","    #### AWPAWP\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        #### AWP\n","        #avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler, score, awp)\n","        #### AWPAWP\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score \u003c score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6cc76b1e"},"outputs":[{"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2032] Elapsed 0m 0s (remain 31m 27s) Loss: 0.6698(0.6698) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/2032] Elapsed 0m 28s (remain 9m 4s) Loss: 0.6561(0.6317) Grad: 39104.2930  LR: 0.00001999  \n","Epoch: [1][200/2032] Elapsed 0m 56s (remain 8m 30s) Loss: 0.5318(0.6053) Grad: 42619.1445  LR: 0.00001997  \n","Epoch: [1][300/2032] Elapsed 1m 23s (remain 7m 59s) Loss: 0.5036(0.5919) Grad: 22547.9590  LR: 0.00001993  \n","Epoch: [1][400/2032] Elapsed 1m 50s (remain 7m 31s) Loss: 0.5313(0.5847) Grad: 51676.2266  LR: 0.00001988  \n","Epoch: [1][500/2032] Elapsed 2m 18s (remain 7m 2s) Loss: 0.5270(0.5789) Grad: 34631.0430  LR: 0.00001981  \n","Epoch: [1][600/2032] Elapsed 2m 46s (remain 6m 35s) Loss: 0.6375(0.5752) Grad: 12288.2930  LR: 0.00001973  \n","Epoch: [1][700/2032] Elapsed 3m 13s (remain 6m 7s) Loss: 0.5512(0.5724) Grad: 23108.1895  LR: 0.00001964  \n","Epoch: [1][800/2032] Elapsed 3m 41s (remain 5m 39s) Loss: 0.5874(0.5688) Grad: 34548.0195  LR: 0.00001952  \n","Epoch: [1][900/2032] Elapsed 4m 8s (remain 5m 11s) Loss: 0.6230(0.5673) Grad: 77002.2734  LR: 0.00001940  \n","Epoch: [1][1000/2032] Elapsed 4m 35s (remain 4m 44s) Loss: 0.5044(0.5652) Grad: 18275.3926  LR: 0.00001926  \n","Epoch: [1][1100/2032] Elapsed 5m 3s (remain 4m 16s) Loss: 0.4988(0.5625) Grad: 23114.4707  LR: 0.00001911  \n","Epoch: [1][1200/2032] Elapsed 5m 30s (remain 3m 48s) Loss: 0.5257(0.5618) Grad: 18335.1152  LR: 0.00001894  \n","Epoch: [1][1300/2032] Elapsed 5m 58s (remain 3m 21s) Loss: 0.4800(0.5606) Grad: 10747.2656  LR: 0.00001876  \n","Epoch: [1][1400/2032] Elapsed 6m 25s (remain 2m 53s) Loss: 0.5826(0.5592) Grad: 18245.8594  LR: 0.00001857  \n","Epoch: [1][1500/2032] Elapsed 6m 53s (remain 2m 26s) Loss: 0.5977(0.5577) Grad: 73629.2344  LR: 0.00001836  \n","Epoch: [1][1600/2032] Elapsed 7m 20s (remain 1m 58s) Loss: 0.5111(0.5560) Grad: 35824.8047  LR: 0.00001815  \n","Epoch: [1][1700/2032] Elapsed 7m 48s (remain 1m 31s) Loss: 0.5522(0.5554) Grad: 25735.0859  LR: 0.00001792  \n","Epoch: [1][1800/2032] Elapsed 8m 16s (remain 1m 3s) Loss: 0.5044(0.5552) Grad: 14340.0254  LR: 0.00001767  \n","Epoch: [1][1900/2032] Elapsed 8m 44s (remain 0m 36s) Loss: 0.5402(0.5541) Grad: 8040.8682  LR: 0.00001742  \n","Epoch: [1][2000/2032] Elapsed 9m 11s (remain 0m 8s) Loss: 0.6006(0.5534) Grad: 14839.3955  LR: 0.00001716  \n","Epoch: [1][2031/2032] Elapsed 9m 20s (remain 0m 0s) Loss: 0.6141(0.5532) Grad: 84010.9922  LR: 0.00001707  \n","EVAL: [0/248] Elapsed 0m 0s (remain 2m 34s) Loss: 0.4784(0.4784) \n","EVAL: [100/248] Elapsed 0m 16s (remain 0m 24s) Loss: 0.4171(0.5561) \n","EVAL: [200/248] Elapsed 0m 32s (remain 0m 7s) Loss: 0.4900(0.5704) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5532  avg_val_loss: 0.5627  time: 601s\n","Epoch 1 - Score: 0.7936\n","Epoch 1 - Save Best Score: 0.7936 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 40s (remain 0m 0s) Loss: 0.6425(0.5627) \n","Epoch: [2][0/2032] Elapsed 0m 0s (remain 26m 52s) Loss: 0.4909(0.4909) Grad: 10943.6582  LR: 0.00001707  \n","Epoch: [2][100/2032] Elapsed 0m 29s (remain 9m 15s) Loss: 0.5726(0.5304) Grad: 92310.3359  LR: 0.00001679  \n","Epoch: [2][200/2032] Elapsed 0m 56s (remain 8m 38s) Loss: 0.5292(0.5212) Grad: 375729.1250  LR: 0.00001650  \n","Epoch: [2][300/2032] Elapsed 1m 24s (remain 8m 5s) Loss: 0.5381(0.5236) Grad: 13700.4844  LR: 0.00001620  \n","Epoch: [2][400/2032] Elapsed 1m 52s (remain 7m 35s) Loss: 0.4737(0.5221) Grad: 93157.9609  LR: 0.00001590  \n","Epoch: [2][500/2032] Elapsed 2m 19s (remain 7m 6s) Loss: 0.5435(0.5179) Grad: 95634.8594  LR: 0.00001558  \n","Epoch: [2][600/2032] Elapsed 2m 47s (remain 6m 37s) Loss: 0.4543(0.5173) Grad: 45976.2539  LR: 0.00001525  \n","Epoch: [2][700/2032] Elapsed 3m 14s (remain 6m 9s) Loss: 0.4035(0.5179) Grad: 197255.7969  LR: 0.00001492  \n","Epoch: [2][800/2032] Elapsed 3m 42s (remain 5m 41s) Loss: 0.4365(0.5172) Grad: 34853.0117  LR: 0.00001458  \n","Epoch: [2][900/2032] Elapsed 4m 9s (remain 5m 13s) Loss: 0.5804(0.5167) Grad: 31310.3691  LR: 0.00001423  \n","Epoch: [2][1000/2032] Elapsed 4m 37s (remain 4m 45s) Loss: 0.6391(0.5180) Grad: 33607.6875  LR: 0.00001388  \n","Epoch: [2][1100/2032] Elapsed 5m 5s (remain 4m 17s) Loss: 0.4589(0.5181) Grad: 43110.5977  LR: 0.00001352  \n","Epoch: [2][1200/2032] Elapsed 5m 32s (remain 3m 50s) Loss: 0.5524(0.5177) Grad: 25026.5117  LR: 0.00001316  \n","Epoch: [2][1300/2032] Elapsed 6m 0s (remain 3m 22s) Loss: 0.5679(0.5183) Grad: 43442.7109  LR: 0.00001279  \n","Epoch: [2][1400/2032] Elapsed 6m 27s (remain 2m 54s) Loss: 0.5345(0.5182) Grad: 65624.1250  LR: 0.00001242  \n","Epoch: [2][1500/2032] Elapsed 6m 55s (remain 2m 26s) Loss: 0.4773(0.5177) Grad: 23497.8242  LR: 0.00001204  \n","Epoch: [2][1600/2032] Elapsed 7m 22s (remain 1m 59s) Loss: 0.5586(0.5181) Grad: 42689.9727  LR: 0.00001166  \n","Epoch: [2][1700/2032] Elapsed 7m 50s (remain 1m 31s) Loss: 0.5498(0.5175) Grad: 141403.2344  LR: 0.00001128  \n","Epoch: [2][1800/2032] Elapsed 8m 17s (remain 1m 3s) Loss: 0.5580(0.5170) Grad: 55252.2500  LR: 0.00001089  \n","Epoch: [2][1900/2032] Elapsed 8m 45s (remain 0m 36s) Loss: 0.4928(0.5166) Grad: 18670.7324  LR: 0.00001051  \n","Epoch: [2][2000/2032] Elapsed 9m 12s (remain 0m 8s) Loss: 0.6060(0.5161) Grad: 92656.2500  LR: 0.00001012  \n","Epoch: [2][2031/2032] Elapsed 9m 21s (remain 0m 0s) Loss: 0.6074(0.5159) Grad: 95374.9766  LR: 0.00001000  \n","EVAL: [0/248] Elapsed 0m 0s (remain 2m 32s) Loss: 0.4754(0.4754) \n","EVAL: [100/248] Elapsed 0m 16s (remain 0m 24s) Loss: 0.4310(0.5529) \n","EVAL: [200/248] Elapsed 0m 32s (remain 0m 7s) Loss: 0.4802(0.5720) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5159  avg_val_loss: 0.5623  time: 602s\n","Epoch 2 - Score: 0.8069\n","Epoch 2 - Save Best Score: 0.8069 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 40s (remain 0m 0s) Loss: 0.6341(0.5623) \n","Epoch: [3][0/2032] Elapsed 0m 0s (remain 27m 6s) Loss: 0.4908(0.4908) Grad: 52965.0352  LR: 0.00001000  \n","Epoch: [3][100/2032] Elapsed 0m 29s (remain 9m 17s) Loss: 0.4443(0.4990) Grad: 68592.8359  LR: 0.00000961  \n","Epoch: [3][200/2032] Elapsed 0m 57s (remain 8m 39s) Loss: 0.5058(0.4986) Grad: 106265.0156  LR: 0.00000923  \n","Epoch: [3][300/2032] Elapsed 1m 24s (remain 8m 6s) Loss: 0.4996(0.4992) Grad: 45386.9180  LR: 0.00000884  \n","Epoch: [3][400/2032] Elapsed 1m 52s (remain 7m 36s) Loss: 0.4465(0.4955) Grad: 76555.5078  LR: 0.00000846  \n","Epoch: [3][500/2032] Elapsed 2m 19s (remain 7m 6s) Loss: 0.4766(0.4981) Grad: 102536.6406  LR: 0.00000808  \n","Epoch: [3][600/2032] Elapsed 2m 47s (remain 6m 38s) Loss: 0.5165(0.4999) Grad: 40773.3359  LR: 0.00000770  \n","Epoch: [3][700/2032] Elapsed 3m 14s (remain 6m 9s) Loss: 0.4378(0.5009) Grad: 18284.4551  LR: 0.00000733  \n","Epoch: [3][800/2032] Elapsed 3m 42s (remain 5m 41s) Loss: 0.4710(0.5008) Grad: 13348.2354  LR: 0.00000696  \n","Epoch: [3][900/2032] Elapsed 4m 9s (remain 5m 13s) Loss: 0.4160(0.5011) Grad: 51831.9844  LR: 0.00000659  \n","Epoch: [3][1000/2032] Elapsed 4m 37s (remain 4m 45s) Loss: 0.4602(0.5008) Grad: 29833.3555  LR: 0.00000623  \n","Epoch: [3][1100/2032] Elapsed 5m 4s (remain 4m 17s) Loss: 0.5355(0.5006) Grad: 29848.1035  LR: 0.00000587  \n","Epoch: [3][1200/2032] Elapsed 5m 32s (remain 3m 49s) Loss: 0.5238(0.5008) Grad: 29426.7305  LR: 0.00000553  \n","Epoch: [3][1300/2032] Elapsed 5m 59s (remain 3m 22s) Loss: 0.6367(0.5010) Grad: 32987.8242  LR: 0.00000518  \n","Epoch: [3][1400/2032] Elapsed 6m 27s (remain 2m 54s) Loss: 0.4042(0.5015) Grad: 38019.7930  LR: 0.00000485  \n","Epoch: [3][1500/2032] Elapsed 6m 54s (remain 2m 26s) Loss: 0.5358(0.5021) Grad: 11185.3525  LR: 0.00000452  \n","Epoch: [3][1600/2032] Elapsed 7m 22s (remain 1m 59s) Loss: 0.5360(0.5024) Grad: 15517.3281  LR: 0.00000420  \n","Epoch: [3][1700/2032] Elapsed 7m 49s (remain 1m 31s) Loss: 0.5940(0.5024) Grad: 35804.0156  LR: 0.00000389  \n","Epoch: [3][1800/2032] Elapsed 8m 17s (remain 1m 3s) Loss: 0.5066(0.5025) Grad: 38358.3047  LR: 0.00000359  \n","Epoch: [3][1900/2032] Elapsed 8m 44s (remain 0m 36s) Loss: 0.5689(0.5020) Grad: 14266.3662  LR: 0.00000330  \n","Epoch: [3][2000/2032] Elapsed 9m 11s (remain 0m 8s) Loss: 0.4092(0.5018) Grad: 16766.7754  LR: 0.00000302  \n","Epoch: [3][2031/2032] Elapsed 9m 20s (remain 0m 0s) Loss: 0.3815(0.5017) Grad: 50160.0625  LR: 0.00000293  \n","EVAL: [0/248] Elapsed 0m 0s (remain 2m 34s) Loss: 0.4802(0.4802) \n","EVAL: [100/248] Elapsed 0m 16s (remain 0m 24s) Loss: 0.4138(0.5701) \n","EVAL: [200/248] Elapsed 0m 32s (remain 0m 7s) Loss: 0.4886(0.5897) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5017  avg_val_loss: 0.5795  time: 601s\n","Epoch 3 - Score: 0.8069\n","Epoch 3 - Save Best Score: 0.8069 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 40s (remain 0m 0s) Loss: 0.6318(0.5795) \n","Epoch: [4][0/2032] Elapsed 0m 0s (remain 26m 24s) Loss: 0.6084(0.6084) Grad: 17822.4082  LR: 0.00000293  \n","Epoch: [4][100/2032] Elapsed 0m 29s (remain 9m 14s) Loss: 0.4059(0.4864) Grad: 12409.2432  LR: 0.00000266  \n","Epoch: [4][200/2032] Elapsed 0m 56s (remain 8m 35s) Loss: 0.4173(0.4910) Grad: 10314.9639  LR: 0.00000240  \n","Epoch: [4][300/2032] Elapsed 1m 24s (remain 8m 3s) Loss: 0.4896(0.4922) Grad: 11633.9775  LR: 0.00000216  \n","Epoch: [4][400/2032] Elapsed 1m 51s (remain 7m 33s) Loss: 0.5743(0.4951) Grad: 94190.5156  LR: 0.00000192  \n","Epoch: [4][500/2032] Elapsed 2m 19s (remain 7m 5s) Loss: 0.6606(0.4960) Grad: 16084.4434  LR: 0.00000170  \n","Epoch: [4][600/2032] Elapsed 2m 46s (remain 6m 37s) Loss: 0.6238(0.4970) Grad: 29425.4824  LR: 0.00000149  \n","Epoch: [4][700/2032] Elapsed 3m 14s (remain 6m 9s) Loss: 0.5088(0.4967) Grad: 143511.4531  LR: 0.00000130  \n","Epoch: [4][800/2032] Elapsed 3m 41s (remain 5m 41s) Loss: 0.5913(0.4959) Grad: 183158.5938  LR: 0.00000111  \n","Epoch: [4][900/2032] Elapsed 4m 9s (remain 5m 13s) Loss: 0.5469(0.4961) Grad: 60153.9062  LR: 0.00000094  \n","Epoch: [4][1000/2032] Elapsed 4m 36s (remain 4m 45s) Loss: 0.5733(0.4962) Grad: 48038.0312  LR: 0.00000078  \n","Epoch: [4][1100/2032] Elapsed 5m 4s (remain 4m 17s) Loss: 0.5201(0.4962) Grad: 270808.7812  LR: 0.00000064  \n","Epoch: [4][1200/2032] Elapsed 5m 31s (remain 3m 49s) Loss: 0.4641(0.4951) Grad: 36474.0859  LR: 0.00000051  \n","Epoch: [4][1300/2032] Elapsed 5m 59s (remain 3m 21s) Loss: 0.4709(0.4950) Grad: 44148.8633  LR: 0.00000040  \n","Epoch: [4][1400/2032] Elapsed 6m 26s (remain 2m 54s) Loss: 0.4506(0.4953) Grad: 23129.0449  LR: 0.00000030  \n","Epoch: [4][1500/2032] Elapsed 6m 54s (remain 2m 26s) Loss: 0.4746(0.4948) Grad: 100403.1953  LR: 0.00000021  \n","Epoch: [4][1600/2032] Elapsed 7m 21s (remain 1m 58s) Loss: 0.4823(0.4949) Grad: 38225.1680  LR: 0.00000014  \n","Epoch: [4][1700/2032] Elapsed 7m 49s (remain 1m 31s) Loss: 0.4818(0.4943) Grad: 79165.3594  LR: 0.00000008  \n","Epoch: [4][1800/2032] Elapsed 8m 16s (remain 1m 3s) Loss: 0.5094(0.4943) Grad: 184889.4062  LR: 0.00000004  \n","Epoch: [4][1900/2032] Elapsed 8m 44s (remain 0m 36s) Loss: 0.4826(0.4941) Grad: 37370.1953  LR: 0.00000001  \n","Epoch: [4][2000/2032] Elapsed 9m 11s (remain 0m 8s) Loss: 0.3906(0.4948) Grad: 101448.6172  LR: 0.00000000  \n","Epoch: [4][2031/2032] Elapsed 9m 20s (remain 0m 0s) Loss: 0.4601(0.4946) Grad: 73107.4141  LR: 0.00000000  \n","EVAL: [0/248] Elapsed 0m 0s (remain 2m 30s) Loss: 0.4832(0.4832) \n","EVAL: [100/248] Elapsed 0m 16s (remain 0m 24s) Loss: 0.4105(0.5689) \n","EVAL: [200/248] Elapsed 0m 32s (remain 0m 7s) Loss: 0.4855(0.5893) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4946  avg_val_loss: 0.5797  time: 601s\n","Epoch 4 - Score: 0.8104\n","Epoch 4 - Save Best Score: 0.8104 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 40s (remain 0m 0s) Loss: 0.6285(0.5797) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","Score: 0.8104\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2052] Elapsed 0m 0s (remain 27m 28s) Loss: 0.7782(0.7782) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/2052] Elapsed 0m 28s (remain 9m 19s) Loss: 0.6307(0.6559) Grad: 20616.1074  LR: 0.00001999  \n","Epoch: [1][200/2052] Elapsed 0m 56s (remain 8m 42s) Loss: 0.6133(0.6289) Grad: 18736.0957  LR: 0.00001997  \n","Epoch: [1][300/2052] Elapsed 1m 24s (remain 8m 9s) Loss: 0.5392(0.6114) Grad: 7121.2881  LR: 0.00001993  \n","Epoch: [1][400/2052] Elapsed 1m 51s (remain 7m 39s) Loss: 0.6314(0.6012) Grad: 15236.0693  LR: 0.00001988  \n","Epoch: [1][500/2052] Elapsed 2m 19s (remain 7m 10s) Loss: 0.4395(0.5922) Grad: 26814.9316  LR: 0.00001982  \n","Epoch: [1][600/2052] Elapsed 2m 46s (remain 6m 42s) Loss: 0.4880(0.5839) Grad: 9233.9023  LR: 0.00001974  \n","Epoch: [1][700/2052] Elapsed 3m 14s (remain 6m 14s) Loss: 0.4131(0.5786) Grad: 7183.7002  LR: 0.00001964  \n","Epoch: [1][800/2052] Elapsed 3m 41s (remain 5m 45s) Loss: 0.6570(0.5744) Grad: 11795.2129  LR: 0.00001953  \n","Epoch: [1][900/2052] Elapsed 4m 8s (remain 5m 17s) Loss: 0.5239(0.5734) Grad: 10470.1533  LR: 0.00001941  \n","Epoch: [1][1000/2052] Elapsed 4m 36s (remain 4m 50s) Loss: 0.5897(0.5703) Grad: 37629.6836  LR: 0.00001928  \n","Epoch: [1][1100/2052] Elapsed 5m 4s (remain 4m 22s) Loss: 0.5304(0.5684) Grad: 8244.9102  LR: 0.00001913  \n","Epoch: [1][1200/2052] Elapsed 5m 31s (remain 3m 54s) Loss: 0.4230(0.5663) Grad: 7408.9541  LR: 0.00001896  \n","Epoch: [1][1300/2052] Elapsed 5m 58s (remain 3m 27s) Loss: 0.4149(0.5636) Grad: 17841.3184  LR: 0.00001879  \n","Epoch: [1][1400/2052] Elapsed 6m 26s (remain 2m 59s) Loss: 0.5165(0.5623) Grad: 14612.6455  LR: 0.00001860  \n","Epoch: [1][1500/2052] Elapsed 6m 53s (remain 2m 31s) Loss: 0.4165(0.5617) Grad: 17372.8926  LR: 0.00001839  \n","Epoch: [1][1600/2052] Elapsed 7m 21s (remain 2m 4s) Loss: 0.5118(0.5608) Grad: 9364.9229  LR: 0.00001818  \n","Epoch: [1][1700/2052] Elapsed 7m 48s (remain 1m 36s) Loss: 0.5339(0.5597) Grad: 43417.5430  LR: 0.00001795  \n","Epoch: [1][1800/2052] Elapsed 8m 16s (remain 1m 9s) Loss: 0.5718(0.5592) Grad: 9608.1973  LR: 0.00001772  \n","Epoch: [1][1900/2052] Elapsed 8m 43s (remain 0m 41s) Loss: 0.5601(0.5589) Grad: 8190.1509  LR: 0.00001747  \n","Epoch: [1][2000/2052] Elapsed 9m 11s (remain 0m 14s) Loss: 0.6384(0.5577) Grad: 19898.0352  LR: 0.00001721  \n","Epoch: [1][2051/2052] Elapsed 9m 25s (remain 0m 0s) Loss: 0.5126(0.5574) Grad: 11151.2490  LR: 0.00001707  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 30s) Loss: 0.6251(0.6251) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 20s) Loss: 0.4176(0.5326) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.6016(0.5392) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5574  avg_val_loss: 0.5376  time: 602s\n","Epoch 1 - Score: 0.8296\n","Epoch 1 - Save Best Score: 0.8296 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.2617(0.5376) \n","Epoch: [2][0/2052] Elapsed 0m 0s (remain 29m 48s) Loss: 0.4554(0.4554) Grad: 8590.5586  LR: 0.00001707  \n","Epoch: [2][100/2052] Elapsed 0m 28s (remain 9m 13s) Loss: 0.5114(0.5250) Grad: 17579.6719  LR: 0.00001679  \n","Epoch: [2][200/2052] Elapsed 0m 56s (remain 8m 40s) Loss: 0.3950(0.5167) Grad: 7665.9536  LR: 0.00001651  \n","Epoch: [2][300/2052] Elapsed 1m 24s (remain 8m 9s) Loss: 0.3632(0.5191) Grad: 22287.1035  LR: 0.00001621  \n","Epoch: [2][400/2052] Elapsed 1m 51s (remain 7m 39s) Loss: 0.5212(0.5178) Grad: 12909.5352  LR: 0.00001591  \n","Epoch: [2][500/2052] Elapsed 2m 19s (remain 7m 10s) Loss: 0.4307(0.5192) Grad: 27174.9062  LR: 0.00001559  \n","Epoch: [2][600/2052] Elapsed 2m 46s (remain 6m 42s) Loss: 0.5650(0.5203) Grad: 18210.3438  LR: 0.00001527  \n","Epoch: [2][700/2052] Elapsed 3m 13s (remain 6m 13s) Loss: 0.4784(0.5213) Grad: 25805.0508  LR: 0.00001494  \n","Epoch: [2][800/2052] Elapsed 3m 41s (remain 5m 45s) Loss: 0.5582(0.5192) Grad: 177941.3125  LR: 0.00001461  \n","Epoch: [2][900/2052] Elapsed 4m 8s (remain 5m 17s) Loss: 0.5699(0.5192) Grad: 60901.9805  LR: 0.00001427  \n","Epoch: [2][1000/2052] Elapsed 4m 36s (remain 4m 50s) Loss: 0.5735(0.5180) Grad: 19102.3379  LR: 0.00001392  \n","Epoch: [2][1100/2052] Elapsed 5m 3s (remain 4m 22s) Loss: 0.5640(0.5178) Grad: 108758.0469  LR: 0.00001356  \n","Epoch: [2][1200/2052] Elapsed 5m 31s (remain 3m 54s) Loss: 0.6739(0.5176) Grad: 39928.3008  LR: 0.00001320  \n","Epoch: [2][1300/2052] Elapsed 5m 58s (remain 3m 27s) Loss: 0.5788(0.5180) Grad: 10205.6436  LR: 0.00001284  \n","Epoch: [2][1400/2052] Elapsed 6m 25s (remain 2m 59s) Loss: 0.5682(0.5167) Grad: 113763.9844  LR: 0.00001247  \n","Epoch: [2][1500/2052] Elapsed 6m 53s (remain 2m 31s) Loss: 0.4889(0.5171) Grad: 20296.4727  LR: 0.00001209  \n","Epoch: [2][1600/2052] Elapsed 7m 20s (remain 2m 4s) Loss: 0.5999(0.5172) Grad: 41009.1719  LR: 0.00001172  \n","Epoch: [2][1700/2052] Elapsed 7m 48s (remain 1m 36s) Loss: 0.4152(0.5178) Grad: 10070.1787  LR: 0.00001134  \n","Epoch: [2][1800/2052] Elapsed 8m 15s (remain 1m 9s) Loss: 0.5012(0.5175) Grad: 23986.1914  LR: 0.00001096  \n","Epoch: [2][1900/2052] Elapsed 8m 43s (remain 0m 41s) Loss: 0.4780(0.5179) Grad: 20607.2227  LR: 0.00001058  \n","Epoch: [2][2000/2052] Elapsed 9m 10s (remain 0m 14s) Loss: 0.5162(0.5181) Grad: 16922.7129  LR: 0.00001020  \n","Epoch: [2][2051/2052] Elapsed 9m 24s (remain 0m 0s) Loss: 0.5913(0.5174) Grad: 54225.3516  LR: 0.00001000  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 33s) Loss: 0.6376(0.6376) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 20s) Loss: 0.3871(0.5363) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.5968(0.5464) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5174  avg_val_loss: 0.5447  time: 602s\n","Epoch 2 - Score: 0.8446\n","Epoch 2 - Save Best Score: 0.8446 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.2528(0.5447) \n","Epoch: [3][0/2052] Elapsed 0m 0s (remain 29m 20s) Loss: 0.4629(0.4629) Grad: 14453.7617  LR: 0.00001000  \n","Epoch: [3][100/2052] Elapsed 0m 28s (remain 9m 17s) Loss: 0.4897(0.5003) Grad: 67918.7188  LR: 0.00000962  \n","Epoch: [3][200/2052] Elapsed 0m 56s (remain 8m 40s) Loss: 0.5338(0.4986) Grad: 26621.1211  LR: 0.00000923  \n","Epoch: [3][300/2052] Elapsed 1m 24s (remain 8m 8s) Loss: 0.4382(0.5019) Grad: 16011.2607  LR: 0.00000885  \n","Epoch: [3][400/2052] Elapsed 1m 51s (remain 7m 39s) Loss: 0.4858(0.5021) Grad: 694961.5625  LR: 0.00000847  \n","Epoch: [3][500/2052] Elapsed 2m 18s (remain 7m 10s) Loss: 0.5141(0.4993) Grad: 13856.4824  LR: 0.00000810  \n","Epoch: [3][600/2052] Elapsed 2m 46s (remain 6m 41s) Loss: 0.6349(0.5004) Grad: 38825.9609  LR: 0.00000772  \n","Epoch: [3][700/2052] Elapsed 3m 14s (remain 6m 14s) Loss: 0.3982(0.5021) Grad: 13158.1855  LR: 0.00000735  \n","Epoch: [3][800/2052] Elapsed 3m 41s (remain 5m 46s) Loss: 0.4509(0.5018) Grad: 10616.9287  LR: 0.00000698  \n","Epoch: [3][900/2052] Elapsed 4m 9s (remain 5m 18s) Loss: 0.4231(0.5012) Grad: 8444.7773  LR: 0.00000662  \n","Epoch: [3][1000/2052] Elapsed 4m 36s (remain 4m 50s) Loss: 0.4409(0.5000) Grad: 19078.6074  LR: 0.00000626  \n","Epoch: [3][1100/2052] Elapsed 5m 3s (remain 4m 22s) Loss: 0.5952(0.5000) Grad: 83783.5078  LR: 0.00000591  \n","Epoch: [3][1200/2052] Elapsed 5m 31s (remain 3m 54s) Loss: 0.4787(0.5005) Grad: 6674.9136  LR: 0.00000557  \n","Epoch: [3][1300/2052] Elapsed 5m 58s (remain 3m 27s) Loss: 0.4761(0.5018) Grad: 16514.2637  LR: 0.00000523  \n","Epoch: [3][1400/2052] Elapsed 6m 26s (remain 2m 59s) Loss: 0.4657(0.5017) Grad: 19841.6992  LR: 0.00000489  \n","Epoch: [3][1500/2052] Elapsed 6m 53s (remain 2m 31s) Loss: 0.5962(0.5009) Grad: 12517.3398  LR: 0.00000457  \n","Epoch: [3][1600/2052] Elapsed 7m 20s (remain 2m 4s) Loss: 0.6044(0.5008) Grad: 18313.7246  LR: 0.00000425  \n","Epoch: [3][1700/2052] Elapsed 7m 48s (remain 1m 36s) Loss: 0.5572(0.5007) Grad: 42960.4805  LR: 0.00000394  \n","Epoch: [3][1800/2052] Elapsed 8m 15s (remain 1m 9s) Loss: 0.4855(0.5010) Grad: 59150.9844  LR: 0.00000364  \n","Epoch: [3][1900/2052] Elapsed 8m 43s (remain 0m 41s) Loss: 0.4442(0.5013) Grad: 8820.4785  LR: 0.00000335  \n","Epoch: [3][2000/2052] Elapsed 9m 11s (remain 0m 14s) Loss: 0.6287(0.5018) Grad: 41169.2344  LR: 0.00000307  \n","Epoch: [3][2051/2052] Elapsed 9m 25s (remain 0m 0s) Loss: 0.5260(0.5018) Grad: 19063.4453  LR: 0.00000293  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 31s) Loss: 0.7194(0.7194) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 20s) Loss: 0.3772(0.5539) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.5970(0.5636) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5018  avg_val_loss: 0.5617  time: 602s\n","Epoch 3 - Score: 0.8398\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.2005(0.5617) \n","Epoch: [4][0/2052] Elapsed 0m 0s (remain 29m 13s) Loss: 0.4306(0.4306) Grad: 15726.0928  LR: 0.00000293  \n","Epoch: [4][100/2052] Elapsed 0m 28s (remain 9m 9s) Loss: 0.5347(0.4938) Grad: 15961.8711  LR: 0.00000266  \n","Epoch: [4][200/2052] Elapsed 0m 55s (remain 8m 35s) Loss: 0.4488(0.4907) Grad: 7053.2178  LR: 0.00000241  \n","Epoch: [4][300/2052] Elapsed 1m 23s (remain 8m 5s) Loss: 0.4576(0.4868) Grad: 5243.4966  LR: 0.00000216  \n","Epoch: [4][400/2052] Elapsed 1m 51s (remain 7m 37s) Loss: 0.5208(0.4920) Grad: 23204.4746  LR: 0.00000193  \n","Epoch: [4][500/2052] Elapsed 2m 18s (remain 7m 9s) Loss: 0.4683(0.4922) Grad: 21767.9277  LR: 0.00000171  \n","Epoch: [4][600/2052] Elapsed 2m 46s (remain 6m 41s) Loss: 0.4298(0.4917) Grad: 11313.6523  LR: 0.00000150  \n","Epoch: [4][700/2052] Elapsed 3m 13s (remain 6m 13s) Loss: 0.4280(0.4942) Grad: 13889.1074  LR: 0.00000131  \n","Epoch: [4][800/2052] Elapsed 3m 41s (remain 5m 45s) Loss: 0.5387(0.4941) Grad: 18145.4844  LR: 0.00000113  \n","Epoch: [4][900/2052] Elapsed 4m 9s (remain 5m 18s) Loss: 0.4322(0.4948) Grad: 43993.0664  LR: 0.00000096  \n","Epoch: [4][1000/2052] Elapsed 4m 36s (remain 4m 50s) Loss: 0.4673(0.4949) Grad: 14489.9346  LR: 0.00000080  \n","Epoch: [4][1100/2052] Elapsed 5m 4s (remain 4m 23s) Loss: 0.3439(0.4946) Grad: 16061.1562  LR: 0.00000066  \n","Epoch: [4][1200/2052] Elapsed 5m 31s (remain 3m 55s) Loss: 0.4309(0.4949) Grad: 11806.3145  LR: 0.00000053  \n","Epoch: [4][1300/2052] Elapsed 5m 59s (remain 3m 27s) Loss: 0.4806(0.4936) Grad: 16103.3193  LR: 0.00000041  \n","Epoch: [4][1400/2052] Elapsed 6m 27s (remain 2m 59s) Loss: 0.4940(0.4931) Grad: 48477.6133  LR: 0.00000031  \n","Epoch: [4][1500/2052] Elapsed 6m 54s (remain 2m 32s) Loss: 0.6166(0.4935) Grad: 21778.4629  LR: 0.00000022  \n","Epoch: [4][1600/2052] Elapsed 7m 22s (remain 2m 4s) Loss: 0.5240(0.4939) Grad: 14795.2910  LR: 0.00000015  \n","Epoch: [4][1700/2052] Elapsed 7m 49s (remain 1m 36s) Loss: 0.4639(0.4940) Grad: 17956.6367  LR: 0.00000009  \n","Epoch: [4][1800/2052] Elapsed 8m 17s (remain 1m 9s) Loss: 0.4332(0.4937) Grad: 10236.2451  LR: 0.00000005  \n","Epoch: [4][1900/2052] Elapsed 8m 44s (remain 0m 41s) Loss: 0.4057(0.4937) Grad: 14373.2754  LR: 0.00000002  \n","Epoch: [4][2000/2052] Elapsed 9m 12s (remain 0m 14s) Loss: 0.5006(0.4932) Grad: 10571.8271  LR: 0.00000000  \n","Epoch: [4][2051/2052] Elapsed 9m 26s (remain 0m 0s) Loss: 0.5882(0.4937) Grad: 8705.9111  LR: 0.00000000  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 34s) Loss: 0.7357(0.7357) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 20s) Loss: 0.3758(0.5572) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.6001(0.5683) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4937  avg_val_loss: 0.5651  time: 604s\n","Epoch 4 - Score: 0.8397\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.2063(0.5651) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 1 result ==========\n","Score: 0.8446\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2059] Elapsed 0m 0s (remain 27m 44s) Loss: 0.7193(0.7193) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/2059] Elapsed 0m 28s (remain 9m 10s) Loss: 0.6344(0.6508) Grad: 62107.2031  LR: 0.00001999  \n","Epoch: [1][200/2059] Elapsed 0m 55s (remain 8m 36s) Loss: 0.5300(0.6208) Grad: 79411.9688  LR: 0.00001997  \n","Epoch: [1][300/2059] Elapsed 1m 23s (remain 8m 6s) Loss: 0.6101(0.6037) Grad: 77117.3438  LR: 0.00001993  \n","Epoch: [1][400/2059] Elapsed 1m 50s (remain 7m 38s) Loss: 0.5347(0.5965) Grad: 62205.1445  LR: 0.00001988  \n","Epoch: [1][500/2059] Elapsed 2m 18s (remain 7m 10s) Loss: 0.6145(0.5887) Grad: 63343.9023  LR: 0.00001982  \n","Epoch: [1][600/2059] Elapsed 2m 45s (remain 6m 42s) Loss: 0.6187(0.5849) Grad: 130615.8984  LR: 0.00001974  \n","Epoch: [1][700/2059] Elapsed 3m 13s (remain 6m 14s) Loss: 0.4571(0.5791) Grad: 72807.6406  LR: 0.00001964  \n","Epoch: [1][800/2059] Elapsed 3m 40s (remain 5m 47s) Loss: 0.6186(0.5755) Grad: 73572.8984  LR: 0.00001954  \n","Epoch: [1][900/2059] Elapsed 4m 8s (remain 5m 19s) Loss: 0.5748(0.5720) Grad: 84184.1094  LR: 0.00001942  \n","Epoch: [1][1000/2059] Elapsed 4m 35s (remain 4m 51s) Loss: 0.6225(0.5685) Grad: 39126.6953  LR: 0.00001928  \n","Epoch: [1][1100/2059] Elapsed 5m 3s (remain 4m 23s) Loss: 0.5453(0.5664) Grad: 47780.0352  LR: 0.00001913  \n","Epoch: [1][1200/2059] Elapsed 5m 31s (remain 3m 56s) Loss: 0.5381(0.5644) Grad: 36347.1250  LR: 0.00001897  \n","Epoch: [1][1300/2059] Elapsed 5m 58s (remain 3m 28s) Loss: 0.4717(0.5627) Grad: 44355.4961  LR: 0.00001879  \n","Epoch: [1][1400/2059] Elapsed 6m 26s (remain 3m 1s) Loss: 0.6100(0.5613) Grad: 39215.9883  LR: 0.00001861  \n","Epoch: [1][1500/2059] Elapsed 6m 53s (remain 2m 33s) Loss: 0.5685(0.5602) Grad: 27326.4922  LR: 0.00001841  \n","Epoch: [1][1600/2059] Elapsed 7m 21s (remain 2m 6s) Loss: 0.3971(0.5591) Grad: 45679.2930  LR: 0.00001819  \n","Epoch: [1][1700/2059] Elapsed 7m 48s (remain 1m 38s) Loss: 0.5355(0.5580) Grad: 73517.7969  LR: 0.00001797  \n","Epoch: [1][1800/2059] Elapsed 8m 16s (remain 1m 11s) Loss: 0.6063(0.5572) Grad: 229907.4844  LR: 0.00001773  \n","Epoch: [1][1900/2059] Elapsed 8m 43s (remain 0m 43s) Loss: 0.5650(0.5563) Grad: 56739.4961  LR: 0.00001748  \n","Epoch: [1][2000/2059] Elapsed 9m 11s (remain 0m 15s) Loss: 0.5013(0.5555) Grad: 48801.8047  LR: 0.00001723  \n","Epoch: [1][2058/2059] Elapsed 9m 27s (remain 0m 0s) Loss: 0.4737(0.5551) Grad: 58614.6016  LR: 0.00001707  \n","EVAL: [0/221] Elapsed 0m 0s (remain 2m 28s) Loss: 0.4096(0.4096) \n","EVAL: [100/221] Elapsed 0m 16s (remain 0m 19s) Loss: 0.5876(0.5413) \n","EVAL: [200/221] Elapsed 0m 32s (remain 0m 3s) Loss: 0.5633(0.5452) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5551  avg_val_loss: 0.5478  time: 603s\n","Epoch 1 - Score: 0.8236\n","Epoch 1 - Save Best Score: 0.8236 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [220/221] Elapsed 0m 35s (remain 0m 0s) Loss: 0.3513(0.5478) \n","Epoch: [2][0/2059] Elapsed 0m 0s (remain 28m 49s) Loss: 0.5759(0.5759) Grad: 122959.5000  LR: 0.00001707  \n","Epoch: [2][100/2059] Elapsed 0m 29s (remain 9m 25s) Loss: 0.5419(0.5199) Grad: 87191.0781  LR: 0.00001679  \n","Epoch: [2][200/2059] Elapsed 0m 57s (remain 8m 47s) Loss: 0.5381(0.5221) Grad: 75136.7734  LR: 0.00001651  \n","Epoch: [2][300/2059] Elapsed 1m 24s (remain 8m 15s) Loss: 0.6124(0.5234) Grad: 94370.6875  LR: 0.00001622  \n","Epoch: [2][400/2059] Elapsed 1m 52s (remain 7m 44s) Loss: 0.4317(0.5224) Grad: 63423.0742  LR: 0.00001591  \n","Epoch: [2][500/2059] Elapsed 2m 19s (remain 7m 14s) Loss: 0.4906(0.5193) Grad: 152827.9062  LR: 0.00001560  \n","Epoch: [2][600/2059] Elapsed 2m 47s (remain 6m 45s) Loss: 0.5579(0.5229) Grad: 27316.2930  LR: 0.00001528  \n","Epoch: [2][700/2059] Elapsed 3m 14s (remain 6m 17s) Loss: 0.5250(0.5241) Grad: 27254.7773  LR: 0.00001495  \n","Epoch: [2][800/2059] Elapsed 3m 42s (remain 5m 49s) Loss: 0.6783(0.5238) Grad: 92324.3984  LR: 0.00001462  \n","Epoch: [2][900/2059] Elapsed 4m 9s (remain 5m 20s) Loss: 0.5006(0.5226) Grad: 78102.6562  LR: 0.00001428  \n","Epoch: [2][1000/2059] Elapsed 4m 37s (remain 4m 52s) Loss: 0.5473(0.5226) Grad: 55087.3906  LR: 0.00001393  \n","Epoch: [2][1100/2059] Elapsed 5m 4s (remain 4m 25s) Loss: 0.4383(0.5223) Grad: 32403.1348  LR: 0.00001357  \n","Epoch: [2][1200/2059] Elapsed 5m 32s (remain 3m 57s) Loss: 0.5738(0.5211) Grad: 49286.1562  LR: 0.00001322  \n","Epoch: [2][1300/2059] Elapsed 5m 59s (remain 3m 29s) Loss: 0.3007(0.5207) Grad: 89592.8750  LR: 0.00001285  \n","Epoch: [2][1400/2059] Elapsed 6m 27s (remain 3m 1s) Loss: 0.5902(0.5207) Grad: 39507.6172  LR: 0.00001249  \n","Epoch: [2][1500/2059] Elapsed 6m 54s (remain 2m 34s) Loss: 0.5950(0.5200) Grad: 33896.7656  LR: 0.00001211  \n","Epoch: [2][1600/2059] Elapsed 7m 22s (remain 2m 6s) Loss: 0.4302(0.5194) Grad: 32399.9727  LR: 0.00001174  \n","Epoch: [2][1700/2059] Elapsed 7m 49s (remain 1m 38s) Loss: 0.5187(0.5188) Grad: 56089.5664  LR: 0.00001136  \n","Epoch: [2][1800/2059] Elapsed 8m 17s (remain 1m 11s) Loss: 0.4067(0.5185) Grad: 126074.3125  LR: 0.00001098  \n","Epoch: [2][1900/2059] Elapsed 8m 44s (remain 0m 43s) Loss: 0.5780(0.5179) Grad: 62341.6133  LR: 0.00001060  \n","Epoch: [2][2000/2059] Elapsed 9m 12s (remain 0m 16s) Loss: 0.3826(0.5180) Grad: 131717.7656  LR: 0.00001022  \n","Epoch: [2][2058/2059] Elapsed 9m 28s (remain 0m 0s) Loss: 0.5777(0.5180) Grad: 169590.4844  LR: 0.00001000  \n","EVAL: [0/221] Elapsed 0m 0s (remain 2m 30s) Loss: 0.3980(0.3980) \n","EVAL: [100/221] Elapsed 0m 16s (remain 0m 19s) Loss: 0.5697(0.5391) \n","EVAL: [200/221] Elapsed 0m 32s (remain 0m 3s) Loss: 0.5672(0.5418) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5180  avg_val_loss: 0.5455  time: 604s\n","Epoch 2 - Score: 0.8387\n","Epoch 2 - Save Best Score: 0.8387 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [220/221] Elapsed 0m 35s (remain 0m 0s) Loss: 0.3450(0.5455) \n","Epoch: [3][0/2059] Elapsed 0m 0s (remain 28m 49s) Loss: 0.5091(0.5091) Grad: 519577.2500  LR: 0.00001000  \n","Epoch: [3][100/2059] Elapsed 0m 28s (remain 9m 18s) Loss: 0.5155(0.5115) Grad: 204837.7031  LR: 0.00000962  \n","Epoch: [3][200/2059] Elapsed 0m 56s (remain 8m 44s) Loss: 0.4791(0.5072) Grad: 76784.1562  LR: 0.00000924  \n","Epoch: [3][300/2059] Elapsed 1m 24s (remain 8m 11s) Loss: 0.5690(0.5094) Grad: 538463.6875  LR: 0.00000886  \n","Epoch: [3][400/2059] Elapsed 1m 51s (remain 7m 41s) Loss: 0.4872(0.5090) Grad: 188413.7031  LR: 0.00000848  \n","Epoch: [3][500/2059] Elapsed 2m 19s (remain 7m 12s) Loss: 0.5536(0.5054) Grad: 543483.6875  LR: 0.00000810  \n","Epoch: [3][600/2059] Elapsed 2m 46s (remain 6m 44s) Loss: 0.5034(0.5043) Grad: 222401.4219  LR: 0.00000773  \n","Epoch: [3][700/2059] Elapsed 3m 14s (remain 6m 16s) Loss: 0.5660(0.5045) Grad: 101581.7344  LR: 0.00000736  \n","Epoch: [3][800/2059] Elapsed 3m 41s (remain 5m 48s) Loss: 0.5730(0.5033) Grad: 300743.4375  LR: 0.00000699  \n","Epoch: [3][900/2059] Elapsed 4m 9s (remain 5m 20s) Loss: 0.4854(0.5025) Grad: 517490.2500  LR: 0.00000663  \n","Epoch: [3][1000/2059] Elapsed 4m 36s (remain 4m 52s) Loss: 0.5729(0.5024) Grad: 166413.7344  LR: 0.00000628  \n","Epoch: [3][1100/2059] Elapsed 5m 4s (remain 4m 24s) Loss: 0.5675(0.5033) Grad: 96452.5547  LR: 0.00000592  \n","Epoch: [3][1200/2059] Elapsed 5m 31s (remain 3m 57s) Loss: 0.4264(0.5034) Grad: 95226.2422  LR: 0.00000558  \n","Epoch: [3][1300/2059] Elapsed 5m 59s (remain 3m 29s) Loss: 0.4622(0.5036) Grad: 47561.0664  LR: 0.00000524  \n","Epoch: [3][1400/2059] Elapsed 6m 26s (remain 3m 1s) Loss: 0.5605(0.5043) Grad: 105912.1953  LR: 0.00000491  \n","Epoch: [3][1500/2059] Elapsed 6m 54s (remain 2m 33s) Loss: 0.5116(0.5046) Grad: 50891.8281  LR: 0.00000458  \n","Epoch: [3][1600/2059] Elapsed 7m 21s (remain 2m 6s) Loss: 0.5276(0.5048) Grad: 78874.6641  LR: 0.00000427  \n","Epoch: [3][1700/2059] Elapsed 7m 48s (remain 1m 38s) Loss: 0.5448(0.5047) Grad: 315495.3750  LR: 0.00000396  \n","Epoch: [3][1800/2059] Elapsed 8m 16s (remain 1m 11s) Loss: 0.4839(0.5043) Grad: 51234.3320  LR: 0.00000366  \n","Epoch: [3][1900/2059] Elapsed 8m 43s (remain 0m 43s) Loss: 0.4469(0.5040) Grad: 45085.6484  LR: 0.00000337  \n","Epoch: [3][2000/2059] Elapsed 9m 11s (remain 0m 15s) Loss: 0.3946(0.5037) Grad: 46992.0586  LR: 0.00000309  \n","Epoch: [3][2058/2059] Elapsed 9m 27s (remain 0m 0s) Loss: 0.4879(0.5039) Grad: 71074.4531  LR: 0.00000293  \n","EVAL: [0/221] Elapsed 0m 0s (remain 2m 24s) Loss: 0.3935(0.3935) \n","EVAL: [100/221] Elapsed 0m 16s (remain 0m 19s) Loss: 0.5763(0.5411) \n","EVAL: [200/221] Elapsed 0m 32s (remain 0m 3s) Loss: 0.5821(0.5458) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5039  avg_val_loss: 0.5498  time: 603s\n","Epoch 3 - Score: 0.8381\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [220/221] Elapsed 0m 35s (remain 0m 0s) Loss: 0.3457(0.5498) \n","Epoch: [4][0/2059] Elapsed 0m 0s (remain 28m 35s) Loss: 0.5823(0.5823) Grad: 45653.7148  LR: 0.00000293  \n","Epoch: [4][100/2059] Elapsed 0m 28s (remain 9m 8s) Loss: 0.5265(0.5023) Grad: 60553.5469  LR: 0.00000266  \n","Epoch: [4][200/2059] Elapsed 0m 55s (remain 8m 36s) Loss: 0.4983(0.5026) Grad: 89586.4219  LR: 0.00000241  \n","Epoch: [4][300/2059] Elapsed 1m 23s (remain 8m 8s) Loss: 0.4408(0.5005) Grad: 58207.0469  LR: 0.00000217  \n","Epoch: [4][400/2059] Elapsed 1m 51s (remain 7m 40s) Loss: 0.4915(0.5021) Grad: 28855.1055  LR: 0.00000194  \n","Epoch: [4][500/2059] Elapsed 2m 19s (remain 7m 12s) Loss: 0.5815(0.5001) Grad: 61198.5312  LR: 0.00000172  \n","Epoch: [4][600/2059] Elapsed 2m 46s (remain 6m 44s) Loss: 0.5504(0.4995) Grad: 80611.0859  LR: 0.00000151  \n","Epoch: [4][700/2059] Elapsed 3m 14s (remain 6m 16s) Loss: 0.4674(0.4991) Grad: 41389.0234  LR: 0.00000131  \n","Epoch: [4][800/2059] Elapsed 3m 41s (remain 5m 48s) Loss: 0.5979(0.5004) Grad: 39703.0117  LR: 0.00000113  \n","Epoch: [4][900/2059] Elapsed 4m 9s (remain 5m 20s) Loss: 0.4838(0.5005) Grad: 12444.3418  LR: 0.00000096  \n","Epoch: [4][1000/2059] Elapsed 4m 36s (remain 4m 52s) Loss: 0.4751(0.5001) Grad: 76513.2812  LR: 0.00000080  \n","Epoch: [4][1100/2059] Elapsed 5m 4s (remain 4m 25s) Loss: 0.3849(0.4997) Grad: 58515.6250  LR: 0.00000066  \n","Epoch: [4][1200/2059] Elapsed 5m 32s (remain 3m 57s) Loss: 0.4857(0.4993) Grad: 486630.5000  LR: 0.00000053  \n","Epoch: [4][1300/2059] Elapsed 5m 59s (remain 3m 29s) Loss: 0.5903(0.4999) Grad: 304532.7812  LR: 0.00000042  \n","Epoch: [4][1400/2059] Elapsed 6m 27s (remain 3m 1s) Loss: 0.5821(0.5005) Grad: 72456.2422  LR: 0.00000031  \n","Epoch: [4][1500/2059] Elapsed 6m 54s (remain 2m 34s) Loss: 0.4145(0.5001) Grad: 165169.8281  LR: 0.00000023  \n","Epoch: [4][1600/2059] Elapsed 7m 22s (remain 2m 6s) Loss: 0.5929(0.5002) Grad: 86281.9766  LR: 0.00000015  \n","Epoch: [4][1700/2059] Elapsed 7m 49s (remain 1m 38s) Loss: 0.6062(0.4996) Grad: 143123.8750  LR: 0.00000009  \n","Epoch: [4][1800/2059] Elapsed 8m 17s (remain 1m 11s) Loss: 0.5487(0.4990) Grad: 82273.6953  LR: 0.00000005  \n","Epoch: [4][1900/2059] Elapsed 8m 44s (remain 0m 43s) Loss: 0.5233(0.4988) Grad: 148030.1094  LR: 0.00000002  \n","Epoch: [4][2000/2059] Elapsed 9m 12s (remain 0m 16s) Loss: 0.4626(0.4986) Grad: 93566.3281  LR: 0.00000000  \n","Epoch: [4][2058/2059] Elapsed 9m 28s (remain 0m 0s) Loss: 0.5215(0.4984) Grad: 86747.9062  LR: 0.00000000  \n","EVAL: [0/221] Elapsed 0m 0s (remain 2m 30s) Loss: 0.3930(0.3930) \n","EVAL: [100/221] Elapsed 0m 16s (remain 0m 19s) Loss: 0.5716(0.5463) \n","EVAL: [200/221] Elapsed 0m 32s (remain 0m 3s) Loss: 0.5922(0.5518) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4984  avg_val_loss: 0.5561  time: 605s\n","Epoch 4 - Score: 0.8362\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [220/221] Elapsed 0m 35s (remain 0m 0s) Loss: 0.3451(0.5561) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 2 result ==========\n","Score: 0.8387\n","========== fold: 3 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2054] Elapsed 0m 0s (remain 27m 1s) Loss: 0.7883(0.7883) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/2054] Elapsed 0m 28s (remain 9m 10s) Loss: 0.7030(0.6464) Grad: 52238.8594  LR: 0.00001999  \n","Epoch: [1][200/2054] Elapsed 0m 56s (remain 8m 36s) Loss: 0.6287(0.6158) Grad: 35530.2461  LR: 0.00001997  \n","Epoch: [1][300/2054] Elapsed 1m 23s (remain 8m 6s) Loss: 0.5893(0.6008) Grad: 47578.1133  LR: 0.00001993  \n","Epoch: [1][400/2054] Elapsed 1m 51s (remain 7m 38s) Loss: 0.5621(0.5929) Grad: 29354.1797  LR: 0.00001988  \n","Epoch: [1][500/2054] Elapsed 2m 18s (remain 7m 10s) Loss: 0.5439(0.5842) Grad: 23151.3008  LR: 0.00001982  \n","Epoch: [1][600/2054] Elapsed 2m 46s (remain 6m 42s) Loss: 0.4102(0.5795) Grad: 44691.2031  LR: 0.00001974  \n","Epoch: [1][700/2054] Elapsed 3m 13s (remain 6m 14s) Loss: 0.5323(0.5752) Grad: 17261.1738  LR: 0.00001964  \n","Epoch: [1][800/2054] Elapsed 3m 41s (remain 5m 46s) Loss: 0.5280(0.5723) Grad: 61586.4688  LR: 0.00001953  \n","Epoch: [1][900/2054] Elapsed 4m 9s (remain 5m 18s) Loss: 0.5073(0.5700) Grad: 14393.3018  LR: 0.00001941  \n","Epoch: [1][1000/2054] Elapsed 4m 36s (remain 4m 51s) Loss: 0.5756(0.5681) Grad: 20422.0234  LR: 0.00001928  \n","Epoch: [1][1100/2054] Elapsed 5m 4s (remain 4m 23s) Loss: 0.4500(0.5652) Grad: 23978.6289  LR: 0.00001913  \n","Epoch: [1][1200/2054] Elapsed 5m 32s (remain 3m 56s) Loss: 0.4957(0.5640) Grad: 62829.1953  LR: 0.00001896  \n","Epoch: [1][1300/2054] Elapsed 6m 0s (remain 3m 28s) Loss: 0.5576(0.5628) Grad: 28101.0879  LR: 0.00001879  \n","Epoch: [1][1400/2054] Elapsed 6m 27s (remain 3m 0s) Loss: 0.5012(0.5618) Grad: 15714.9863  LR: 0.00001860  \n","Epoch: [1][1500/2054] Elapsed 6m 55s (remain 2m 32s) Loss: 0.4810(0.5611) Grad: 13560.7578  LR: 0.00001840  \n","Epoch: [1][1600/2054] Elapsed 7m 22s (remain 2m 5s) Loss: 0.4986(0.5596) Grad: 29279.8672  LR: 0.00001818  \n","Epoch: [1][1700/2054] Elapsed 7m 50s (remain 1m 37s) Loss: 0.5865(0.5581) Grad: 21885.6074  LR: 0.00001796  \n","Epoch: [1][1800/2054] Elapsed 8m 17s (remain 1m 9s) Loss: 0.4019(0.5577) Grad: 17503.4707  LR: 0.00001772  \n","Epoch: [1][1900/2054] Elapsed 8m 45s (remain 0m 42s) Loss: 0.5291(0.5573) Grad: 36112.8711  LR: 0.00001747  \n","Epoch: [1][2000/2054] Elapsed 9m 13s (remain 0m 14s) Loss: 0.7575(0.5566) Grad: 103326.2344  LR: 0.00001721  \n","Epoch: [1][2053/2054] Elapsed 9m 27s (remain 0m 0s) Loss: 0.5410(0.5563) Grad: 56423.1602  LR: 0.00001707  \n","EVAL: [0/226] Elapsed 0m 0s (remain 2m 31s) Loss: 0.6186(0.6186) \n","EVAL: [100/226] Elapsed 0m 16s (remain 0m 20s) Loss: 0.5607(0.5617) \n","EVAL: [200/226] Elapsed 0m 32s (remain 0m 4s) Loss: 0.6089(0.5523) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5563  avg_val_loss: 0.5514  time: 604s\n","Epoch 1 - Score: 0.8193\n","Epoch 1 - Save Best Score: 0.8193 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [225/226] Elapsed 0m 36s (remain 0m 0s) Loss: 0.7018(0.5514) \n","Epoch: [2][0/2054] Elapsed 0m 0s (remain 28m 48s) Loss: 0.6025(0.6025) Grad: 16130.6357  LR: 0.00001707  \n","Epoch: [2][100/2054] Elapsed 0m 29s (remain 9m 21s) Loss: 0.5492(0.5127) Grad: 24994.2129  LR: 0.00001679  \n","Epoch: [2][200/2054] Elapsed 0m 56s (remain 8m 44s) Loss: 0.4273(0.5137) Grad: 38651.8594  LR: 0.00001651  \n","Epoch: [2][300/2054] Elapsed 1m 24s (remain 8m 13s) Loss: 0.5958(0.5114) Grad: 60651.8906  LR: 0.00001621  \n","Epoch: [2][400/2054] Elapsed 1m 52s (remain 7m 43s) Loss: 0.5847(0.5132) Grad: 41173.6523  LR: 0.00001591  \n","Epoch: [2][500/2054] Elapsed 2m 20s (remain 7m 14s) Loss: 0.5357(0.5140) Grad: 122293.0000  LR: 0.00001560  \n","Epoch: [2][600/2054] Elapsed 2m 47s (remain 6m 45s) Loss: 0.4861(0.5151) Grad: 85067.4219  LR: 0.00001528  \n","Epoch: [2][700/2054] Elapsed 3m 15s (remain 6m 16s) Loss: 0.4464(0.5167) Grad: 61158.1172  LR: 0.00001495  \n","Epoch: [2][800/2054] Elapsed 3m 42s (remain 5m 48s) Loss: 0.5775(0.5165) Grad: 27127.6289  LR: 0.00001461  \n","Epoch: [2][900/2054] Elapsed 4m 10s (remain 5m 20s) Loss: 0.5556(0.5164) Grad: 16362.7314  LR: 0.00001427  \n","Epoch: [2][1000/2054] Elapsed 4m 37s (remain 4m 52s) Loss: 0.5210(0.5158) Grad: 34989.7695  LR: 0.00001392  \n","Epoch: [2][1100/2054] Elapsed 5m 5s (remain 4m 24s) Loss: 0.5181(0.5169) Grad: 50276.0195  LR: 0.00001357  \n","Epoch: [2][1200/2054] Elapsed 5m 33s (remain 3m 56s) Loss: 0.4710(0.5166) Grad: 35697.5586  LR: 0.00001321  \n","Epoch: [2][1300/2054] Elapsed 6m 0s (remain 3m 28s) Loss: 0.6213(0.5167) Grad: 36061.7383  LR: 0.00001284  \n","Epoch: [2][1400/2054] Elapsed 6m 28s (remain 3m 0s) Loss: 0.3506(0.5167) Grad: 43250.4531  LR: 0.00001247  \n","Epoch: [2][1500/2054] Elapsed 6m 55s (remain 2m 33s) Loss: 0.5232(0.5166) Grad: 33419.6914  LR: 0.00001210  \n","Epoch: [2][1600/2054] Elapsed 7m 23s (remain 2m 5s) Loss: 0.5776(0.5168) Grad: 45271.8125  LR: 0.00001173  \n","Epoch: [2][1700/2054] Elapsed 7m 51s (remain 1m 37s) Loss: 0.4824(0.5176) Grad: 29245.8750  LR: 0.00001135  \n","Epoch: [2][1800/2054] Elapsed 8m 18s (remain 1m 10s) Loss: 0.4250(0.5176) Grad: 31575.0312  LR: 0.00001097  \n","Epoch: [2][1900/2054] Elapsed 8m 46s (remain 0m 42s) Loss: 0.4813(0.5177) Grad: 46463.9375  LR: 0.00001059  \n","Epoch: [2][2000/2054] Elapsed 9m 13s (remain 0m 14s) Loss: 0.5264(0.5182) Grad: 50956.3438  LR: 0.00001020  \n","Epoch: [2][2053/2054] Elapsed 9m 28s (remain 0m 0s) Loss: 0.3939(0.5182) Grad: 54962.5938  LR: 0.00001000  \n","EVAL: [0/226] Elapsed 0m 0s (remain 2m 32s) Loss: 0.6187(0.6187) \n","EVAL: [100/226] Elapsed 0m 16s (remain 0m 20s) Loss: 0.5581(0.5663) \n","EVAL: [200/226] Elapsed 0m 32s (remain 0m 4s) Loss: 0.5664(0.5541) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5182  avg_val_loss: 0.5522  time: 605s\n","Epoch 2 - Score: 0.8286\n","Epoch 2 - Save Best Score: 0.8286 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [225/226] Elapsed 0m 36s (remain 0m 0s) Loss: 0.9688(0.5522) \n","Epoch: [3][0/2054] Elapsed 0m 0s (remain 29m 28s) Loss: 0.5892(0.5892) Grad: 91862.9141  LR: 0.00001000  \n","Epoch: [3][100/2054] Elapsed 0m 29s (remain 9m 26s) Loss: 0.5765(0.4939) Grad: 34473.0117  LR: 0.00000962  \n","Epoch: [3][200/2054] Elapsed 0m 57s (remain 8m 46s) Loss: 0.5231(0.5055) Grad: 42673.1328  LR: 0.00000923  \n","Epoch: [3][300/2054] Elapsed 1m 24s (remain 8m 13s) Loss: 0.4518(0.5028) Grad: 87830.8516  LR: 0.00000885  \n","Epoch: [3][400/2054] Elapsed 1m 52s (remain 7m 43s) Loss: 0.4383(0.5013) Grad: 57221.9688  LR: 0.00000847  \n","Epoch: [3][500/2054] Elapsed 2m 20s (remain 7m 14s) Loss: 0.4851(0.5026) Grad: 60532.4883  LR: 0.00000810  \n","Epoch: [3][600/2054] Elapsed 2m 47s (remain 6m 45s) Loss: 0.4812(0.5031) Grad: 38446.3984  LR: 0.00000772  \n","Epoch: [3][700/2054] Elapsed 3m 15s (remain 6m 17s) Loss: 0.5558(0.5041) Grad: 26751.3633  LR: 0.00000735  \n","Epoch: [3][800/2054] Elapsed 3m 43s (remain 5m 49s) Loss: 0.4023(0.5032) Grad: 44227.3242  LR: 0.00000699  \n","Epoch: [3][900/2054] Elapsed 4m 10s (remain 5m 21s) Loss: 0.4678(0.5037) Grad: 149655.9844  LR: 0.00000662  \n","Epoch: [3][1000/2054] Elapsed 4m 38s (remain 4m 52s) Loss: 0.5293(0.5036) Grad: 36196.5508  LR: 0.00000627  \n","Epoch: [3][1100/2054] Elapsed 5m 6s (remain 4m 25s) Loss: 0.5518(0.5036) Grad: 32847.9844  LR: 0.00000592  \n","Epoch: [3][1200/2054] Elapsed 5m 33s (remain 3m 57s) Loss: 0.5940(0.5029) Grad: 43557.3359  LR: 0.00000557  \n","Epoch: [3][1300/2054] Elapsed 6m 1s (remain 3m 29s) Loss: 0.5948(0.5030) Grad: 290158.2188  LR: 0.00000523  \n","Epoch: [3][1400/2054] Elapsed 6m 29s (remain 3m 1s) Loss: 0.5960(0.5031) Grad: 89822.0312  LR: 0.00000490  \n","Epoch: [3][1500/2054] Elapsed 6m 56s (remain 2m 33s) Loss: 0.3820(0.5025) Grad: 35802.2266  LR: 0.00000457  \n","Epoch: [3][1600/2054] Elapsed 7m 24s (remain 2m 5s) Loss: 0.4989(0.5022) Grad: 32979.4062  LR: 0.00000426  \n","Epoch: [3][1700/2054] Elapsed 7m 51s (remain 1m 37s) Loss: 0.4462(0.5023) Grad: 79558.6328  LR: 0.00000395  \n","Epoch: [3][1800/2054] Elapsed 8m 19s (remain 1m 10s) Loss: 0.6400(0.5024) Grad: 59724.9492  LR: 0.00000365  \n","Epoch: [3][1900/2054] Elapsed 8m 47s (remain 0m 42s) Loss: 0.4132(0.5023) Grad: 86628.7812  LR: 0.00000336  \n","Epoch: [3][2000/2054] Elapsed 9m 15s (remain 0m 14s) Loss: 0.5606(0.5019) Grad: 88938.7188  LR: 0.00000308  \n","Epoch: [3][2053/2054] Elapsed 9m 29s (remain 0m 0s) Loss: 0.4037(0.5019) Grad: 95190.7109  LR: 0.00000293  \n","EVAL: [0/226] Elapsed 0m 0s (remain 2m 32s) Loss: 0.5949(0.5949) \n","EVAL: [100/226] Elapsed 0m 16s (remain 0m 20s) Loss: 0.5528(0.5776) \n","EVAL: [200/226] Elapsed 0m 32s (remain 0m 4s) Loss: 0.7024(0.5668) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5019  avg_val_loss: 0.5654  time: 606s\n","Epoch 3 - Score: 0.8289\n","Epoch 3 - Save Best Score: 0.8289 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [225/226] Elapsed 0m 36s (remain 0m 0s) Loss: 1.0983(0.5654) \n","Epoch: [4][0/2054] Elapsed 0m 0s (remain 29m 24s) Loss: 0.5601(0.5601) Grad: 108445.7500  LR: 0.00000293  \n","Epoch: [4][100/2054] Elapsed 0m 28s (remain 9m 20s) Loss: 0.4389(0.4942) Grad: 102873.2578  LR: 0.00000266  \n","Epoch: [4][200/2054] Elapsed 0m 56s (remain 8m 44s) Loss: 0.5938(0.5005) Grad: 84893.9609  LR: 0.00000241  \n","Epoch: [4][300/2054] Elapsed 1m 24s (remain 8m 11s) Loss: 0.4485(0.4976) Grad: 89699.3281  LR: 0.00000217  \n","Epoch: [4][400/2054] Elapsed 1m 52s (remain 7m 42s) Loss: 0.5054(0.5001) Grad: 71424.5078  LR: 0.00000193  \n","Epoch: [4][500/2054] Elapsed 2m 19s (remain 7m 13s) Loss: 0.4146(0.5019) Grad: 105563.8125  LR: 0.00000171  \n","Epoch: [4][600/2054] Elapsed 2m 47s (remain 6m 44s) Loss: 0.4986(0.4993) Grad: 49411.0195  LR: 0.00000151  \n","Epoch: [4][700/2054] Elapsed 3m 14s (remain 6m 16s) Loss: 0.4826(0.4996) Grad: 35475.7031  LR: 0.00000131  \n","Epoch: [4][800/2054] Elapsed 3m 42s (remain 5m 48s) Loss: 0.4548(0.4981) Grad: 134277.2031  LR: 0.00000113  \n","Epoch: [4][900/2054] Elapsed 4m 10s (remain 5m 20s) Loss: 0.3896(0.4984) Grad: 136705.4062  LR: 0.00000096  \n","Epoch: [4][1000/2054] Elapsed 4m 37s (remain 4m 52s) Loss: 0.5874(0.4992) Grad: 148000.6562  LR: 0.00000080  \n","Epoch: [4][1100/2054] Elapsed 5m 5s (remain 4m 24s) Loss: 0.5159(0.4993) Grad: 81431.3047  LR: 0.00000066  \n","Epoch: [4][1200/2054] Elapsed 5m 33s (remain 3m 56s) Loss: 0.4218(0.4994) Grad: 57783.7969  LR: 0.00000053  \n","Epoch: [4][1300/2054] Elapsed 6m 1s (remain 3m 28s) Loss: 0.5163(0.4996) Grad: 48666.2812  LR: 0.00000041  \n","Epoch: [4][1400/2054] Elapsed 6m 28s (remain 3m 1s) Loss: 0.4905(0.4983) Grad: 121745.7344  LR: 0.00000031  \n","Epoch: [4][1500/2054] Elapsed 6m 56s (remain 2m 33s) Loss: 0.4678(0.4979) Grad: 113154.2344  LR: 0.00000022  \n","Epoch: [4][1600/2054] Elapsed 7m 24s (remain 2m 5s) Loss: 0.6518(0.4970) Grad: 134414.0938  LR: 0.00000015  \n","Epoch: [4][1700/2054] Elapsed 7m 51s (remain 1m 37s) Loss: 0.6333(0.4969) Grad: 1389864.8750  LR: 0.00000009  \n","Epoch: [4][1800/2054] Elapsed 8m 19s (remain 1m 10s) Loss: 0.5229(0.4971) Grad: 77251.8516  LR: 0.00000005  \n","Epoch: [4][1900/2054] Elapsed 8m 47s (remain 0m 42s) Loss: 0.5544(0.4964) Grad: 193794.7656  LR: 0.00000002  \n","Epoch: [4][2000/2054] Elapsed 9m 14s (remain 0m 14s) Loss: 0.5158(0.4963) Grad: 959245.4375  LR: 0.00000000  \n","Epoch: [4][2053/2054] Elapsed 9m 29s (remain 0m 0s) Loss: 0.5268(0.4962) Grad: 612640.0000  LR: 0.00000000  \n","EVAL: [0/226] Elapsed 0m 0s (remain 2m 30s) Loss: 0.5947(0.5947) \n","EVAL: [100/226] Elapsed 0m 16s (remain 0m 20s) Loss: 0.5538(0.5814) \n","EVAL: [200/226] Elapsed 0m 32s (remain 0m 4s) Loss: 0.7122(0.5708) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4962  avg_val_loss: 0.5696  time: 606s\n","Epoch 4 - Score: 0.8273\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [225/226] Elapsed 0m 36s (remain 0m 0s) Loss: 1.1263(0.5696) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 3 result ==========\n","Score: 0.8289\n","========== fold: 4 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2035] Elapsed 0m 0s (remain 26m 17s) Loss: 0.7740(0.7740) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/2035] Elapsed 0m 28s (remain 9m 4s) Loss: 0.5826(0.6328) Grad: 49742.8516  LR: 0.00001999  \n","Epoch: [1][200/2035] Elapsed 0m 56s (remain 8m 31s) Loss: 0.6364(0.6139) Grad: 31759.0820  LR: 0.00001997  \n","Epoch: [1][300/2035] Elapsed 1m 23s (remain 8m 1s) Loss: 0.4669(0.5952) Grad: 49291.9375  LR: 0.00001993  \n","Epoch: [1][400/2035] Elapsed 1m 51s (remain 7m 32s) Loss: 0.5874(0.5863) Grad: 17686.5996  LR: 0.00001988  \n","Epoch: [1][500/2035] Elapsed 2m 18s (remain 7m 4s) Loss: 0.5695(0.5815) Grad: 93566.5078  LR: 0.00001981  \n","Epoch: [1][600/2035] Elapsed 2m 46s (remain 6m 36s) Loss: 0.6328(0.5803) Grad: 29935.4785  LR: 0.00001973  \n","Epoch: [1][700/2035] Elapsed 3m 13s (remain 6m 8s) Loss: 0.4960(0.5765) Grad: 14550.7451  LR: 0.00001964  \n","Epoch: [1][800/2035] Elapsed 3m 41s (remain 5m 40s) Loss: 0.6011(0.5741) Grad: 14679.8496  LR: 0.00001953  \n","Epoch: [1][900/2035] Elapsed 4m 8s (remain 5m 13s) Loss: 0.6010(0.5722) Grad: 49254.2969  LR: 0.00001940  \n","Epoch: [1][1000/2035] Elapsed 4m 36s (remain 4m 45s) Loss: 0.5038(0.5704) Grad: 33559.4336  LR: 0.00001926  \n","Epoch: [1][1100/2035] Elapsed 5m 3s (remain 4m 17s) Loss: 0.6069(0.5687) Grad: 74665.4844  LR: 0.00001911  \n","Epoch: [1][1200/2035] Elapsed 5m 31s (remain 3m 50s) Loss: 0.4825(0.5666) Grad: 18240.9961  LR: 0.00001895  \n","Epoch: [1][1300/2035] Elapsed 5m 59s (remain 3m 22s) Loss: 0.5220(0.5642) Grad: 19701.2559  LR: 0.00001877  \n","Epoch: [1][1400/2035] Elapsed 6m 26s (remain 2m 54s) Loss: 0.5999(0.5630) Grad: 11665.9883  LR: 0.00001857  \n","Epoch: [1][1500/2035] Elapsed 6m 54s (remain 2m 27s) Loss: 0.5231(0.5619) Grad: 34861.2305  LR: 0.00001837  \n","Epoch: [1][1600/2035] Elapsed 7m 21s (remain 1m 59s) Loss: 0.6460(0.5611) Grad: 27923.1934  LR: 0.00001815  \n","Epoch: [1][1700/2035] Elapsed 7m 49s (remain 1m 32s) Loss: 0.3403(0.5601) Grad: 18006.2949  LR: 0.00001792  \n","Epoch: [1][1800/2035] Elapsed 8m 16s (remain 1m 4s) Loss: 0.7632(0.5591) Grad: 115995.0312  LR: 0.00001768  \n","Epoch: [1][1900/2035] Elapsed 8m 44s (remain 0m 36s) Loss: 0.4285(0.5579) Grad: 72760.3438  LR: 0.00001743  \n","Epoch: [1][2000/2035] Elapsed 9m 11s (remain 0m 9s) Loss: 0.5110(0.5568) Grad: 51216.5000  LR: 0.00001716  \n","Epoch: [1][2034/2035] Elapsed 9m 20s (remain 0m 0s) Loss: 0.4897(0.5567) Grad: 16911.6387  LR: 0.00001707  \n","EVAL: [0/244] Elapsed 0m 0s (remain 2m 39s) Loss: 0.6615(0.6615) \n","EVAL: [100/244] Elapsed 0m 16s (remain 0m 23s) Loss: 0.5815(0.5436) \n","EVAL: [200/244] Elapsed 0m 32s (remain 0m 6s) Loss: 0.5263(0.5389) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5567  avg_val_loss: 0.5419  time: 600s\n","Epoch 1 - Score: 0.8198\n","Epoch 1 - Save Best Score: 0.8198 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [243/244] Elapsed 0m 39s (remain 0m 0s) Loss: 0.5145(0.5419) \n","Epoch: [2][0/2035] Elapsed 0m 0s (remain 28m 34s) Loss: 0.5836(0.5836) Grad: 12673.7617  LR: 0.00001707  \n","Epoch: [2][100/2035] Elapsed 0m 29s (remain 9m 17s) Loss: 0.5534(0.5319) Grad: 21556.6699  LR: 0.00001679  \n","Epoch: [2][200/2035] Elapsed 0m 56s (remain 8m 37s) Loss: 0.5221(0.5304) Grad: 63523.1328  LR: 0.00001650  \n","Epoch: [2][300/2035] Elapsed 1m 24s (remain 8m 5s) Loss: 0.5081(0.5277) Grad: 29887.6289  LR: 0.00001621  \n","Epoch: [2][400/2035] Elapsed 1m 51s (remain 7m 36s) Loss: 0.5222(0.5261) Grad: 27627.8379  LR: 0.00001590  \n","Epoch: [2][500/2035] Elapsed 2m 19s (remain 7m 7s) Loss: 0.5676(0.5256) Grad: 29345.1074  LR: 0.00001558  \n","Epoch: [2][600/2035] Elapsed 2m 47s (remain 6m 38s) Loss: 0.4152(0.5241) Grad: 31284.0781  LR: 0.00001526  \n","Epoch: [2][700/2035] Elapsed 3m 14s (remain 6m 10s) Loss: 0.4700(0.5236) Grad: 45028.5508  LR: 0.00001493  \n","Epoch: [2][800/2035] Elapsed 3m 42s (remain 5m 42s) Loss: 0.5727(0.5229) Grad: 196466.7812  LR: 0.00001459  \n","Epoch: [2][900/2035] Elapsed 4m 9s (remain 5m 14s) Loss: 0.5228(0.5216) Grad: 24001.6758  LR: 0.00001424  \n","Epoch: [2][1000/2035] Elapsed 4m 37s (remain 4m 46s) Loss: 0.5426(0.5213) Grad: 32487.9766  LR: 0.00001389  \n","Epoch: [2][1100/2035] Elapsed 5m 4s (remain 4m 18s) Loss: 0.5976(0.5207) Grad: 57983.8750  LR: 0.00001353  \n","Epoch: [2][1200/2035] Elapsed 5m 32s (remain 3m 50s) Loss: 0.5066(0.5204) Grad: 39301.6562  LR: 0.00001317  \n","Epoch: [2][1300/2035] Elapsed 5m 59s (remain 3m 22s) Loss: 0.5909(0.5205) Grad: 46397.6992  LR: 0.00001280  \n","Epoch: [2][1400/2035] Elapsed 6m 27s (remain 2m 55s) Loss: 0.5918(0.5199) Grad: 72315.4922  LR: 0.00001243  \n","Epoch: [2][1500/2035] Elapsed 6m 54s (remain 2m 27s) Loss: 0.5118(0.5197) Grad: 13558.3789  LR: 0.00001205  \n","Epoch: [2][1600/2035] Elapsed 7m 22s (remain 1m 59s) Loss: 0.4355(0.5189) Grad: 13003.0869  LR: 0.00001167  \n","Epoch: [2][1700/2035] Elapsed 7m 49s (remain 1m 32s) Loss: 0.4511(0.5182) Grad: 9548.9131  LR: 0.00001129  \n","Epoch: [2][1800/2035] Elapsed 8m 17s (remain 1m 4s) Loss: 0.5181(0.5190) Grad: 19024.7520  LR: 0.00001091  \n","Epoch: [2][1900/2035] Elapsed 8m 44s (remain 0m 36s) Loss: 0.5300(0.5196) Grad: 32234.0703  LR: 0.00001052  \n","Epoch: [2][2000/2035] Elapsed 9m 12s (remain 0m 9s) Loss: 0.5600(0.5198) Grad: 7631.7754  LR: 0.00001014  \n","Epoch: [2][2034/2035] Elapsed 9m 21s (remain 0m 0s) Loss: 0.5259(0.5200) Grad: 16721.2090  LR: 0.00001000  \n","EVAL: [0/244] Elapsed 0m 0s (remain 2m 42s) Loss: 0.6879(0.6879) \n","EVAL: [100/244] Elapsed 0m 16s (remain 0m 23s) Loss: 0.5763(0.5564) \n","EVAL: [200/244] Elapsed 0m 32s (remain 0m 6s) Loss: 0.5351(0.5543) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5200  avg_val_loss: 0.5564  time: 601s\n","Epoch 2 - Score: 0.8244\n","Epoch 2 - Save Best Score: 0.8244 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [243/244] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4796(0.5564) \n","Epoch: [3][0/2035] Elapsed 0m 0s (remain 28m 54s) Loss: 0.5372(0.5372) Grad: 12780.4277  LR: 0.00001000  \n","Epoch: [3][100/2035] Elapsed 0m 28s (remain 9m 13s) Loss: 0.6688(0.4999) Grad: 24455.2734  LR: 0.00000961  \n","Epoch: [3][200/2035] Elapsed 0m 56s (remain 8m 39s) Loss: 0.5460(0.5082) Grad: 13157.0469  LR: 0.00000923  \n","Epoch: [3][300/2035] Elapsed 1m 24s (remain 8m 7s) Loss: 0.6776(0.5065) Grad: 23386.6406  LR: 0.00000885  \n","Epoch: [3][400/2035] Elapsed 1m 52s (remain 7m 37s) Loss: 0.5092(0.5037) Grad: 90965.4609  LR: 0.00000846  \n","Epoch: [3][500/2035] Elapsed 2m 19s (remain 7m 8s) Loss: 0.3705(0.5040) Grad: 23888.6543  LR: 0.00000808  \n","Epoch: [3][600/2035] Elapsed 2m 47s (remain 6m 39s) Loss: 0.4703(0.5048) Grad: 14394.9014  LR: 0.00000771  \n","Epoch: [3][700/2035] Elapsed 3m 15s (remain 6m 11s) Loss: 0.6351(0.5055) Grad: 80962.2891  LR: 0.00000733  \n","Epoch: [3][800/2035] Elapsed 3m 43s (remain 5m 43s) Loss: 0.4901(0.5060) Grad: 9374.0742  LR: 0.00000696  \n","Epoch: [3][900/2035] Elapsed 4m 10s (remain 5m 15s) Loss: 0.3714(0.5047) Grad: 40821.3242  LR: 0.00000660  \n","Epoch: [3][1000/2035] Elapsed 4m 38s (remain 4m 47s) Loss: 0.3815(0.5061) Grad: 18423.3789  LR: 0.00000624  \n","Epoch: [3][1100/2035] Elapsed 5m 6s (remain 4m 19s) Loss: 0.6211(0.5077) Grad: 7769.4424  LR: 0.00000588  \n","Epoch: [3][1200/2035] Elapsed 5m 33s (remain 3m 51s) Loss: 0.5441(0.5076) Grad: 17738.0039  LR: 0.00000553  \n","Epoch: [3][1300/2035] Elapsed 6m 1s (remain 3m 23s) Loss: 0.4582(0.5064) Grad: 19865.2305  LR: 0.00000519  \n","Epoch: [3][1400/2035] Elapsed 6m 29s (remain 2m 56s) Loss: 0.4398(0.5063) Grad: 5259.0308  LR: 0.00000486  \n","Epoch: [3][1500/2035] Elapsed 6m 56s (remain 2m 28s) Loss: 0.4594(0.5051) Grad: 13442.7646  LR: 0.00000453  \n","Epoch: [3][1600/2035] Elapsed 7m 24s (remain 2m 0s) Loss: 0.4876(0.5047) Grad: 15177.3174  LR: 0.00000421  \n","Epoch: [3][1700/2035] Elapsed 7m 52s (remain 1m 32s) Loss: 0.4516(0.5048) Grad: 18773.4453  LR: 0.00000390  \n","Epoch: [3][1800/2035] Elapsed 8m 19s (remain 1m 4s) Loss: 0.4832(0.5052) Grad: 7903.5083  LR: 0.00000360  \n","Epoch: [3][1900/2035] Elapsed 8m 47s (remain 0m 37s) Loss: 0.4468(0.5053) Grad: 20296.4492  LR: 0.00000331  \n","Epoch: [3][2000/2035] Elapsed 9m 15s (remain 0m 9s) Loss: 0.4520(0.5049) Grad: 78530.1484  LR: 0.00000303  \n","Epoch: [3][2034/2035] Elapsed 9m 24s (remain 0m 0s) Loss: 0.5617(0.5048) Grad: 10086.6758  LR: 0.00000293  \n","EVAL: [0/244] Elapsed 0m 0s (remain 2m 45s) Loss: 0.6803(0.6803) \n","EVAL: [100/244] Elapsed 0m 16s (remain 0m 23s) Loss: 0.5760(0.5721) \n","EVAL: [200/244] Elapsed 0m 32s (remain 0m 6s) Loss: 0.5114(0.5678) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5048  avg_val_loss: 0.5697  time: 604s\n","Epoch 3 - Score: 0.8246\n","Epoch 3 - Save Best Score: 0.8246 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [243/244] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4886(0.5697) \n","Epoch: [4][0/2035] Elapsed 0m 0s (remain 28m 29s) Loss: 0.5170(0.5170) Grad: 18161.2383  LR: 0.00000293  \n","Epoch: [4][100/2035] Elapsed 0m 29s (remain 9m 18s) Loss: 0.3258(0.4920) Grad: 12586.0215  LR: 0.00000266  \n","Epoch: [4][200/2035] Elapsed 0m 57s (remain 8m 40s) Loss: 0.4001(0.4893) Grad: 10475.6660  LR: 0.00000241  \n","Epoch: [4][300/2035] Elapsed 1m 24s (remain 8m 8s) Loss: 0.5880(0.4908) Grad: 21371.3281  LR: 0.00000216  \n","Epoch: [4][400/2035] Elapsed 1m 52s (remain 7m 38s) Loss: 0.5565(0.4895) Grad: 8873.5898  LR: 0.00000193  \n","Epoch: [4][500/2035] Elapsed 2m 20s (remain 7m 8s) Loss: 0.5058(0.4905) Grad: 12315.7900  LR: 0.00000171  \n","Epoch: [4][600/2035] Elapsed 2m 47s (remain 6m 40s) Loss: 0.5646(0.4918) Grad: 23430.0684  LR: 0.00000150  \n","Epoch: [4][700/2035] Elapsed 3m 15s (remain 6m 11s) Loss: 0.5875(0.4927) Grad: 10604.3066  LR: 0.00000130  \n","Epoch: [4][800/2035] Elapsed 3m 43s (remain 5m 43s) Loss: 0.4961(0.4922) Grad: 13693.5742  LR: 0.00000112  \n","Epoch: [4][900/2035] Elapsed 4m 10s (remain 5m 15s) Loss: 0.5296(0.4931) Grad: 25439.4980  LR: 0.00000095  \n","Epoch: [4][1000/2035] Elapsed 4m 38s (remain 4m 47s) Loss: 0.4021(0.4944) Grad: 877171.7500  LR: 0.00000079  \n","Epoch: [4][1100/2035] Elapsed 5m 6s (remain 4m 19s) Loss: 0.5578(0.4945) Grad: 27293.4277  LR: 0.00000065  \n","Epoch: [4][1200/2035] Elapsed 5m 34s (remain 3m 51s) Loss: 0.4844(0.4952) Grad: 15310.0596  LR: 0.00000052  \n","Epoch: [4][1300/2035] Elapsed 6m 1s (remain 3m 24s) Loss: 0.4186(0.4953) Grad: 13673.2021  LR: 0.00000040  \n","Epoch: [4][1400/2035] Elapsed 6m 29s (remain 2m 56s) Loss: 0.4969(0.4948) Grad: 81960.8750  LR: 0.00000030  \n","Epoch: [4][1500/2035] Elapsed 6m 57s (remain 2m 28s) Loss: 0.5242(0.4942) Grad: 23161.6211  LR: 0.00000021  \n","Epoch: [4][1600/2035] Elapsed 7m 24s (remain 2m 0s) Loss: 0.4722(0.4948) Grad: 85738.6328  LR: 0.00000014  \n","Epoch: [4][1700/2035] Elapsed 7m 52s (remain 1m 32s) Loss: 0.5128(0.4946) Grad: 34086.7031  LR: 0.00000008  \n","Epoch: [4][1800/2035] Elapsed 8m 20s (remain 1m 4s) Loss: 0.5969(0.4944) Grad: 21847.5664  LR: 0.00000004  \n","Epoch: [4][1900/2035] Elapsed 8m 47s (remain 0m 37s) Loss: 0.5846(0.4953) Grad: 16484.8672  LR: 0.00000001  \n","Epoch: [4][2000/2035] Elapsed 9m 15s (remain 0m 9s) Loss: 0.3720(0.4952) Grad: 122492.4453  LR: 0.00000000  \n","Epoch: [4][2034/2035] Elapsed 9m 24s (remain 0m 0s) Loss: 0.5571(0.4952) Grad: 38084.4922  LR: 0.00000000  \n","EVAL: [0/244] Elapsed 0m 0s (remain 2m 48s) Loss: 0.6881(0.6881) \n","EVAL: [100/244] Elapsed 0m 16s (remain 0m 23s) Loss: 0.5734(0.5781) \n","EVAL: [200/244] Elapsed 0m 32s (remain 0m 6s) Loss: 0.5065(0.5747) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4952  avg_val_loss: 0.5756  time: 605s\n","Epoch 4 - Score: 0.8233\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [243/244] Elapsed 0m 39s (remain 0m 0s) Loss: 0.5085(0.5756) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 4 result ==========\n","Score: 0.8246\n","========== fold: 5 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2059] Elapsed 0m 0s (remain 29m 15s) Loss: 0.6218(0.6218) Grad: 205380.3281  LR: 0.00002000  \n","Epoch: [1][100/2059] Elapsed 0m 28s (remain 9m 12s) Loss: 0.6294(0.6508) Grad: 21781.9590  LR: 0.00001999  \n","Epoch: [1][200/2059] Elapsed 0m 56s (remain 8m 39s) Loss: 0.6819(0.6271) Grad: 63512.9883  LR: 0.00001997  \n","Epoch: [1][300/2059] Elapsed 1m 23s (remain 8m 10s) Loss: 0.6019(0.6126) Grad: 28040.8281  LR: 0.00001993  \n","Epoch: [1][400/2059] Elapsed 1m 51s (remain 7m 41s) Loss: 0.6247(0.5998) Grad: 22204.2988  LR: 0.00001988  \n","Epoch: [1][500/2059] Elapsed 2m 19s (remain 7m 12s) Loss: 0.5656(0.5932) Grad: 27039.2383  LR: 0.00001982  \n","Epoch: [1][600/2059] Elapsed 2m 46s (remain 6m 44s) Loss: 0.4796(0.5861) Grad: 19886.3555  LR: 0.00001974  \n","Epoch: [1][700/2059] Elapsed 3m 14s (remain 6m 16s) Loss: 0.6248(0.5830) Grad: 166004.0781  LR: 0.00001964  \n","Epoch: [1][800/2059] Elapsed 3m 42s (remain 5m 48s) Loss: 0.5021(0.5814) Grad: 2659.0642  LR: 0.00001954  \n","Epoch: [1][900/2059] Elapsed 4m 9s (remain 5m 20s) Loss: 0.3945(0.5819) Grad: 1282.2384  LR: 0.00001942  \n","Epoch: [1][1000/2059] Elapsed 4m 37s (remain 4m 53s) Loss: 0.5854(0.5794) Grad: 3241.3652  LR: 0.00001928  \n","Epoch: [1][1100/2059] Elapsed 5m 5s (remain 4m 25s) Loss: 0.4944(0.5783) Grad: 2826.8000  LR: 0.00001913  \n","Epoch: [1][1200/2059] Elapsed 5m 32s (remain 3m 57s) Loss: 0.5431(0.5767) Grad: 1593.9729  LR: 0.00001897  \n","Epoch: [1][1300/2059] Elapsed 6m 0s (remain 3m 30s) Loss: 0.5369(0.5753) Grad: 1736.7748  LR: 0.00001879  \n","Epoch: [1][1400/2059] Elapsed 6m 28s (remain 3m 2s) Loss: 0.5960(0.5739) Grad: 2713.6235  LR: 0.00001861  \n","Epoch: [1][1500/2059] Elapsed 6m 55s (remain 2m 34s) Loss: 0.7851(0.5721) Grad: 7684.2021  LR: 0.00001841  \n","Epoch: [1][1600/2059] Elapsed 7m 23s (remain 2m 6s) Loss: 0.5904(0.5712) Grad: 556.7212  LR: 0.00001819  \n","Epoch: [1][1700/2059] Elapsed 7m 51s (remain 1m 39s) Loss: 0.4727(0.5696) Grad: 2253.7747  LR: 0.00001797  \n","Epoch: [1][1800/2059] Elapsed 8m 18s (remain 1m 11s) Loss: 0.4893(0.5689) Grad: 979.3171  LR: 0.00001773  \n","Epoch: [1][1900/2059] Elapsed 8m 46s (remain 0m 43s) Loss: 0.6180(0.5679) Grad: 2933.8997  LR: 0.00001749  \n","Epoch: [1][2000/2059] Elapsed 9m 13s (remain 0m 16s) Loss: 0.5624(0.5667) Grad: 2653.3821  LR: 0.00001723  \n","Epoch: [1][2058/2059] Elapsed 9m 29s (remain 0m 0s) Loss: 0.4524(0.5662) Grad: 987.7833  LR: 0.00001707  \n","EVAL: [0/220] Elapsed 0m 0s (remain 2m 24s) Loss: 0.5829(0.5829) \n","EVAL: [100/220] Elapsed 0m 16s (remain 0m 19s) Loss: 0.5866(0.5511) \n","EVAL: [200/220] Elapsed 0m 32s (remain 0m 3s) Loss: 0.4057(0.5477) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5662  avg_val_loss: 0.5464  time: 606s\n","Epoch 1 - Score: 0.8007\n","Epoch 1 - Save Best Score: 0.8007 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [219/220] Elapsed 0m 35s (remain 0m 0s) Loss: 0.4391(0.5464) \n","Epoch: [2][0/2059] Elapsed 0m 0s (remain 28m 44s) Loss: 0.5658(0.5658) Grad: 542.1802  LR: 0.00001707  \n","Epoch: [2][100/2059] Elapsed 0m 28s (remain 9m 22s) Loss: 0.5242(0.5250) Grad: 914.7444  LR: 0.00001680  \n","Epoch: [2][200/2059] Elapsed 0m 56s (remain 8m 45s) Loss: 0.5992(0.5271) Grad: 623.7129  LR: 0.00001651  \n","Epoch: [2][300/2059] Elapsed 1m 24s (remain 8m 14s) Loss: 0.5288(0.5241) Grad: 2418.9536  LR: 0.00001622  \n","Epoch: [2][400/2059] Elapsed 1m 52s (remain 7m 44s) Loss: 0.6922(0.5234) Grad: 1442.2396  LR: 0.00001591  \n","Epoch: [2][500/2059] Elapsed 2m 19s (remain 7m 15s) Loss: 0.5922(0.5239) Grad: 1653.3060  LR: 0.00001560  \n","Epoch: [2][600/2059] Elapsed 2m 47s (remain 6m 46s) Loss: 0.5309(0.5242) Grad: 1284.7010  LR: 0.00001528  \n","Epoch: [2][700/2059] Elapsed 3m 15s (remain 6m 18s) Loss: 0.5260(0.5224) Grad: 5037.7251  LR: 0.00001495  \n","Epoch: [2][800/2059] Elapsed 3m 43s (remain 5m 50s) Loss: 0.4316(0.5231) Grad: 1202.7515  LR: 0.00001462  \n","Epoch: [2][900/2059] Elapsed 4m 10s (remain 5m 22s) Loss: 0.5236(0.5242) Grad: 3588.9768  LR: 0.00001428  \n","Epoch: [2][1000/2059] Elapsed 4m 38s (remain 4m 54s) Loss: 0.6281(0.5241) Grad: 1785.6472  LR: 0.00001393  \n","Epoch: [2][1100/2059] Elapsed 5m 5s (remain 4m 26s) Loss: 0.5765(0.5237) Grad: 964.3355  LR: 0.00001358  \n","Epoch: [2][1200/2059] Elapsed 5m 33s (remain 3m 58s) Loss: 0.5563(0.5229) Grad: 10506.4795  LR: 0.00001322  \n","Epoch: [2][1300/2059] Elapsed 6m 1s (remain 3m 30s) Loss: 0.4327(0.5228) Grad: 1117.8896  LR: 0.00001286  \n","Epoch: [2][1400/2059] Elapsed 6m 28s (remain 3m 2s) Loss: 0.4718(0.5227) Grad: 1356.0638  LR: 0.00001249  \n","Epoch: [2][1500/2059] Elapsed 6m 56s (remain 2m 34s) Loss: 0.5157(0.5227) Grad: 5504.6743  LR: 0.00001212  \n","Epoch: [2][1600/2059] Elapsed 7m 24s (remain 2m 7s) Loss: 0.4834(0.5226) Grad: 1512.0883  LR: 0.00001174  \n","Epoch: [2][1700/2059] Elapsed 7m 52s (remain 1m 39s) Loss: 0.4603(0.5224) Grad: 2392.3840  LR: 0.00001137  \n","Epoch: [2][1800/2059] Elapsed 8m 19s (remain 1m 11s) Loss: 0.5403(0.5226) Grad: 2330.5015  LR: 0.00001099  \n","Epoch: [2][1900/2059] Elapsed 8m 47s (remain 0m 43s) Loss: 0.5341(0.5226) Grad: 1416.0049  LR: 0.00001061  \n","Epoch: [2][2000/2059] Elapsed 9m 15s (remain 0m 16s) Loss: 0.4278(0.5224) Grad: 3591.3015  LR: 0.00001023  \n","Epoch: [2][2058/2059] Elapsed 9m 31s (remain 0m 0s) Loss: 0.6380(0.5225) Grad: 1605.7416  LR: 0.00001001  \n","EVAL: [0/220] Elapsed 0m 0s (remain 2m 28s) Loss: 0.6043(0.6043) \n","EVAL: [100/220] Elapsed 0m 16s (remain 0m 19s) Loss: 0.5729(0.5550) \n","EVAL: [200/220] Elapsed 0m 32s (remain 0m 3s) Loss: 0.3574(0.5547) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5225  avg_val_loss: 0.5557  time: 607s\n","Epoch 2 - Score: 0.8110\n","Epoch 2 - Save Best Score: 0.8110 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [219/220] Elapsed 0m 35s (remain 0m 0s) Loss: 0.4188(0.5557) \n","Epoch: [3][0/2059] Elapsed 0m 0s (remain 30m 8s) Loss: 0.4881(0.4881) Grad: 1421.1976  LR: 0.00001000  \n","Epoch: [3][100/2059] Elapsed 0m 29s (remain 9m 26s) Loss: 0.4255(0.5043) Grad: 1290.9913  LR: 0.00000962  \n","Epoch: [3][200/2059] Elapsed 0m 57s (remain 8m 48s) Loss: 0.3973(0.5047) Grad: 438.3871  LR: 0.00000924  \n","Epoch: [3][300/2059] Elapsed 1m 24s (remain 8m 15s) Loss: 0.5329(0.5033) Grad: 869.6011  LR: 0.00000886  \n","Epoch: [3][400/2059] Elapsed 1m 52s (remain 7m 45s) Loss: 0.5369(0.5036) Grad: 1438.9348  LR: 0.00000848  \n","Epoch: [3][500/2059] Elapsed 2m 20s (remain 7m 15s) Loss: 0.6348(0.5064) Grad: 4332.4048  LR: 0.00000811  \n","Epoch: [3][600/2059] Elapsed 2m 47s (remain 6m 47s) Loss: 0.5586(0.5061) Grad: 899.5390  LR: 0.00000773  \n","Epoch: [3][700/2059] Elapsed 3m 15s (remain 6m 18s) Loss: 0.4693(0.5066) Grad: 3871.6685  LR: 0.00000736  \n","Epoch: [3][800/2059] Elapsed 3m 43s (remain 5m 50s) Loss: 0.5263(0.5062) Grad: 2514.6704  LR: 0.00000700  \n","Epoch: [3][900/2059] Elapsed 4m 11s (remain 5m 22s) Loss: 0.5712(0.5048) Grad: 1568.9437  LR: 0.00000664  \n","Epoch: [3][1000/2059] Elapsed 4m 38s (remain 4m 54s) Loss: 0.4670(0.5048) Grad: 3635.7178  LR: 0.00000628  \n","Epoch: [3][1100/2059] Elapsed 5m 6s (remain 4m 26s) Loss: 0.5486(0.5041) Grad: 4129.3169  LR: 0.00000593  \n","Epoch: [3][1200/2059] Elapsed 5m 34s (remain 3m 58s) Loss: 0.5016(0.5038) Grad: 19615.9355  LR: 0.00000558  \n","Epoch: [3][1300/2059] Elapsed 6m 1s (remain 3m 30s) Loss: 0.5015(0.5038) Grad: 2690.3096  LR: 0.00000525  \n","Epoch: [3][1400/2059] Elapsed 6m 29s (remain 3m 2s) Loss: 0.4351(0.5036) Grad: 2209.3667  LR: 0.00000491  \n","Epoch: [3][1500/2059] Elapsed 6m 57s (remain 2m 35s) Loss: 0.4609(0.5039) Grad: 2803.6743  LR: 0.00000459  \n","Epoch: [3][1600/2059] Elapsed 7m 24s (remain 2m 7s) Loss: 0.5308(0.5037) Grad: 4022.7073  LR: 0.00000427  \n","Epoch: [3][1700/2059] Elapsed 7m 52s (remain 1m 39s) Loss: 0.3737(0.5037) Grad: 2444.1863  LR: 0.00000396  \n","Epoch: [3][1800/2059] Elapsed 8m 20s (remain 1m 11s) Loss: 0.4933(0.5032) Grad: 2746.3384  LR: 0.00000366  \n","Epoch: [3][1900/2059] Elapsed 8m 47s (remain 0m 43s) Loss: 0.5231(0.5033) Grad: 3920.3765  LR: 0.00000337  \n","Epoch: [3][2000/2059] Elapsed 9m 15s (remain 0m 16s) Loss: 0.5290(0.5038) Grad: 25864.4805  LR: 0.00000309  \n","Epoch: [3][2058/2059] Elapsed 9m 31s (remain 0m 0s) Loss: 0.3112(0.5036) Grad: 3571.7969  LR: 0.00000294  \n","EVAL: [0/220] Elapsed 0m 0s (remain 2m 28s) Loss: 0.7194(0.7194) \n","EVAL: [100/220] Elapsed 0m 16s (remain 0m 19s) Loss: 0.5786(0.5623) \n","EVAL: [200/220] Elapsed 0m 32s (remain 0m 3s) Loss: 0.3371(0.5671) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5036  avg_val_loss: 0.5691  time: 608s\n","Epoch 3 - Score: 0.8127\n","Epoch 3 - Save Best Score: 0.8127 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [219/220] Elapsed 0m 35s (remain 0m 0s) Loss: 0.4078(0.5691) \n","Epoch: [4][0/2059] Elapsed 0m 0s (remain 30m 11s) Loss: 0.5095(0.5095) Grad: 3749.8042  LR: 0.00000293  \n","Epoch: [4][100/2059] Elapsed 0m 29s (remain 9m 25s) Loss: 0.4470(0.4982) Grad: 1861.1486  LR: 0.00000267  \n","Epoch: [4][200/2059] Elapsed 0m 57s (remain 8m 48s) Loss: 0.4521(0.5006) Grad: 1582.5245  LR: 0.00000241  \n","Epoch: [4][300/2059] Elapsed 1m 24s (remain 8m 15s) Loss: 0.3860(0.5019) Grad: 2271.4382  LR: 0.00000217  \n","Epoch: [4][400/2059] Elapsed 1m 52s (remain 7m 45s) Loss: 0.4395(0.5013) Grad: 1877.8391  LR: 0.00000194  \n","Epoch: [4][500/2059] Elapsed 2m 20s (remain 7m 16s) Loss: 0.5592(0.5006) Grad: 1772.1179  LR: 0.00000172  \n","Epoch: [4][600/2059] Elapsed 2m 47s (remain 6m 47s) Loss: 0.3871(0.5004) Grad: 1872.7692  LR: 0.00000151  \n","Epoch: [4][700/2059] Elapsed 3m 15s (remain 6m 18s) Loss: 0.5155(0.4996) Grad: 2978.3066  LR: 0.00000132  \n","Epoch: [4][800/2059] Elapsed 3m 43s (remain 5m 50s) Loss: 0.4382(0.4991) Grad: 2716.8604  LR: 0.00000113  \n","Epoch: [4][900/2059] Elapsed 4m 10s (remain 5m 22s) Loss: 0.4019(0.4992) Grad: 3410.4004  LR: 0.00000096  \n","Epoch: [4][1000/2059] Elapsed 4m 38s (remain 4m 54s) Loss: 0.6614(0.4995) Grad: 5591.5298  LR: 0.00000081  \n","Epoch: [4][1100/2059] Elapsed 5m 6s (remain 4m 26s) Loss: 0.4236(0.4990) Grad: 2508.0964  LR: 0.00000066  \n","Epoch: [4][1200/2059] Elapsed 5m 34s (remain 3m 58s) Loss: 0.5277(0.4992) Grad: 6578.0205  LR: 0.00000053  \n","Epoch: [4][1300/2059] Elapsed 6m 1s (remain 3m 30s) Loss: 0.5534(0.4977) Grad: 5567.5039  LR: 0.00000042  \n","Epoch: [4][1400/2059] Elapsed 6m 29s (remain 3m 2s) Loss: 0.4946(0.4958) Grad: 4475.7676  LR: 0.00000032  \n","Epoch: [4][1500/2059] Elapsed 6m 56s (remain 2m 34s) Loss: 0.5165(0.4951) Grad: 13950.4326  LR: 0.00000023  \n","Epoch: [4][1600/2059] Elapsed 7m 24s (remain 2m 7s) Loss: 0.4970(0.4956) Grad: 7495.1113  LR: 0.00000015  \n","Epoch: [4][1700/2059] Elapsed 7m 52s (remain 1m 39s) Loss: 0.4459(0.4950) Grad: 5563.8755  LR: 0.00000009  \n","Epoch: [4][1800/2059] Elapsed 8m 19s (remain 1m 11s) Loss: 0.4323(0.4946) Grad: 2829.6890  LR: 0.00000005  \n","Epoch: [4][1900/2059] Elapsed 8m 47s (remain 0m 43s) Loss: 0.5647(0.4946) Grad: 42791.2188  LR: 0.00000002  \n","Epoch: [4][2000/2059] Elapsed 9m 14s (remain 0m 16s) Loss: 0.5265(0.4952) Grad: 5915.7905  LR: 0.00000000  \n","Epoch: [4][2058/2059] Elapsed 9m 30s (remain 0m 0s) Loss: 0.6342(0.4952) Grad: 58652.0117  LR: 0.00000000  \n","EVAL: [0/220] Elapsed 0m 0s (remain 2m 26s) Loss: 0.6581(0.6581) \n","EVAL: [100/220] Elapsed 0m 16s (remain 0m 19s) Loss: 0.5705(0.5687) \n","EVAL: [200/220] Elapsed 0m 32s (remain 0m 3s) Loss: 0.3423(0.5747) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4952  avg_val_loss: 0.5779  time: 607s\n","Epoch 4 - Score: 0.8127\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [219/220] Elapsed 0m 35s (remain 0m 0s) Loss: 0.4078(0.5779) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 5 result ==========\n","Score: 0.8127\n","========== fold: 6 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2051] Elapsed 0m 0s (remain 29m 53s) Loss: 0.5647(0.5647) Grad: 130109.9609  LR: 0.00002000  \n","Epoch: [1][100/2051] Elapsed 0m 28s (remain 9m 11s) Loss: 0.5491(0.6311) Grad: 125269.2500  LR: 0.00001999  \n","Epoch: [1][200/2051] Elapsed 0m 56s (remain 8m 37s) Loss: 0.5195(0.6023) Grad: 56412.0742  LR: 0.00001997  \n","Epoch: [1][300/2051] Elapsed 1m 23s (remain 8m 7s) Loss: 0.4428(0.5918) Grad: 46299.7734  LR: 0.00001993  \n","Epoch: [1][400/2051] Elapsed 1m 51s (remain 7m 38s) Loss: 0.5864(0.5882) Grad: 47212.0977  LR: 0.00001988  \n","Epoch: [1][500/2051] Elapsed 2m 19s (remain 7m 10s) Loss: 0.5229(0.5832) Grad: 66444.3359  LR: 0.00001982  \n","Epoch: [1][600/2051] Elapsed 2m 46s (remain 6m 42s) Loss: 0.6342(0.5803) Grad: 91536.0156  LR: 0.00001974  \n","Epoch: [1][700/2051] Elapsed 3m 14s (remain 6m 14s) Loss: 0.5431(0.5776) Grad: 55217.0938  LR: 0.00001964  \n","Epoch: [1][800/2051] Elapsed 3m 42s (remain 5m 46s) Loss: 0.5767(0.5743) Grad: 110633.9609  LR: 0.00001953  \n","Epoch: [1][900/2051] Elapsed 4m 9s (remain 5m 18s) Loss: 0.6383(0.5713) Grad: 65993.0000  LR: 0.00001941  \n","Epoch: [1][1000/2051] Elapsed 4m 37s (remain 4m 51s) Loss: 0.5507(0.5691) Grad: 30847.8770  LR: 0.00001927  \n","Epoch: [1][1100/2051] Elapsed 5m 5s (remain 4m 23s) Loss: 0.5821(0.5665) Grad: 107082.6641  LR: 0.00001912  \n","Epoch: [1][1200/2051] Elapsed 5m 33s (remain 3m 55s) Loss: 0.4786(0.5649) Grad: 236136.4219  LR: 0.00001896  \n","Epoch: [1][1300/2051] Elapsed 6m 0s (remain 3m 27s) Loss: 0.5497(0.5633) Grad: 45755.9258  LR: 0.00001879  \n","Epoch: [1][1400/2051] Elapsed 6m 28s (remain 3m 0s) Loss: 0.4515(0.5611) Grad: 25139.4551  LR: 0.00001860  \n","Epoch: [1][1500/2051] Elapsed 6m 55s (remain 2m 32s) Loss: 0.5798(0.5602) Grad: 49021.4844  LR: 0.00001839  \n","Epoch: [1][1600/2051] Elapsed 7m 23s (remain 2m 4s) Loss: 0.5324(0.5590) Grad: 125776.7891  LR: 0.00001818  \n","Epoch: [1][1700/2051] Elapsed 7m 51s (remain 1m 36s) Loss: 0.4789(0.5580) Grad: 33337.5781  LR: 0.00001795  \n","Epoch: [1][1800/2051] Elapsed 8m 18s (remain 1m 9s) Loss: 0.5653(0.5570) Grad: 78730.1875  LR: 0.00001772  \n","Epoch: [1][1900/2051] Elapsed 8m 46s (remain 0m 41s) Loss: 0.4780(0.5560) Grad: 33485.2422  LR: 0.00001747  \n","Epoch: [1][2000/2051] Elapsed 9m 14s (remain 0m 13s) Loss: 0.4950(0.5544) Grad: 24010.9277  LR: 0.00001721  \n","Epoch: [1][2050/2051] Elapsed 9m 28s (remain 0m 0s) Loss: 0.6128(0.5543) Grad: 290158.8750  LR: 0.00001707  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 31s) Loss: 0.5039(0.5039) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 20s) Loss: 0.4929(0.5482) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.5873(0.5507) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5543  avg_val_loss: 0.5501  time: 605s\n","Epoch 1 - Score: 0.8244\n","Epoch 1 - Save Best Score: 0.8244 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.6902(0.5501) \n","Epoch: [2][0/2051] Elapsed 0m 0s (remain 29m 10s) Loss: 0.3665(0.3665) Grad: 43244.9844  LR: 0.00001707  \n","Epoch: [2][100/2051] Elapsed 0m 29s (remain 9m 37s) Loss: 0.5839(0.5262) Grad: 56787.3203  LR: 0.00001679  \n","Epoch: [2][200/2051] Elapsed 0m 57s (remain 8m 52s) Loss: 0.5815(0.5242) Grad: 65217.7656  LR: 0.00001651  \n","Epoch: [2][300/2051] Elapsed 1m 25s (remain 8m 16s) Loss: 0.4710(0.5226) Grad: 75782.0156  LR: 0.00001621  \n","Epoch: [2][400/2051] Elapsed 1m 53s (remain 7m 47s) Loss: 0.5607(0.5211) Grad: 33970.1250  LR: 0.00001591  \n","Epoch: [2][500/2051] Elapsed 2m 21s (remain 7m 17s) Loss: 0.4817(0.5187) Grad: 35076.5000  LR: 0.00001560  \n","Epoch: [2][600/2051] Elapsed 2m 49s (remain 6m 47s) Loss: 0.4052(0.5181) Grad: 125053.4688  LR: 0.00001527  \n","Epoch: [2][700/2051] Elapsed 3m 16s (remain 6m 19s) Loss: 0.5238(0.5181) Grad: 67015.7188  LR: 0.00001494  \n","Epoch: [2][800/2051] Elapsed 3m 44s (remain 5m 50s) Loss: 0.6109(0.5173) Grad: 64239.9688  LR: 0.00001461  \n","Epoch: [2][900/2051] Elapsed 4m 12s (remain 5m 22s) Loss: 0.4245(0.5173) Grad: 53958.1719  LR: 0.00001427  \n","Epoch: [2][1000/2051] Elapsed 4m 40s (remain 4m 53s) Loss: 0.5119(0.5175) Grad: 37079.7227  LR: 0.00001392  \n","Epoch: [2][1100/2051] Elapsed 5m 7s (remain 4m 25s) Loss: 0.3543(0.5169) Grad: 67163.5625  LR: 0.00001356  \n","Epoch: [2][1200/2051] Elapsed 5m 35s (remain 3m 57s) Loss: 0.3902(0.5180) Grad: 109077.3594  LR: 0.00001320  \n","Epoch: [2][1300/2051] Elapsed 6m 3s (remain 3m 29s) Loss: 0.5985(0.5179) Grad: 81868.4375  LR: 0.00001284  \n","Epoch: [2][1400/2051] Elapsed 6m 31s (remain 3m 1s) Loss: 0.5635(0.5176) Grad: 100716.6328  LR: 0.00001247  \n","Epoch: [2][1500/2051] Elapsed 6m 59s (remain 2m 33s) Loss: 0.5942(0.5180) Grad: 176080.8125  LR: 0.00001209  \n","Epoch: [2][1600/2051] Elapsed 7m 27s (remain 2m 5s) Loss: 0.5824(0.5181) Grad: 46994.4961  LR: 0.00001172  \n","Epoch: [2][1700/2051] Elapsed 7m 54s (remain 1m 37s) Loss: 0.5192(0.5173) Grad: 56481.4219  LR: 0.00001134  \n","Epoch: [2][1800/2051] Elapsed 8m 22s (remain 1m 9s) Loss: 0.3236(0.5166) Grad: 197648.9688  LR: 0.00001096  \n","Epoch: [2][1900/2051] Elapsed 8m 50s (remain 0m 41s) Loss: 0.4461(0.5168) Grad: 248002.9688  LR: 0.00001058  \n","Epoch: [2][2000/2051] Elapsed 9m 18s (remain 0m 13s) Loss: 0.5816(0.5169) Grad: 126109.7578  LR: 0.00001020  \n","Epoch: [2][2050/2051] Elapsed 9m 32s (remain 0m 0s) Loss: 0.4923(0.5168) Grad: 114825.3516  LR: 0.00001000  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 38s) Loss: 0.5275(0.5275) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 21s) Loss: 0.4564(0.5430) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.5852(0.5439) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5168  avg_val_loss: 0.5428  time: 609s\n","Epoch 2 - Score: 0.8400\n","Epoch 2 - Save Best Score: 0.8400 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 37s (remain 0m 0s) Loss: 0.6419(0.5428) \n","Epoch: [3][0/2051] Elapsed 0m 0s (remain 29m 43s) Loss: 0.5129(0.5129) Grad: 54993.8672  LR: 0.00001000  \n","Epoch: [3][100/2051] Elapsed 0m 28s (remain 9m 18s) Loss: 0.5808(0.4945) Grad: 474053.0312  LR: 0.00000962  \n","Epoch: [3][200/2051] Elapsed 0m 56s (remain 8m 44s) Loss: 0.4485(0.4918) Grad: 183047.4375  LR: 0.00000924  \n","Epoch: [3][300/2051] Elapsed 1m 24s (remain 8m 12s) Loss: 0.4063(0.4967) Grad: 338802.2188  LR: 0.00000885  \n","Epoch: [3][400/2051] Elapsed 1m 52s (remain 7m 42s) Loss: 0.6116(0.5006) Grad: 114073.3359  LR: 0.00000847  \n","Epoch: [3][500/2051] Elapsed 2m 19s (remain 7m 13s) Loss: 0.4514(0.5028) Grad: 105172.2656  LR: 0.00000810  \n","Epoch: [3][600/2051] Elapsed 2m 47s (remain 6m 44s) Loss: 0.5457(0.5033) Grad: 319429.3125  LR: 0.00000772  \n","Epoch: [3][700/2051] Elapsed 3m 15s (remain 6m 16s) Loss: 0.6416(0.5042) Grad: 193735.2969  LR: 0.00000735  \n","Epoch: [3][800/2051] Elapsed 3m 43s (remain 5m 48s) Loss: 0.5885(0.5056) Grad: 235283.4062  LR: 0.00000698  \n","Epoch: [3][900/2051] Elapsed 4m 10s (remain 5m 20s) Loss: 0.3898(0.5056) Grad: 114484.4297  LR: 0.00000662  \n","Epoch: [3][1000/2051] Elapsed 4m 38s (remain 4m 52s) Loss: 0.4928(0.5052) Grad: 165926.4375  LR: 0.00000626  \n","Epoch: [3][1100/2051] Elapsed 5m 6s (remain 4m 24s) Loss: 0.5698(0.5042) Grad: 468723.7812  LR: 0.00000591  \n","Epoch: [3][1200/2051] Elapsed 5m 33s (remain 3m 56s) Loss: 0.4642(0.5035) Grad: 154969.5938  LR: 0.00000557  \n","Epoch: [3][1300/2051] Elapsed 6m 1s (remain 3m 28s) Loss: 0.5429(0.5034) Grad: 85763.3281  LR: 0.00000523  \n","Epoch: [3][1400/2051] Elapsed 6m 29s (remain 3m 0s) Loss: 0.4042(0.5029) Grad: 436124.1875  LR: 0.00000489  \n","Epoch: [3][1500/2051] Elapsed 6m 56s (remain 2m 32s) Loss: 0.4358(0.5023) Grad: 86443.9297  LR: 0.00000457  \n","Epoch: [3][1600/2051] Elapsed 7m 24s (remain 2m 4s) Loss: 0.4916(0.5021) Grad: 176742.9531  LR: 0.00000425  \n","Epoch: [3][1700/2051] Elapsed 7m 52s (remain 1m 37s) Loss: 0.5832(0.5024) Grad: 60785.2578  LR: 0.00000394  \n","Epoch: [3][1800/2051] Elapsed 8m 19s (remain 1m 9s) Loss: 0.5886(0.5024) Grad: 318634.7500  LR: 0.00000364  \n","Epoch: [3][1900/2051] Elapsed 8m 47s (remain 0m 41s) Loss: 0.6801(0.5028) Grad: 114769.5312  LR: 0.00000335  \n","Epoch: [3][2000/2051] Elapsed 9m 15s (remain 0m 13s) Loss: 0.5550(0.5028) Grad: 96523.4219  LR: 0.00000307  \n","Epoch: [3][2050/2051] Elapsed 9m 29s (remain 0m 0s) Loss: 0.5077(0.5030) Grad: 141018.3750  LR: 0.00000293  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 37s) Loss: 0.5189(0.5189) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 20s) Loss: 0.4538(0.5495) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.5826(0.5535) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5030  avg_val_loss: 0.5523  time: 606s\n","Epoch 3 - Score: 0.8363\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.6488(0.5523) \n","Epoch: [4][0/2051] Elapsed 0m 0s (remain 29m 27s) Loss: 0.4486(0.4486) Grad: 54852.0469  LR: 0.00000293  \n","Epoch: [4][100/2051] Elapsed 0m 28s (remain 9m 13s) Loss: 0.5140(0.5016) Grad: 752298.0625  LR: 0.00000266  \n","Epoch: [4][200/2051] Elapsed 0m 56s (remain 8m 39s) Loss: 0.5385(0.5042) Grad: 503940.1875  LR: 0.00000241  \n","Epoch: [4][300/2051] Elapsed 1m 24s (remain 8m 9s) Loss: 0.4322(0.5004) Grad: 134228.7031  LR: 0.00000217  \n","Epoch: [4][400/2051] Elapsed 1m 51s (remain 7m 40s) Loss: 0.5693(0.4996) Grad: 90025.7188  LR: 0.00000193  \n","Epoch: [4][500/2051] Elapsed 2m 19s (remain 7m 12s) Loss: 0.5134(0.4990) Grad: 140681.9688  LR: 0.00000171  \n","Epoch: [4][600/2051] Elapsed 2m 47s (remain 6m 44s) Loss: 0.4713(0.4999) Grad: 76826.8359  LR: 0.00000151  \n","Epoch: [4][700/2051] Elapsed 3m 15s (remain 6m 16s) Loss: 0.5970(0.4985) Grad: 360393.3750  LR: 0.00000131  \n","Epoch: [4][800/2051] Elapsed 3m 43s (remain 5m 48s) Loss: 0.4045(0.4976) Grad: 89068.2266  LR: 0.00000113  \n","Epoch: [4][900/2051] Elapsed 4m 10s (remain 5m 20s) Loss: 0.5352(0.4987) Grad: 93704.6094  LR: 0.00000096  \n","Epoch: [4][1000/2051] Elapsed 4m 38s (remain 4m 52s) Loss: 0.4945(0.4985) Grad: 243690.1562  LR: 0.00000080  \n","Epoch: [4][1100/2051] Elapsed 5m 6s (remain 4m 24s) Loss: 0.6001(0.4981) Grad: 76730.0000  LR: 0.00000066  \n","Epoch: [4][1200/2051] Elapsed 5m 33s (remain 3m 56s) Loss: 0.4394(0.4976) Grad: 101776.4531  LR: 0.00000053  \n","Epoch: [4][1300/2051] Elapsed 6m 1s (remain 3m 28s) Loss: 0.4611(0.4972) Grad: 58968.5469  LR: 0.00000041  \n","Epoch: [4][1400/2051] Elapsed 6m 29s (remain 3m 0s) Loss: 0.5645(0.4972) Grad: 127615.9766  LR: 0.00000031  \n","Epoch: [4][1500/2051] Elapsed 6m 57s (remain 2m 32s) Loss: 0.4653(0.4979) Grad: 15965.5244  LR: 0.00000022  \n","Epoch: [4][1600/2051] Elapsed 7m 25s (remain 2m 5s) Loss: 0.4439(0.4976) Grad: 38751.3555  LR: 0.00000015  \n","Epoch: [4][1700/2051] Elapsed 7m 52s (remain 1m 37s) Loss: 0.5098(0.4977) Grad: 56955.4688  LR: 0.00000009  \n","Epoch: [4][1800/2051] Elapsed 8m 20s (remain 1m 9s) Loss: 0.4310(0.4977) Grad: 25312.2324  LR: 0.00000005  \n","Epoch: [4][1900/2051] Elapsed 8m 48s (remain 0m 41s) Loss: 0.5430(0.4975) Grad: 67512.3828  LR: 0.00000002  \n","Epoch: [4][2000/2051] Elapsed 9m 16s (remain 0m 13s) Loss: 0.5915(0.4982) Grad: 52474.6641  LR: 0.00000000  \n","Epoch: [4][2050/2051] Elapsed 9m 30s (remain 0m 0s) Loss: 0.5787(0.4980) Grad: 49417.1016  LR: 0.00000000  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 36s) Loss: 0.5133(0.5133) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 20s) Loss: 0.4625(0.5541) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.5772(0.5592) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4980  avg_val_loss: 0.5580  time: 607s\n","Epoch 4 - Score: 0.8342\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.6598(0.5580) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 6 result ==========\n","Score: 0.8400\n","========== fold: 7 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2076] Elapsed 0m 0s (remain 28m 50s) Loss: 0.7685(0.7685) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/2076] Elapsed 0m 28s (remain 9m 20s) Loss: 0.6161(0.6409) Grad: 34015.0586  LR: 0.00001999  \n","Epoch: [1][200/2076] Elapsed 0m 56s (remain 8m 46s) Loss: 0.5558(0.6128) Grad: 19145.5098  LR: 0.00001997  \n","Epoch: [1][300/2076] Elapsed 1m 24s (remain 8m 15s) Loss: 0.4846(0.5997) Grad: 15487.0361  LR: 0.00001994  \n","Epoch: [1][400/2076] Elapsed 1m 51s (remain 7m 47s) Loss: 0.5301(0.5898) Grad: 55895.3828  LR: 0.00001989  \n","Epoch: [1][500/2076] Elapsed 2m 19s (remain 7m 18s) Loss: 0.6283(0.5839) Grad: 33480.9023  LR: 0.00001982  \n","Epoch: [1][600/2076] Elapsed 2m 47s (remain 6m 50s) Loss: 0.4131(0.5790) Grad: 27226.3477  LR: 0.00001974  \n","Epoch: [1][700/2076] Elapsed 3m 15s (remain 6m 22s) Loss: 0.4300(0.5765) Grad: 26933.8105  LR: 0.00001965  \n","Epoch: [1][800/2076] Elapsed 3m 42s (remain 5m 54s) Loss: 0.5731(0.5736) Grad: 23088.2344  LR: 0.00001954  \n","Epoch: [1][900/2076] Elapsed 4m 10s (remain 5m 26s) Loss: 0.6881(0.5710) Grad: 76103.1328  LR: 0.00001942  \n","Epoch: [1][1000/2076] Elapsed 4m 38s (remain 4m 58s) Loss: 0.5340(0.5695) Grad: 15025.3486  LR: 0.00001929  \n","Epoch: [1][1100/2076] Elapsed 5m 5s (remain 4m 30s) Loss: 0.6071(0.5678) Grad: 28562.5039  LR: 0.00001914  \n","Epoch: [1][1200/2076] Elapsed 5m 33s (remain 4m 3s) Loss: 0.5437(0.5663) Grad: 26000.2383  LR: 0.00001899  \n","Epoch: [1][1300/2076] Elapsed 6m 1s (remain 3m 35s) Loss: 0.6196(0.5647) Grad: 36674.0742  LR: 0.00001881  \n","Epoch: [1][1400/2076] Elapsed 6m 29s (remain 3m 7s) Loss: 0.5256(0.5629) Grad: 63890.7969  LR: 0.00001863  \n","Epoch: [1][1500/2076] Elapsed 6m 57s (remain 2m 39s) Loss: 0.3874(0.5612) Grad: 21137.6367  LR: 0.00001843  \n","Epoch: [1][1600/2076] Elapsed 7m 24s (remain 2m 11s) Loss: 0.4403(0.5596) Grad: 23465.6797  LR: 0.00001822  \n","Epoch: [1][1700/2076] Elapsed 7m 52s (remain 1m 44s) Loss: 0.5529(0.5583) Grad: 43622.8789  LR: 0.00001800  \n","Epoch: [1][1800/2076] Elapsed 8m 20s (remain 1m 16s) Loss: 0.5737(0.5579) Grad: 26643.0215  LR: 0.00001777  \n","Epoch: [1][1900/2076] Elapsed 8m 47s (remain 0m 48s) Loss: 0.5162(0.5569) Grad: 25159.0938  LR: 0.00001752  \n","Epoch: [1][2000/2076] Elapsed 9m 15s (remain 0m 20s) Loss: 0.5027(0.5568) Grad: 15424.1865  LR: 0.00001727  \n","Epoch: [1][2075/2076] Elapsed 9m 36s (remain 0m 0s) Loss: 0.4750(0.5562) Grad: 48451.0117  LR: 0.00001707  \n","EVAL: [0/204] Elapsed 0m 0s (remain 2m 16s) Loss: 0.5046(0.5046) \n","EVAL: [100/204] Elapsed 0m 16s (remain 0m 16s) Loss: 0.4935(0.5371) \n","EVAL: [200/204] Elapsed 0m 32s (remain 0m 0s) Loss: 0.5252(0.5326) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5562  avg_val_loss: 0.5328  time: 610s\n","Epoch 1 - Score: 0.8373\n","Epoch 1 - Save Best Score: 0.8373 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [203/204] Elapsed 0m 33s (remain 0m 0s) Loss: 0.3825(0.5328) \n","Epoch: [2][0/2076] Elapsed 0m 0s (remain 27m 38s) Loss: 0.4174(0.4174) Grad: 33329.3711  LR: 0.00001707  \n","Epoch: [2][100/2076] Elapsed 0m 28s (remain 9m 25s) Loss: 0.4985(0.5141) Grad: 54568.4141  LR: 0.00001680  \n","Epoch: [2][200/2076] Elapsed 0m 56s (remain 8m 51s) Loss: 0.5280(0.5151) Grad: 29057.4473  LR: 0.00001651  \n","Epoch: [2][300/2076] Elapsed 1m 24s (remain 8m 20s) Loss: 0.4842(0.5140) Grad: 69908.6484  LR: 0.00001622  \n","Epoch: [2][400/2076] Elapsed 1m 52s (remain 7m 50s) Loss: 0.5758(0.5130) Grad: 47863.1094  LR: 0.00001592  \n","Epoch: [2][500/2076] Elapsed 2m 20s (remain 7m 20s) Loss: 0.5936(0.5133) Grad: 89231.4688  LR: 0.00001561  \n","Epoch: [2][600/2076] Elapsed 2m 47s (remain 6m 52s) Loss: 0.3881(0.5147) Grad: 34213.0039  LR: 0.00001530  \n","Epoch: [2][700/2076] Elapsed 3m 15s (remain 6m 23s) Loss: 0.7504(0.5156) Grad: 76960.0234  LR: 0.00001497  \n","Epoch: [2][800/2076] Elapsed 3m 43s (remain 5m 55s) Loss: 0.4905(0.5170) Grad: 37741.1250  LR: 0.00001464  \n","Epoch: [2][900/2076] Elapsed 4m 11s (remain 5m 27s) Loss: 0.4836(0.5175) Grad: 31004.7617  LR: 0.00001430  \n","Epoch: [2][1000/2076] Elapsed 4m 38s (remain 4m 59s) Loss: 0.6307(0.5175) Grad: 101491.6719  LR: 0.00001396  \n","Epoch: [2][1100/2076] Elapsed 5m 6s (remain 4m 31s) Loss: 0.7436(0.5182) Grad: 155395.9688  LR: 0.00001361  \n","Epoch: [2][1200/2076] Elapsed 5m 34s (remain 4m 3s) Loss: 0.4656(0.5174) Grad: 39440.2070  LR: 0.00001325  \n","Epoch: [2][1300/2076] Elapsed 6m 1s (remain 3m 35s) Loss: 0.5296(0.5180) Grad: 40844.2695  LR: 0.00001289  \n","Epoch: [2][1400/2076] Elapsed 6m 29s (remain 3m 7s) Loss: 0.7104(0.5183) Grad: 139671.2344  LR: 0.00001253  \n","Epoch: [2][1500/2076] Elapsed 6m 57s (remain 2m 39s) Loss: 0.5164(0.5177) Grad: 73691.0391  LR: 0.00001216  \n","Epoch: [2][1600/2076] Elapsed 7m 24s (remain 2m 12s) Loss: 0.5225(0.5176) Grad: 10259.8613  LR: 0.00001179  \n","Epoch: [2][1700/2076] Elapsed 7m 52s (remain 1m 44s) Loss: 0.5373(0.5175) Grad: 30999.4902  LR: 0.00001141  \n","Epoch: [2][1800/2076] Elapsed 8m 20s (remain 1m 16s) Loss: 0.5851(0.5179) Grad: 43714.9688  LR: 0.00001104  \n","Epoch: [2][1900/2076] Elapsed 8m 48s (remain 0m 48s) Loss: 0.4912(0.5180) Grad: 31071.9902  LR: 0.00001066  \n","Epoch: [2][2000/2076] Elapsed 9m 15s (remain 0m 20s) Loss: 0.4399(0.5178) Grad: 62059.3125  LR: 0.00001028  \n","Epoch: [2][2075/2076] Elapsed 9m 36s (remain 0m 0s) Loss: 0.4986(0.5178) Grad: 50620.5781  LR: 0.00001000  \n","EVAL: [0/204] Elapsed 0m 0s (remain 2m 1s) Loss: 0.4909(0.4909) \n","EVAL: [100/204] Elapsed 0m 16s (remain 0m 16s) Loss: 0.4857(0.5398) \n","EVAL: [200/204] Elapsed 0m 32s (remain 0m 0s) Loss: 0.5128(0.5371) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5178  avg_val_loss: 0.5374  time: 610s\n","Epoch 2 - Score: 0.8422\n","Epoch 2 - Save Best Score: 0.8422 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [203/204] Elapsed 0m 32s (remain 0m 0s) Loss: 0.4346(0.5374) \n","Epoch: [3][0/2076] Elapsed 0m 0s (remain 28m 48s) Loss: 0.5359(0.5359) Grad: 57836.0156  LR: 0.00001000  \n","Epoch: [3][100/2076] Elapsed 0m 29s (remain 9m 29s) Loss: 0.3331(0.4981) Grad: 41831.1211  LR: 0.00000962  \n","Epoch: [3][200/2076] Elapsed 0m 57s (remain 8m 54s) Loss: 0.5342(0.5032) Grad: 37606.6328  LR: 0.00000924  \n","Epoch: [3][300/2076] Elapsed 1m 24s (remain 8m 21s) Loss: 0.4171(0.5026) Grad: 58922.1094  LR: 0.00000886  \n","Epoch: [3][400/2076] Elapsed 1m 52s (remain 7m 50s) Loss: 0.5505(0.5034) Grad: 118296.2734  LR: 0.00000849  \n","Epoch: [3][500/2076] Elapsed 2m 20s (remain 7m 21s) Loss: 0.5833(0.5040) Grad: 52382.4883  LR: 0.00000812  \n","Epoch: [3][600/2076] Elapsed 2m 48s (remain 6m 52s) Loss: 0.5095(0.5028) Grad: 74954.2969  LR: 0.00000775  \n","Epoch: [3][700/2076] Elapsed 3m 16s (remain 6m 24s) Loss: 0.4357(0.5029) Grad: 105967.8906  LR: 0.00000738  \n","Epoch: [3][800/2076] Elapsed 3m 43s (remain 5m 56s) Loss: 0.4807(0.5028) Grad: 72678.7812  LR: 0.00000702  \n","Epoch: [3][900/2076] Elapsed 4m 11s (remain 5m 27s) Loss: 0.5519(0.5038) Grad: 53052.0781  LR: 0.00000666  \n","Epoch: [3][1000/2076] Elapsed 4m 39s (remain 4m 59s) Loss: 0.4907(0.5038) Grad: 44160.3867  LR: 0.00000630  \n","Epoch: [3][1100/2076] Elapsed 5m 6s (remain 4m 31s) Loss: 0.5466(0.5032) Grad: 52703.3672  LR: 0.00000595  \n","Epoch: [3][1200/2076] Elapsed 5m 34s (remain 4m 3s) Loss: 0.5267(0.5026) Grad: 321847.8438  LR: 0.00000561  \n","Epoch: [3][1300/2076] Elapsed 6m 2s (remain 3m 35s) Loss: 0.4766(0.5026) Grad: 36693.2148  LR: 0.00000527  \n","Epoch: [3][1400/2076] Elapsed 6m 29s (remain 3m 7s) Loss: 0.6226(0.5020) Grad: 43370.7070  LR: 0.00000494  \n","Epoch: [3][1500/2076] Elapsed 6m 57s (remain 2m 39s) Loss: 0.4793(0.5025) Grad: 93024.3125  LR: 0.00000462  \n","Epoch: [3][1600/2076] Elapsed 7m 25s (remain 2m 12s) Loss: 0.4134(0.5024) Grad: 105749.6406  LR: 0.00000431  \n","Epoch: [3][1700/2076] Elapsed 7m 53s (remain 1m 44s) Loss: 0.4797(0.5023) Grad: 57801.9688  LR: 0.00000400  \n","Epoch: [3][1800/2076] Elapsed 8m 20s (remain 1m 16s) Loss: 0.5350(0.5026) Grad: 43820.0781  LR: 0.00000370  \n","Epoch: [3][1900/2076] Elapsed 8m 48s (remain 0m 48s) Loss: 0.5684(0.5024) Grad: 112575.5391  LR: 0.00000341  \n","Epoch: [3][2000/2076] Elapsed 9m 16s (remain 0m 20s) Loss: 0.4900(0.5020) Grad: 169173.0469  LR: 0.00000313  \n","Epoch: [3][2075/2076] Elapsed 9m 37s (remain 0m 0s) Loss: 0.4926(0.5025) Grad: 224026.0625  LR: 0.00000293  \n","EVAL: [0/204] Elapsed 0m 0s (remain 2m 12s) Loss: 0.5202(0.5202) \n","EVAL: [100/204] Elapsed 0m 16s (remain 0m 16s) Loss: 0.4840(0.5454) \n","EVAL: [200/204] Elapsed 0m 32s (remain 0m 0s) Loss: 0.5495(0.5427) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5025  avg_val_loss: 0.5429  time: 610s\n","Epoch 3 - Score: 0.8398\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [203/204] Elapsed 0m 32s (remain 0m 0s) Loss: 0.3946(0.5429) \n","Epoch: [4][0/2076] Elapsed 0m 0s (remain 28m 33s) Loss: 0.5388(0.5388) Grad: 58651.7656  LR: 0.00000293  \n","Epoch: [4][100/2076] Elapsed 0m 28s (remain 9m 19s) Loss: 0.4575(0.4971) Grad: 45367.3906  LR: 0.00000266  \n","Epoch: [4][200/2076] Elapsed 0m 56s (remain 8m 46s) Loss: 0.5960(0.5007) Grad: 249386.0469  LR: 0.00000241  \n","Epoch: [4][300/2076] Elapsed 1m 24s (remain 8m 16s) Loss: 0.5562(0.4998) Grad: 222052.1094  LR: 0.00000217  \n","Epoch: [4][400/2076] Elapsed 1m 51s (remain 7m 47s) Loss: 0.5269(0.4974) Grad: 34427.7383  LR: 0.00000194  \n","Epoch: [4][500/2076] Elapsed 2m 19s (remain 7m 19s) Loss: 0.4743(0.4963) Grad: 29806.1016  LR: 0.00000172  \n","Epoch: [4][600/2076] Elapsed 2m 47s (remain 6m 51s) Loss: 0.4795(0.4970) Grad: 32526.9512  LR: 0.00000152  \n","Epoch: [4][700/2076] Elapsed 3m 15s (remain 6m 22s) Loss: 0.4571(0.4967) Grad: 36092.4570  LR: 0.00000132  \n","Epoch: [4][800/2076] Elapsed 3m 42s (remain 5m 54s) Loss: 0.4908(0.4970) Grad: 32234.0723  LR: 0.00000114  \n","Epoch: [4][900/2076] Elapsed 4m 10s (remain 5m 27s) Loss: 0.5181(0.4967) Grad: 46818.1562  LR: 0.00000097  \n","Epoch: [4][1000/2076] Elapsed 4m 38s (remain 4m 59s) Loss: 0.5277(0.4964) Grad: 40490.1133  LR: 0.00000082  \n","Epoch: [4][1100/2076] Elapsed 5m 6s (remain 4m 31s) Loss: 0.4666(0.4970) Grad: 65759.0703  LR: 0.00000067  \n","Epoch: [4][1200/2076] Elapsed 5m 34s (remain 4m 3s) Loss: 0.5009(0.4972) Grad: 47016.9023  LR: 0.00000054  \n","Epoch: [4][1300/2076] Elapsed 6m 2s (remain 3m 35s) Loss: 0.6525(0.4972) Grad: 52597.5430  LR: 0.00000043  \n","Epoch: [4][1400/2076] Elapsed 6m 29s (remain 3m 7s) Loss: 0.4084(0.4969) Grad: 52015.4570  LR: 0.00000032  \n","Epoch: [4][1500/2076] Elapsed 6m 57s (remain 2m 39s) Loss: 0.5949(0.4973) Grad: 397386.8438  LR: 0.00000024  \n","Epoch: [4][1600/2076] Elapsed 7m 25s (remain 2m 12s) Loss: 0.4970(0.4970) Grad: 52753.0781  LR: 0.00000016  \n","Epoch: [4][1700/2076] Elapsed 7m 53s (remain 1m 44s) Loss: 0.5956(0.4970) Grad: 37652.5469  LR: 0.00000010  \n","Epoch: [4][1800/2076] Elapsed 8m 20s (remain 1m 16s) Loss: 0.3120(0.4966) Grad: 32712.0840  LR: 0.00000005  \n","Epoch: [4][1900/2076] Elapsed 8m 48s (remain 0m 48s) Loss: 0.5066(0.4968) Grad: 42092.4219  LR: 0.00000002  \n","Epoch: [4][2000/2076] Elapsed 9m 16s (remain 0m 20s) Loss: 0.5783(0.4971) Grad: 75083.9688  LR: 0.00000000  \n","Epoch: [4][2075/2076] Elapsed 9m 37s (remain 0m 0s) Loss: 0.4897(0.4973) Grad: 55392.4570  LR: 0.00000000  \n","EVAL: [0/204] Elapsed 0m 0s (remain 2m 12s) Loss: 0.5183(0.5183) \n","EVAL: [100/204] Elapsed 0m 16s (remain 0m 16s) Loss: 0.4860(0.5475) \n","EVAL: [200/204] Elapsed 0m 32s (remain 0m 0s) Loss: 0.5674(0.5448) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4973  avg_val_loss: 0.5450  time: 610s\n","Epoch 4 - Score: 0.8399\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [203/204] Elapsed 0m 33s (remain 0m 0s) Loss: 0.3875(0.5450) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 7 result ==========\n","Score: 0.8422\n","========== fold: 8 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2061] Elapsed 0m 0s (remain 30m 39s) Loss: 0.7145(0.7145) Grad: 128445.8750  LR: 0.00002000  \n","Epoch: [1][100/2061] Elapsed 0m 28s (remain 9m 9s) Loss: 0.6573(0.6467) Grad: 114256.4844  LR: 0.00001999  \n","Epoch: [1][200/2061] Elapsed 0m 55s (remain 8m 36s) Loss: 0.6584(0.6164) Grad: 83721.2891  LR: 0.00001997  \n","Epoch: [1][300/2061] Elapsed 1m 23s (remain 8m 7s) Loss: 0.4790(0.6001) Grad: 60650.0039  LR: 0.00001993  \n","Epoch: [1][400/2061] Elapsed 1m 50s (remain 7m 38s) Loss: 0.6206(0.5886) Grad: 145153.5625  LR: 0.00001988  \n","Epoch: [1][500/2061] Elapsed 2m 18s (remain 7m 10s) Loss: 0.5265(0.5811) Grad: 59118.8555  LR: 0.00001982  \n","Epoch: [1][600/2061] Elapsed 2m 45s (remain 6m 42s) Loss: 0.6271(0.5777) Grad: 36024.8164  LR: 0.00001974  \n","Epoch: [1][700/2061] Elapsed 3m 13s (remain 6m 14s) Loss: 0.5411(0.5741) Grad: 58709.2969  LR: 0.00001965  \n","Epoch: [1][800/2061] Elapsed 3m 40s (remain 5m 47s) Loss: 0.6376(0.5698) Grad: 143462.0156  LR: 0.00001954  \n","Epoch: [1][900/2061] Elapsed 4m 8s (remain 5m 20s) Loss: 0.5517(0.5670) Grad: 61096.3672  LR: 0.00001942  \n","Epoch: [1][1000/2061] Elapsed 4m 36s (remain 4m 52s) Loss: 0.5152(0.5662) Grad: 68926.7500  LR: 0.00001928  \n","Epoch: [1][1100/2061] Elapsed 5m 3s (remain 4m 24s) Loss: 0.5424(0.5646) Grad: 24970.5137  LR: 0.00001913  \n","Epoch: [1][1200/2061] Elapsed 5m 31s (remain 3m 57s) Loss: 0.5458(0.5640) Grad: 77926.7969  LR: 0.00001897  \n","Epoch: [1][1300/2061] Elapsed 5m 58s (remain 3m 29s) Loss: 0.4489(0.5626) Grad: 47361.6172  LR: 0.00001880  \n","Epoch: [1][1400/2061] Elapsed 6m 26s (remain 3m 1s) Loss: 0.5888(0.5616) Grad: 57898.4883  LR: 0.00001861  \n","Epoch: [1][1500/2061] Elapsed 6m 54s (remain 2m 34s) Loss: 0.6277(0.5601) Grad: 243362.8438  LR: 0.00001841  \n","Epoch: [1][1600/2061] Elapsed 7m 22s (remain 2m 7s) Loss: 0.5671(0.5588) Grad: 70842.4531  LR: 0.00001820  \n","Epoch: [1][1700/2061] Elapsed 7m 49s (remain 1m 39s) Loss: 0.4740(0.5579) Grad: 41295.3633  LR: 0.00001797  \n","Epoch: [1][1800/2061] Elapsed 8m 17s (remain 1m 11s) Loss: 0.5531(0.5570) Grad: 69041.6641  LR: 0.00001774  \n","Epoch: [1][1900/2061] Elapsed 8m 44s (remain 0m 44s) Loss: 0.5763(0.5558) Grad: 32298.3438  LR: 0.00001749  \n","Epoch: [1][2000/2061] Elapsed 9m 12s (remain 0m 16s) Loss: 0.5253(0.5547) Grad: 9648.1348  LR: 0.00001723  \n","Epoch: [1][2060/2061] Elapsed 9m 28s (remain 0m 0s) Loss: 0.5807(0.5549) Grad: 158867.2344  LR: 0.00001707  \n","EVAL: [0/218] Elapsed 0m 0s (remain 2m 35s) Loss: 0.5572(0.5572) \n","EVAL: [100/218] Elapsed 0m 16s (remain 0m 19s) Loss: 0.6383(0.5339) \n","EVAL: [200/218] Elapsed 0m 32s (remain 0m 2s) Loss: 0.7014(0.5465) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5549  avg_val_loss: 0.5487  time: 604s\n","Epoch 1 - Score: 0.8170\n","Epoch 1 - Save Best Score: 0.8170 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [217/218] Elapsed 0m 35s (remain 0m 0s) Loss: 0.5981(0.5487) \n","Epoch: [2][0/2061] Elapsed 0m 0s (remain 29m 33s) Loss: 0.5112(0.5112) Grad: 119131.5391  LR: 0.00001707  \n","Epoch: [2][100/2061] Elapsed 0m 29s (remain 9m 23s) Loss: 0.4750(0.5207) Grad: 69000.6328  LR: 0.00001680  \n","Epoch: [2][200/2061] Elapsed 0m 56s (remain 8m 45s) Loss: 0.4250(0.5184) Grad: 39337.4844  LR: 0.00001651  \n","Epoch: [2][300/2061] Elapsed 1m 24s (remain 8m 13s) Loss: 0.4180(0.5205) Grad: 49007.7930  LR: 0.00001622  \n","Epoch: [2][400/2061] Elapsed 1m 52s (remain 7m 44s) Loss: 0.5594(0.5192) Grad: 56806.1094  LR: 0.00001591  \n","Epoch: [2][500/2061] Elapsed 2m 19s (remain 7m 15s) Loss: 0.4752(0.5191) Grad: 86031.7812  LR: 0.00001560  \n","Epoch: [2][600/2061] Elapsed 2m 47s (remain 6m 46s) Loss: 0.5484(0.5184) Grad: 139981.6719  LR: 0.00001528  \n","Epoch: [2][700/2061] Elapsed 3m 14s (remain 6m 17s) Loss: 0.5557(0.5199) Grad: 169353.9844  LR: 0.00001496  \n","Epoch: [2][800/2061] Elapsed 3m 42s (remain 5m 49s) Loss: 0.5450(0.5202) Grad: 198548.4844  LR: 0.00001462  \n","Epoch: [2][900/2061] Elapsed 4m 9s (remain 5m 21s) Loss: 0.5297(0.5187) Grad: 118451.3984  LR: 0.00001428  \n","Epoch: [2][1000/2061] Elapsed 4m 37s (remain 4m 53s) Loss: 0.4347(0.5183) Grad: 78165.5000  LR: 0.00001393  \n","Epoch: [2][1100/2061] Elapsed 5m 4s (remain 4m 25s) Loss: 0.5122(0.5193) Grad: 140212.4375  LR: 0.00001358  \n","Epoch: [2][1200/2061] Elapsed 5m 32s (remain 3m 57s) Loss: 0.5021(0.5195) Grad: 79729.6953  LR: 0.00001322  \n","Epoch: [2][1300/2061] Elapsed 5m 59s (remain 3m 30s) Loss: 0.5542(0.5197) Grad: 44522.2461  LR: 0.00001286  \n","Epoch: [2][1400/2061] Elapsed 6m 27s (remain 3m 2s) Loss: 0.5254(0.5194) Grad: 80506.0156  LR: 0.00001249  \n","Epoch: [2][1500/2061] Elapsed 6m 54s (remain 2m 34s) Loss: 0.4680(0.5188) Grad: 53666.2227  LR: 0.00001212  \n","Epoch: [2][1600/2061] Elapsed 7m 22s (remain 2m 7s) Loss: 0.5000(0.5187) Grad: 65745.4375  LR: 0.00001175  \n","Epoch: [2][1700/2061] Elapsed 7m 49s (remain 1m 39s) Loss: 0.4456(0.5184) Grad: 73202.7344  LR: 0.00001137  \n","Epoch: [2][1800/2061] Elapsed 8m 17s (remain 1m 11s) Loss: 0.5586(0.5180) Grad: 21850.6035  LR: 0.00001099  \n","Epoch: [2][1900/2061] Elapsed 8m 44s (remain 0m 44s) Loss: 0.5148(0.5181) Grad: 65071.5820  LR: 0.00001061  \n","Epoch: [2][2000/2061] Elapsed 9m 12s (remain 0m 16s) Loss: 0.5905(0.5183) Grad: 245310.5000  LR: 0.00001023  \n","Epoch: [2][2060/2061] Elapsed 9m 28s (remain 0m 0s) Loss: 0.5614(0.5183) Grad: 76702.9219  LR: 0.00001000  \n","EVAL: [0/218] Elapsed 0m 0s (remain 2m 31s) Loss: 0.5986(0.5986) \n","EVAL: [100/218] Elapsed 0m 16s (remain 0m 19s) Loss: 0.6529(0.5340) \n","EVAL: [200/218] Elapsed 0m 32s (remain 0m 2s) Loss: 0.7387(0.5470) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5183  avg_val_loss: 0.5501  time: 604s\n","Epoch 2 - Score: 0.8262\n","Epoch 2 - Save Best Score: 0.8262 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [217/218] Elapsed 0m 35s (remain 0m 0s) Loss: 0.6180(0.5501) \n","Epoch: [3][0/2061] Elapsed 0m 0s (remain 30m 4s) Loss: 0.4449(0.4449) Grad: 214126.1875  LR: 0.00001000  \n","Epoch: [3][100/2061] Elapsed 0m 29s (remain 9m 23s) Loss: 0.4864(0.5012) Grad: 67304.2266  LR: 0.00000962  \n","Epoch: [3][200/2061] Elapsed 0m 56s (remain 8m 47s) Loss: 0.4284(0.5055) Grad: 85924.2578  LR: 0.00000924  \n","Epoch: [3][300/2061] Elapsed 1m 24s (remain 8m 13s) Loss: 0.3968(0.5086) Grad: 98675.7734  LR: 0.00000886  \n","Epoch: [3][400/2061] Elapsed 1m 51s (remain 7m 43s) Loss: 0.4778(0.5051) Grad: 50933.0195  LR: 0.00000848  \n","Epoch: [3][500/2061] Elapsed 2m 19s (remain 7m 14s) Loss: 0.6078(0.5052) Grad: 343716.2500  LR: 0.00000811  \n","Epoch: [3][600/2061] Elapsed 2m 46s (remain 6m 45s) Loss: 0.4771(0.5054) Grad: 65765.5703  LR: 0.00000773  \n","Epoch: [3][700/2061] Elapsed 3m 14s (remain 6m 16s) Loss: 0.5575(0.5052) Grad: 75233.3438  LR: 0.00000736  \n","Epoch: [3][800/2061] Elapsed 3m 42s (remain 5m 49s) Loss: 0.5986(0.5057) Grad: 101429.6016  LR: 0.00000700  \n","Epoch: [3][900/2061] Elapsed 4m 9s (remain 5m 21s) Loss: 0.6200(0.5063) Grad: 82104.3828  LR: 0.00000664  \n","Epoch: [3][1000/2061] Elapsed 4m 36s (remain 4m 53s) Loss: 0.5436(0.5048) Grad: 117444.2344  LR: 0.00000628  \n","Epoch: [3][1100/2061] Elapsed 5m 4s (remain 4m 25s) Loss: 0.3810(0.5051) Grad: 73499.3047  LR: 0.00000593  \n","Epoch: [3][1200/2061] Elapsed 5m 31s (remain 3m 57s) Loss: 0.4676(0.5043) Grad: 50876.9102  LR: 0.00000559  \n","Epoch: [3][1300/2061] Elapsed 5m 59s (remain 3m 29s) Loss: 0.4873(0.5047) Grad: 36728.0391  LR: 0.00000525  \n","Epoch: [3][1400/2061] Elapsed 6m 26s (remain 3m 2s) Loss: 0.4047(0.5048) Grad: 107364.2969  LR: 0.00000492  \n","Epoch: [3][1500/2061] Elapsed 6m 54s (remain 2m 34s) Loss: 0.5230(0.5048) Grad: 317970.0312  LR: 0.00000459  \n","Epoch: [3][1600/2061] Elapsed 7m 21s (remain 2m 6s) Loss: 0.5253(0.5047) Grad: 69115.0703  LR: 0.00000427  \n","Epoch: [3][1700/2061] Elapsed 7m 49s (remain 1m 39s) Loss: 0.4698(0.5046) Grad: 40754.1680  LR: 0.00000397  \n","Epoch: [3][1800/2061] Elapsed 8m 16s (remain 1m 11s) Loss: 0.5284(0.5048) Grad: 22168.9219  LR: 0.00000367  \n","Epoch: [3][1900/2061] Elapsed 8m 44s (remain 0m 44s) Loss: 0.5057(0.5053) Grad: 53337.3477  LR: 0.00000338  \n","Epoch: [3][2000/2061] Elapsed 9m 11s (remain 0m 16s) Loss: 0.4593(0.5046) Grad: 119242.5391  LR: 0.00000310  \n","Epoch: [3][2060/2061] Elapsed 9m 28s (remain 0m 0s) Loss: 0.5255(0.5046) Grad: 83054.6641  LR: 0.00000293  \n","EVAL: [0/218] Elapsed 0m 0s (remain 2m 29s) Loss: 0.7240(0.7240) \n","EVAL: [100/218] Elapsed 0m 16s (remain 0m 19s) Loss: 0.6944(0.5397) \n","EVAL: [200/218] Elapsed 0m 32s (remain 0m 2s) Loss: 0.7178(0.5478) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5046  avg_val_loss: 0.5503  time: 604s\n","Epoch 3 - Score: 0.8315\n","Epoch 3 - Save Best Score: 0.8315 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [217/218] Elapsed 0m 35s (remain 0m 0s) Loss: 0.5951(0.5503) \n","Epoch: [4][0/2061] Elapsed 0m 0s (remain 30m 23s) Loss: 0.3491(0.3491) Grad: 79452.7422  LR: 0.00000293  \n","Epoch: [4][100/2061] Elapsed 0m 28s (remain 9m 20s) Loss: 0.4378(0.4944) Grad: 34206.9023  LR: 0.00000267  \n","Epoch: [4][200/2061] Elapsed 0m 56s (remain 8m 43s) Loss: 0.5610(0.4958) Grad: 147466.0312  LR: 0.00000241  \n","Epoch: [4][300/2061] Elapsed 1m 24s (remain 8m 11s) Loss: 0.4264(0.5015) Grad: 48807.7383  LR: 0.00000217  \n","Epoch: [4][400/2061] Elapsed 1m 51s (remain 7m 41s) Loss: 0.4913(0.5021) Grad: 38992.9258  LR: 0.00000194  \n","Epoch: [4][500/2061] Elapsed 2m 18s (remain 7m 12s) Loss: 0.6034(0.5014) Grad: 78435.0625  LR: 0.00000172  \n","Epoch: [4][600/2061] Elapsed 2m 46s (remain 6m 43s) Loss: 0.4023(0.4981) Grad: 54224.0352  LR: 0.00000151  \n","Epoch: [4][700/2061] Elapsed 3m 13s (remain 6m 14s) Loss: 0.5546(0.4983) Grad: 20557.5605  LR: 0.00000132  \n","Epoch: [4][800/2061] Elapsed 3m 40s (remain 5m 47s) Loss: 0.4464(0.4984) Grad: 222437.3906  LR: 0.00000113  \n","Epoch: [4][900/2061] Elapsed 4m 7s (remain 5m 19s) Loss: 0.5132(0.4976) Grad: 17806.1953  LR: 0.00000096  \n","Epoch: [4][1000/2061] Elapsed 4m 35s (remain 4m 51s) Loss: 0.4963(0.4980) Grad: 32870.3125  LR: 0.00000081  \n","Epoch: [4][1100/2061] Elapsed 5m 2s (remain 4m 23s) Loss: 0.5020(0.4980) Grad: 39060.8594  LR: 0.00000066  \n","Epoch: [4][1200/2061] Elapsed 5m 30s (remain 3m 56s) Loss: 0.3744(0.4977) Grad: 17383.3906  LR: 0.00000053  \n","Epoch: [4][1300/2061] Elapsed 5m 57s (remain 3m 28s) Loss: 0.5146(0.4981) Grad: 22444.0039  LR: 0.00000042  \n","Epoch: [4][1400/2061] Elapsed 6m 24s (remain 3m 1s) Loss: 0.4792(0.4986) Grad: 17750.3340  LR: 0.00000032  \n","Epoch: [4][1500/2061] Elapsed 6m 52s (remain 2m 33s) Loss: 0.4452(0.4983) Grad: 16266.2031  LR: 0.00000023  \n","Epoch: [4][1600/2061] Elapsed 7m 19s (remain 2m 6s) Loss: 0.5471(0.4987) Grad: 22179.5234  LR: 0.00000015  \n","Epoch: [4][1700/2061] Elapsed 7m 46s (remain 1m 38s) Loss: 0.6388(0.4991) Grad: 328865.5000  LR: 0.00000009  \n","Epoch: [4][1800/2061] Elapsed 8m 14s (remain 1m 11s) Loss: 0.5601(0.4992) Grad: 40064.3828  LR: 0.00000005  \n","Epoch: [4][1900/2061] Elapsed 8m 41s (remain 0m 43s) Loss: 0.4928(0.4989) Grad: 23867.6211  LR: 0.00000002  \n","Epoch: [4][2000/2061] Elapsed 9m 8s (remain 0m 16s) Loss: 0.4347(0.4991) Grad: 17255.9336  LR: 0.00000000  \n","Epoch: [4][2060/2061] Elapsed 9m 25s (remain 0m 0s) Loss: 0.5976(0.4991) Grad: 25710.4902  LR: 0.00000000  \n","EVAL: [0/218] Elapsed 0m 0s (remain 2m 33s) Loss: 0.7436(0.7436) \n","EVAL: [100/218] Elapsed 0m 16s (remain 0m 19s) Loss: 0.6856(0.5444) \n","EVAL: [200/218] Elapsed 0m 32s (remain 0m 2s) Loss: 0.7246(0.5547) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4991  avg_val_loss: 0.5569  time: 601s\n","Epoch 4 - Score: 0.8315\n","Epoch 4 - Save Best Score: 0.8315 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [217/218] Elapsed 0m 35s (remain 0m 0s) Loss: 0.5936(0.5569) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 8 result ==========\n","Score: 0.8315\n","========== fold: 9 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/2032] Elapsed 0m 0s (remain 28m 17s) Loss: 0.6718(0.6718) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/2032] Elapsed 0m 28s (remain 9m 11s) Loss: 0.5828(0.6448) Grad: 48148.4414  LR: 0.00001999  \n","Epoch: [1][200/2032] Elapsed 0m 56s (remain 8m 32s) Loss: 0.6174(0.6150) Grad: 17841.7617  LR: 0.00001997  \n","Epoch: [1][300/2032] Elapsed 1m 23s (remain 8m 0s) Loss: 0.5437(0.6011) Grad: 28740.3770  LR: 0.00001993  \n","Epoch: [1][400/2032] Elapsed 1m 50s (remain 7m 31s) Loss: 0.6396(0.5906) Grad: 25085.5566  LR: 0.00001988  \n","Epoch: [1][500/2032] Elapsed 2m 18s (remain 7m 2s) Loss: 0.6024(0.5838) Grad: 9617.3770  LR: 0.00001981  \n","Epoch: [1][600/2032] Elapsed 2m 45s (remain 6m 34s) Loss: 0.5069(0.5810) Grad: 14917.5215  LR: 0.00001973  \n","Epoch: [1][700/2032] Elapsed 3m 12s (remain 6m 6s) Loss: 0.5399(0.5775) Grad: 5068.5229  LR: 0.00001964  \n","Epoch: [1][800/2032] Elapsed 3m 40s (remain 5m 38s) Loss: 0.5570(0.5736) Grad: 14496.1963  LR: 0.00001952  \n","Epoch: [1][900/2032] Elapsed 4m 7s (remain 5m 10s) Loss: 0.5038(0.5712) Grad: 9615.4199  LR: 0.00001940  \n","Epoch: [1][1000/2032] Elapsed 4m 35s (remain 4m 43s) Loss: 0.5065(0.5695) Grad: 20930.0391  LR: 0.00001926  \n","Epoch: [1][1100/2032] Elapsed 5m 2s (remain 4m 15s) Loss: 0.6068(0.5681) Grad: 5620.7173  LR: 0.00001911  \n","Epoch: [1][1200/2032] Elapsed 5m 29s (remain 3m 48s) Loss: 0.5342(0.5660) Grad: 9383.3535  LR: 0.00001894  \n","Epoch: [1][1300/2032] Elapsed 5m 57s (remain 3m 20s) Loss: 0.6880(0.5648) Grad: 33188.9492  LR: 0.00001876  \n","Epoch: [1][1400/2032] Elapsed 6m 24s (remain 2m 53s) Loss: 0.5718(0.5632) Grad: 8425.0850  LR: 0.00001857  \n","Epoch: [1][1500/2032] Elapsed 6m 51s (remain 2m 25s) Loss: 0.5259(0.5623) Grad: 10322.8662  LR: 0.00001836  \n","Epoch: [1][1600/2032] Elapsed 7m 19s (remain 1m 58s) Loss: 0.4244(0.5610) Grad: 11291.5195  LR: 0.00001815  \n","Epoch: [1][1700/2032] Elapsed 7m 46s (remain 1m 30s) Loss: 0.5596(0.5597) Grad: 6734.0859  LR: 0.00001792  \n","Epoch: [1][1800/2032] Elapsed 8m 13s (remain 1m 3s) Loss: 0.5513(0.5593) Grad: 24906.0176  LR: 0.00001768  \n","Epoch: [1][1900/2032] Elapsed 8m 41s (remain 0m 35s) Loss: 0.4601(0.5588) Grad: 7907.8931  LR: 0.00001742  \n","Epoch: [1][2000/2032] Elapsed 9m 8s (remain 0m 8s) Loss: 0.5454(0.5581) Grad: 11669.7227  LR: 0.00001716  \n","Epoch: [1][2031/2032] Elapsed 9m 16s (remain 0m 0s) Loss: 0.4612(0.5578) Grad: 7736.8838  LR: 0.00001707  \n","EVAL: [0/247] Elapsed 0m 0s (remain 2m 53s) Loss: 0.4103(0.4103) \n","EVAL: [100/247] Elapsed 0m 16s (remain 0m 23s) Loss: 0.5889(0.5576) \n","EVAL: [200/247] Elapsed 0m 32s (remain 0m 7s) Loss: 0.7255(0.5571) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5578  avg_val_loss: 0.5510  time: 597s\n","Epoch 1 - Score: 0.8210\n","Epoch 1 - Save Best Score: 0.8210 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [246/247] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4203(0.5510) \n","Epoch: [2][0/2032] Elapsed 0m 0s (remain 29m 43s) Loss: 0.5352(0.5352) Grad: 6456.7715  LR: 0.00001707  \n","Epoch: [2][100/2032] Elapsed 0m 28s (remain 9m 8s) Loss: 0.4267(0.5300) Grad: 5177.1377  LR: 0.00001679  \n","Epoch: [2][200/2032] Elapsed 0m 56s (remain 8m 34s) Loss: 0.5626(0.5274) Grad: 22946.2734  LR: 0.00001650  \n","Epoch: [2][300/2032] Elapsed 1m 23s (remain 8m 2s) Loss: 0.5986(0.5259) Grad: 18011.7637  LR: 0.00001621  \n","Epoch: [2][400/2032] Elapsed 1m 51s (remain 7m 34s) Loss: 0.5866(0.5239) Grad: 5333.4663  LR: 0.00001590  \n","Epoch: [2][500/2032] Elapsed 2m 19s (remain 7m 5s) Loss: 0.6743(0.5227) Grad: 29865.7539  LR: 0.00001558  \n","Epoch: [2][600/2032] Elapsed 2m 46s (remain 6m 36s) Loss: 0.5930(0.5203) Grad: 6236.2563  LR: 0.00001526  \n","Epoch: [2][700/2032] Elapsed 3m 14s (remain 6m 8s) Loss: 0.4951(0.5186) Grad: 8876.3418  LR: 0.00001492  \n","Epoch: [2][800/2032] Elapsed 3m 41s (remain 5m 40s) Loss: 0.6430(0.5179) Grad: 14397.1270  LR: 0.00001458  \n","Epoch: [2][900/2032] Elapsed 4m 9s (remain 5m 12s) Loss: 0.5809(0.5175) Grad: 15048.7627  LR: 0.00001424  \n","Epoch: [2][1000/2032] Elapsed 4m 36s (remain 4m 45s) Loss: 0.5607(0.5171) Grad: 18148.8125  LR: 0.00001388  \n","Epoch: [2][1100/2032] Elapsed 5m 4s (remain 4m 17s) Loss: 0.5327(0.5174) Grad: 9466.2783  LR: 0.00001353  \n","Epoch: [2][1200/2032] Elapsed 5m 32s (remain 3m 49s) Loss: 0.4871(0.5173) Grad: 24083.8828  LR: 0.00001316  \n","Epoch: [2][1300/2032] Elapsed 5m 59s (remain 3m 22s) Loss: 0.5772(0.5173) Grad: 16714.3457  LR: 0.00001279  \n","Epoch: [2][1400/2032] Elapsed 6m 27s (remain 2m 54s) Loss: 0.3931(0.5170) Grad: 6098.0093  LR: 0.00001242  \n","Epoch: [2][1500/2032] Elapsed 6m 54s (remain 2m 26s) Loss: 0.5002(0.5170) Grad: 23821.9531  LR: 0.00001204  \n","Epoch: [2][1600/2032] Elapsed 7m 22s (remain 1m 59s) Loss: 0.6913(0.5171) Grad: 221849.2188  LR: 0.00001166  \n","Epoch: [2][1700/2032] Elapsed 7m 50s (remain 1m 31s) Loss: 0.4758(0.5176) Grad: 9064.5723  LR: 0.00001128  \n","Epoch: [2][1800/2032] Elapsed 8m 18s (remain 1m 3s) Loss: 0.4764(0.5172) Grad: 8141.9590  LR: 0.00001090  \n","Epoch: [2][1900/2032] Elapsed 8m 45s (remain 0m 36s) Loss: 0.6042(0.5173) Grad: 44032.2930  LR: 0.00001051  \n","Epoch: [2][2000/2032] Elapsed 9m 13s (remain 0m 8s) Loss: 0.6139(0.5172) Grad: 35254.8359  LR: 0.00001013  \n","Epoch: [2][2031/2032] Elapsed 9m 21s (remain 0m 0s) Loss: 0.5857(0.5172) Grad: 9999.3574  LR: 0.00001001  \n","EVAL: [0/247] Elapsed 0m 0s (remain 3m 3s) Loss: 0.4521(0.4521) \n","EVAL: [100/247] Elapsed 0m 16s (remain 0m 24s) Loss: 0.5956(0.5566) \n","EVAL: [200/247] Elapsed 0m 32s (remain 0m 7s) Loss: 0.7722(0.5592) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5172  avg_val_loss: 0.5521  time: 602s\n","Epoch 2 - Score: 0.8257\n","Epoch 2 - Save Best Score: 0.8257 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [246/247] Elapsed 0m 40s (remain 0m 0s) Loss: 0.4064(0.5521) \n","Epoch: [3][0/2032] Elapsed 0m 0s (remain 31m 39s) Loss: 0.5194(0.5194) Grad: 26532.4258  LR: 0.00001000  \n","Epoch: [3][100/2032] Elapsed 0m 29s (remain 9m 22s) Loss: 0.2864(0.4902) Grad: 31868.8516  LR: 0.00000962  \n","Epoch: [3][200/2032] Elapsed 0m 57s (remain 8m 43s) Loss: 0.5361(0.4975) Grad: 37621.1133  LR: 0.00000923  \n","Epoch: [3][300/2032] Elapsed 1m 25s (remain 8m 8s) Loss: 0.4855(0.4967) Grad: 8081.8008  LR: 0.00000885  \n","Epoch: [3][400/2032] Elapsed 1m 52s (remain 7m 38s) Loss: 0.5028(0.4988) Grad: 18498.2832  LR: 0.00000846  \n","Epoch: [3][500/2032] Elapsed 2m 20s (remain 7m 9s) Loss: 0.4799(0.4998) Grad: 70841.7344  LR: 0.00000808  \n","Epoch: [3][600/2032] Elapsed 2m 48s (remain 6m 40s) Loss: 0.4990(0.5005) Grad: 22649.0293  LR: 0.00000770  \n","Epoch: [3][700/2032] Elapsed 3m 15s (remain 6m 11s) Loss: 0.5065(0.4994) Grad: 24048.4785  LR: 0.00000733  \n","Epoch: [3][800/2032] Elapsed 3m 43s (remain 5m 43s) Loss: 0.5812(0.4992) Grad: 72509.1484  LR: 0.00000696  \n","Epoch: [3][900/2032] Elapsed 4m 11s (remain 5m 15s) Loss: 0.4910(0.4991) Grad: 16657.8613  LR: 0.00000659  \n","Epoch: [3][1000/2032] Elapsed 4m 39s (remain 4m 47s) Loss: 0.5129(0.5002) Grad: 14025.9561  LR: 0.00000623  \n","Epoch: [3][1100/2032] Elapsed 5m 6s (remain 4m 19s) Loss: 0.4562(0.5003) Grad: 16025.2061  LR: 0.00000588  \n","Epoch: [3][1200/2032] Elapsed 5m 34s (remain 3m 51s) Loss: 0.4314(0.5003) Grad: 20165.2930  LR: 0.00000553  \n","Epoch: [3][1300/2032] Elapsed 6m 1s (remain 3m 23s) Loss: 0.5829(0.4999) Grad: 71901.2109  LR: 0.00000519  \n","Epoch: [3][1400/2032] Elapsed 6m 29s (remain 2m 55s) Loss: 0.6221(0.4996) Grad: 25326.8945  LR: 0.00000485  \n","Epoch: [3][1500/2032] Elapsed 6m 57s (remain 2m 27s) Loss: 0.4353(0.4991) Grad: 19750.2598  LR: 0.00000453  \n","Epoch: [3][1600/2032] Elapsed 7m 24s (remain 1m 59s) Loss: 0.6421(0.4994) Grad: 68907.2188  LR: 0.00000421  \n","Epoch: [3][1700/2032] Elapsed 7m 52s (remain 1m 31s) Loss: 0.5418(0.5005) Grad: 19841.5312  LR: 0.00000390  \n","Epoch: [3][1800/2032] Elapsed 8m 20s (remain 1m 4s) Loss: 0.4421(0.5001) Grad: 24168.8320  LR: 0.00000359  \n","Epoch: [3][1900/2032] Elapsed 8m 47s (remain 0m 36s) Loss: 0.5442(0.5005) Grad: 12770.5996  LR: 0.00000330  \n","Epoch: [3][2000/2032] Elapsed 9m 15s (remain 0m 8s) Loss: 0.6084(0.5009) Grad: 70917.4844  LR: 0.00000302  \n","Epoch: [3][2031/2032] Elapsed 9m 24s (remain 0m 0s) Loss: 0.5127(0.5011) Grad: 25190.7461  LR: 0.00000294  \n","EVAL: [0/247] Elapsed 0m 0s (remain 3m 6s) Loss: 0.4728(0.4728) \n","EVAL: [100/247] Elapsed 0m 16s (remain 0m 24s) Loss: 0.6361(0.5641) \n","EVAL: [200/247] Elapsed 0m 32s (remain 0m 7s) Loss: 0.8593(0.5672) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5011  avg_val_loss: 0.5578  time: 604s\n","Epoch 3 - Score: 0.8282\n","Epoch 3 - Save Best Score: 0.8282 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [246/247] Elapsed 0m 40s (remain 0m 0s) Loss: 0.4297(0.5578) \n","Epoch: [4][0/2032] Elapsed 0m 0s (remain 30m 44s) Loss: 0.5932(0.5932) Grad: 16210.5605  LR: 0.00000293  \n","Epoch: [4][100/2032] Elapsed 0m 29s (remain 9m 23s) Loss: 0.5792(0.4926) Grad: 45303.5312  LR: 0.00000266  \n","Epoch: [4][200/2032] Elapsed 0m 57s (remain 8m 42s) Loss: 0.4034(0.4948) Grad: 77553.5938  LR: 0.00000241  \n","Epoch: [4][300/2032] Elapsed 1m 25s (remain 8m 9s) Loss: 0.4866(0.4954) Grad: 311015.4688  LR: 0.00000216  \n","Epoch: [4][400/2032] Elapsed 1m 52s (remain 7m 38s) Loss: 0.5299(0.4952) Grad: 24813.6406  LR: 0.00000193  \n","Epoch: [4][500/2032] Elapsed 2m 20s (remain 7m 9s) Loss: 0.4499(0.4948) Grad: 311537.5625  LR: 0.00000171  \n","Epoch: [4][600/2032] Elapsed 2m 48s (remain 6m 40s) Loss: 0.3960(0.4945) Grad: 28969.3398  LR: 0.00000150  \n","Epoch: [4][700/2032] Elapsed 3m 15s (remain 6m 11s) Loss: 0.4403(0.4949) Grad: 101371.0781  LR: 0.00000130  \n","Epoch: [4][800/2032] Elapsed 3m 43s (remain 5m 43s) Loss: 0.5335(0.4952) Grad: 29493.7754  LR: 0.00000112  \n","Epoch: [4][900/2032] Elapsed 4m 11s (remain 5m 15s) Loss: 0.4957(0.4937) Grad: 149778.0312  LR: 0.00000094  \n","Epoch: [4][1000/2032] Elapsed 4m 38s (remain 4m 47s) Loss: 0.4559(0.4940) Grad: 320102.1562  LR: 0.00000079  \n","Epoch: [4][1100/2032] Elapsed 5m 6s (remain 4m 19s) Loss: 0.4525(0.4939) Grad: 36303.8398  LR: 0.00000064  \n","Epoch: [4][1200/2032] Elapsed 5m 34s (remain 3m 51s) Loss: 0.4725(0.4932) Grad: 45552.7617  LR: 0.00000051  \n","Epoch: [4][1300/2032] Elapsed 6m 1s (remain 3m 23s) Loss: 0.4688(0.4934) Grad: 34538.2070  LR: 0.00000040  \n","Epoch: [4][1400/2032] Elapsed 6m 29s (remain 2m 55s) Loss: 0.5091(0.4934) Grad: 47993.0078  LR: 0.00000030  \n","Epoch: [4][1500/2032] Elapsed 6m 57s (remain 2m 27s) Loss: 0.5730(0.4933) Grad: 33183.0742  LR: 0.00000021  \n","Epoch: [4][1600/2032] Elapsed 7m 24s (remain 1m 59s) Loss: 0.4316(0.4936) Grad: 26493.4570  LR: 0.00000014  \n","Epoch: [4][1700/2032] Elapsed 7m 52s (remain 1m 31s) Loss: 0.5545(0.4939) Grad: 36731.0117  LR: 0.00000008  \n","Epoch: [4][1800/2032] Elapsed 8m 20s (remain 1m 4s) Loss: 0.5156(0.4943) Grad: 79374.1875  LR: 0.00000004  \n","Epoch: [4][1900/2032] Elapsed 8m 47s (remain 0m 36s) Loss: 0.4463(0.4941) Grad: 36994.1875  LR: 0.00000001  \n","Epoch: [4][2000/2032] Elapsed 9m 15s (remain 0m 8s) Loss: 0.5384(0.4941) Grad: 88892.1797  LR: 0.00000000  \n","Epoch: [4][2031/2032] Elapsed 9m 23s (remain 0m 0s) Loss: 0.4691(0.4942) Grad: 24638.7207  LR: 0.00000000  \n","EVAL: [0/247] Elapsed 0m 0s (remain 3m 1s) Loss: 0.4895(0.4895) \n","EVAL: [100/247] Elapsed 0m 16s (remain 0m 24s) Loss: 0.6889(0.5804) \n","EVAL: [200/247] Elapsed 0m 32s (remain 0m 7s) Loss: 0.9043(0.5843) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4942  avg_val_loss: 0.5741  time: 604s\n","Epoch 4 - Score: 0.8240\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [246/247] Elapsed 0m 39s (remain 0m 0s) Loss: 0.4131(0.5741) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 9 result ==========\n","Score: 0.8282\n","========== CV ==========\n","Score: 0.8294\n"]},{"data":{"text/html":["Waiting for W\u0026B process to finish... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6eb07ad6193a4eb489a249e6a56161d1","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▁██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e█▅▆▆▄▄▆▃▄▅▄▃▃▅▃▄▃▆▁▂▄▅▆▅▅▃▆▂▅▄▂▅▃▅▄▄▄▄▆▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e▁▇▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▃▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e▄▅▃█▅▅▃▅▄▅▃▄▄▃▂▄▅▃▄▃▃▃▃▅▂▄▄▂▃▃▂▃▁▃▃▄▃▃▁▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e▁█▆▆\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e▂▁▄█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e█▄▆▅▄█▄▆▅▅▅▅▄▅▅▅▆▂▁▅▁▂▅▃▃▂▃▄▃▅▆▇▄▅▂▅▄▂▄▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e▁██▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▁▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e▃▅▄▅▃▇▅▄▄▄▄▅▅█▄▅▄▄▃▂▆▃▃▅▆▅▅▄▄▄▅▄▁▄▂▄▅▂▃▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e▁██▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▄▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] loss\u003c/td\u003e\u003ctd\u003e█▅▄▅▃▂▅▃▅▃█▅▃▆▄▆▂▃▁▄▂▄▃▆▄▂▆▁▅▂▅▂▁▃▃▄▄▆▄▅\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] score\u003c/td\u003e\u003ctd\u003e▁██▆\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] loss\u003c/td\u003e\u003ctd\u003e▆▅▄▇▆▄▂▆▃▆▃▄▆▃▆▂▆▆▄▄█▇▁█▃▄▄▄▅▄▂▆▃▂▄▅▅█▂▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] score\u003c/td\u003e\u003ctd\u003e▁▇██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_val_loss\u003c/td\u003e\u003ctd\u003e▄▁▅█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] loss\u003c/td\u003e\u003ctd\u003e▆▆▅▃▅█▅▄▇▅▆▅▅▃▅▄▇▅▄█▄▇▅▄▃▃▅▄▅▃▆▅▃▄▅▂▁▆▇▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▃▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] score\u003c/td\u003e\u003ctd\u003e▁█▆▅\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▄▇█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] loss\u003c/td\u003e\u003ctd\u003e▇█▆▆▆▆█▇██▄▅▇▆▆▃▆▅▇▄▄▄▄▆▆▅▄▆▅▃▃▁▇▅▄▆▅▃▃▆\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] score\u003c/td\u003e\u003ctd\u003e▁█▅▅\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▃▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▂▂█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] loss\u003c/td\u003e\u003ctd\u003e▆▆█▇▃▅▅▃▆▅▇▁█▅▂▄▆▆▇▆▄▅▅▄▅▄▃▃▅▃▆▃▃▅▄▄▅▄▄▆\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] score\u003c/td\u003e\u003ctd\u003e▁▅██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▁▃█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] loss\u003c/td\u003e\u003ctd\u003e▇▄█▅▅▄▃▂▇▇▁▆▃▅▃▃▃▂▄▆▅▃▇▅▅▅▄▅▅▅▃▂▄▄▆▇▂▆▄▃\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] score\u003c/td\u003e\u003ctd\u003e▁▆█▄\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49458\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.57965\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e0.46009\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e0.81036\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49374\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.56513\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e0.5882\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e0.83969\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49835\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.55612\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e0.52147\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e0.83623\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.4962\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.56963\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e0.52684\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e0.8273\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49519\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.5756\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] loss\u003c/td\u003e\u003ctd\u003e0.55714\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold4] score\u003c/td\u003e\u003ctd\u003e0.82329\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49516\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.57787\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] loss\u003c/td\u003e\u003ctd\u003e0.63415\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold5] score\u003c/td\u003e\u003ctd\u003e0.81268\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.498\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.55804\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] loss\u003c/td\u003e\u003ctd\u003e0.57868\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold6] score\u003c/td\u003e\u003ctd\u003e0.83416\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49733\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.54499\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] loss\u003c/td\u003e\u003ctd\u003e0.48972\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold7] score\u003c/td\u003e\u003ctd\u003e0.83988\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49906\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.55692\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] loss\u003c/td\u003e\u003ctd\u003e0.59759\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold8] score\u003c/td\u003e\u003ctd\u003e0.83147\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49422\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.57414\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] loss\u003c/td\u003e\u003ctd\u003e0.46907\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold9] score\u003c/td\u003e\u003ctd\u003e0.82397\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced \u003cstrong style=\"color:#cdcd00\"\u003eexp003.002\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching/runs/kci59mo9\" target=\"_blank\"\u003ehttps://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching/runs/kci59mo9\u003c/a\u003e\u003cbr/\u003eSynced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e../input/nb005t-deberta-v3-large/wandb/run-20220618_234513-kci59mo9/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:\u003c.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()\n","\n","\n","\n","\n","    # Push to LINE\n","    import requests\n","\n","    def send_line_notification(message):\n","        import json\n","        f = open(\"../../line.json\", \"r\")\n","        json_data = json.load(f)\n","        line_token = json_data[\"kagglePush\"]\n","        endpoint = 'https://notify-api.line.me/api/notify'\n","        message = \"\\n{}\".format(message)\n","        payload = {'message': message}\n","        headers = {'Authorization': 'Bearer {}'.format(line_token)}\n","        requests.post(endpoint, data=payload, headers=headers)\n","\n","    if CFG.wandb:\n","        send_line_notification(f\"Training of {CFG.wandbproject+'/'+CFG.wandbgroup+'/'+CFG.wandbname} has been done. See {run.url}\")\n","    else:\n","        send_line_notification(f\"Training of {CFG.wandbproject+'/'+CFG.wandbgroup+'/'+CFG.wandbname} has been done.\")"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"nb005t-deberta-v3-large.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"088fad03b258409e8da86cf7cd8a7350":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"179373f9a51d4c5eb5fc9f48326c2d9a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"348fbcb90a674b908c8c1f781d50fd99":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"361028ef37d34c76b5c732fa6246aa83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3ae35f492a79477bac9bbb59eb42fe61":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4072e0966884414dbc918c24cb189af8":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a33be352e3c44d0bb9c5d45a4d5dcf9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c55b3283c78424cab128644d6a4fc78","placeholder":"​","style":"IPY_MODEL_7d0575f090964725909560822acee989","value":" 36473/36473 [00:03\u0026lt;00:00, 11502.70it/s]"}},"4fc63b184c8d4fc7bb2cefd21834ea65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_714bd691000d46afbec37991a36a84b6","placeholder":"​","style":"IPY_MODEL_a73979c8263a4b68a697cac0b45730a6","value":" 136/136 [00:00\u0026lt;00:00, 2077.39it/s]"}},"505290ab262d424f934afb4b8ba39596":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_52ec2b32156b4949895ee9a4eaf0b33d","IPY_MODEL_93aa167402ea42a4a828857fa5d2147c","IPY_MODEL_4a33be352e3c44d0bb9c5d45a4d5dcf9"],"layout":"IPY_MODEL_179373f9a51d4c5eb5fc9f48326c2d9a"}},"52ec2b32156b4949895ee9a4eaf0b33d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4072e0966884414dbc918c24cb189af8","placeholder":"​","style":"IPY_MODEL_a6a0e73b676949269825e589540e8207","value":"100%"}},"5a2eef87a7854c6f9bbe0d60fb34ea96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_348fbcb90a674b908c8c1f781d50fd99","placeholder":"​","style":"IPY_MODEL_8fbd65b2c44f4a07b39a3475ad602f6b","value":"100%"}},"5c55b3283c78424cab128644d6a4fc78":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"714bd691000d46afbec37991a36a84b6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"796a43f783c94d0e96bd207baeb21c98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e539e6abcd964374be406fbabbb0ed8b","placeholder":"​","style":"IPY_MODEL_9e9446181bae4bc0ac24dd34e9d5de98","value":"100%"}},"7c3184059c3e42cc8eacded19dfe5dda":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d0575f090964725909560822acee989":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c3472838d994350b94de7967c409d73":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c3184059c3e42cc8eacded19dfe5dda","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f188ca124b0344efb921290ffa64d3a7","value":36473}},"8fbd65b2c44f4a07b39a3475ad602f6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"93aa167402ea42a4a828857fa5d2147c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a296ab7ae84a4d448d2b086a2fb9cc23","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_361028ef37d34c76b5c732fa6246aa83","value":36473}},"9d7bdd5ea15243b0a272a1c8846cddbe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_796a43f783c94d0e96bd207baeb21c98","IPY_MODEL_cc48ad54ac404505bc2f9201feb77ed4","IPY_MODEL_4fc63b184c8d4fc7bb2cefd21834ea65"],"layout":"IPY_MODEL_c9ee137cf8ac43b79ba269d830008755"}},"9e9446181bae4bc0ac24dd34e9d5de98":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a296ab7ae84a4d448d2b086a2fb9cc23":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6a0e73b676949269825e589540e8207":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a73979c8263a4b68a697cac0b45730a6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bd8ec0d8060144f0abcc2faf45c24328":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5a2eef87a7854c6f9bbe0d60fb34ea96","IPY_MODEL_8c3472838d994350b94de7967c409d73","IPY_MODEL_be4abade0a8d49a09f883aadf120591b"],"layout":"IPY_MODEL_3ae35f492a79477bac9bbb59eb42fe61"}},"be24645912dd4752bdb3d87b35630611":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be4abade0a8d49a09f883aadf120591b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be24645912dd4752bdb3d87b35630611","placeholder":"​","style":"IPY_MODEL_c6a26b1c00114ec0b87b137d4e655780","value":" 36473/36473 [00:03\u0026lt;00:00, 12207.70it/s]"}},"c6a26b1c00114ec0b87b137d4e655780":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c9ee137cf8ac43b79ba269d830008755":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cc48ad54ac404505bc2f9201feb77ed4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_088fad03b258409e8da86cf7cd8a7350","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e1352ea5a1b14bf6867c75ffc98e58b9","value":136}},"e1352ea5a1b14bf6867c75ffc98e58b9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e539e6abcd964374be406fbabbb0ed8b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f188ca124b0344efb921290ffa64d3a7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}}}}},"nbformat":4,"nbformat_minor":0}