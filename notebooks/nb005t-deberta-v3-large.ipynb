{"cells":[{"cell_type":"markdown","metadata":{"id":"e460cbb5"},"source":["# About this notebook\n","- tokenizer(anchor[SEP]target | CPC)\n","- Deberta-v3-large starter code\n","- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/pppm-pip-wheels)\n","- Inference notebook is [here](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n","\n","If this notebook is helpful, feel free to upvote :)"]},{"cell_type":"markdown","metadata":{"id":"xONchFYMvMMf"},"source":["# Directory settings"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2614,"status":"ok","timestamp":1655687932134,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"fa3b873b","outputId":"e4296125-21c9-4d48-9188-f98afc234026"},"outputs":[{"output_type":"stream","name":"stdout","text":["3.7.13 (default, Apr 24 2022, 01:04:09) \n","[GCC 7.5.0]\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/colab_notebooks/kaggle/us-patent-phrase-to-phrase-matching/notebooks\n"]}],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","comp_name = 'us-patent-phrase-to-phrase-matching'\n","nb_name = 'nb005t-deberta-v3-large'\n","\n","import sys\n","print(sys.version)\n","if \"google.colab\" in sys.modules:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    base = f\"/content/drive/MyDrive/colab_notebooks/kaggle/{comp_name}/notebooks\"\n","    %cd {base}\n","\n","\n","import os\n","INPUT_DIR = f'../input/{comp_name}/'\n","if 'kaggle_web_client' in sys.modules:\n","    OUTPUT_DIR = './'\n","else:\n","    OUTPUT_DIR = f'../input/{nb_name}/'\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"1d0c4430"},"source":["# CFG"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1655687932135,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"48dd82bb"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    wandb=True\n","    wandbproject=comp_name\n","    wandbgroup=nb_name\n","    wandbname='exp003.003'\n","    _wandb_kernel='riow1983'\n","    apex=True\n","    print_freq=100\n","    num_workers=8\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=16\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    #### AWP\n","    adv_lr=1e-6\n","    adv_eps=1e-3\n","    #### AWPAWP\n","    n_fold=10\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]\n","    CFG.wandb = False"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":18916,"status":"ok","timestamp":1655687951043,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"b88c983e","colab":{"base_uri":"https://localhost:8080/","height":965},"outputId":"157e4fd6-c014-4cc0-b2db-ab78c057ebfd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting wandb\n","  Downloading wandb-0.12.18-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 14.0 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Collecting shortuuid>=0.5.0\n","  Downloading shortuuid-1.0.9-py3-none-any.whl (9.4 kB)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Collecting setproctitle\n","  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n","Collecting GitPython>=1.0.0\n","  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n","\u001b[K     |████████████████████████████████| 181 kB 73.8 MB/s \n","\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Collecting sentry-sdk>=1.0.0\n","  Downloading sentry_sdk-1.5.12-py2.py3-none-any.whl (145 kB)\n","\u001b[K     |████████████████████████████████| 145 kB 85.8 MB/s \n","\u001b[?25hCollecting pathtools\n","  Downloading pathtools-0.1.2.tar.gz (11 kB)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Collecting gitdb<5,>=4.0.1\n","  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n","\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n","\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.1.1)\n","Collecting smmap<6,>=3.0.1\n","  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.6.15)\n","Building wheels for collected packages: pathtools\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=0f67b13f32b7ff2c7c1b383f1b5d351856ae95c53b3f418672b18866ec9326a0\n","  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n","Successfully built pathtools\n","Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n","Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.12 setproctitle-1.2.3 shortuuid-1.0.9 smmap-5.0.0 wandb-0.12.18\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mriow1983\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.12.18"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>../input/nb005t-deberta-v3-large/wandb/run-20220620_011904-zgha65g9</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching/runs/zgha65g9\" target=\"_blank\">exp003.003</a></strong> to <a href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["wandb run id: zgha65g9\n"]}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    if 'google.colab' in sys.modules:\n","        !pip install wandb\n","    import wandb\n","\n","    try:\n","        if 'kaggle_web_client' in sys.modules:\n","            from kaggle_secrets import UserSecretsClient\n","            user_secrets = UserSecretsClient()\n","            secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        else:\n","            import json\n","            f = open(\"../../wandb.json\", \"r\")\n","            json_data = json.load(f)\n","            secret_value_0 = json_data[\"wandb_api\"]\n","        wandb.login(key=secret_value_0)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","    \n","    run = wandb.init(\n","        dir=OUTPUT_DIR,\n","        project=CFG.wandbproject,\n","        group=CFG.wandbgroup,\n","        name=CFG.wandbname, \n","        config=class2dict(CFG),\n","        job_type=\"train\",\n","        anonymous=anony)\n","    print(f\"wandb run id: {run.id}\")"]},{"cell_type":"markdown","metadata":{"id":"f2ed8ef2"},"source":["# Library"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17259,"status":"ok","timestamp":1655687968294,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"35916341","outputId":"c622c6bc-a343-42f1-e51c-002812618a37"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.__version__: 1.11.0+cu113\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.18.0\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","\n","# # PyTorchのバージョンを1.10.1に下げる (Google Colabなのでpipでやる)\n","# os.system('pip uninstall -y torch torchvision torchaudio')\n","# os.system('pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html')\n","\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","os.system('pip uninstall -y transformers')\n","os.system('pip uninstall -y tokenizers')\n","os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels transformers')\n","os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels tokenizers')\n","# os.system('python -m pip install transformers')\n","# os.system('python -m pip install tokenizers')\n","os.system('pip install sentencepiece')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"fd586614"},"source":["# Utils"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1655687968295,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"d5c0ccc6"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"cb3d8e1e"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":36,"status":"ok","timestamp":1655687968300,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"bef012d3","outputId":"729987f3-2855-4a0f-a37a-9b74a12a8091"},"outputs":[{"output_type":"stream","name":"stdout","text":["train.shape: (145477, 6)\n","test.shape: (36, 4)\n","submission.shape: (36, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["                 id context  score     anchor                  target  is_aug\n","0  37d61fd2272659b1     A47   0.50  abatement  abatement of pollution       0\n","1  7b9652b17b68b7a4     A47   0.75  abatement          act of abating       0\n","2  36d72442aefd8232     A47   0.25  abatement         active catalyst       0\n","3  5296b0c19e1ce60e     A47   0.50  abatement     eliminating process       0\n","4  54c1e3b9184cb5b6     A47   0.00  abatement           forest region       0"],"text/html":["\n","  <div id=\"df-c883a754-d81a-427f-ae15-3f0bb5ff785d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>is_aug</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c883a754-d81a-427f-ae15-3f0bb5ff785d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c883a754-d81a-427f-ae15-3f0bb5ff785d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c883a754-d81a-427f-ae15-3f0bb5ff785d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                 id              anchor                         target context\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n","2  36baf228038e314b      lower trunnion                 lower locating     B60\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"],"text/html":["\n","  <div id=\"df-87b4daf1-980e-4cd3-807e-971552e67a34\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87b4daf1-980e-4cd3-807e-971552e67a34')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-87b4daf1-980e-4cd3-807e-971552e67a34 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-87b4daf1-980e-4cd3-807e-971552e67a34');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                 id  score\n","0  4112d61851461f60      0\n","1  09e418c93a776564      0\n","2  36baf228038e314b      0\n","3  1f37ead645e7f0c8      0\n","4  71a5b6ad068d531f      0"],"text/html":["\n","  <div id=\"df-9bfa376d-41bb-415f-9bb4-6824000a0b3a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9bfa376d-41bb-415f-9bb4-6824000a0b3a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9bfa376d-41bb-415f-9bb4-6824000a0b3a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9bfa376d-41bb-415f-9bb4-6824000a0b3a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","#### AUG\n","# train = pd.read_csv(INPUT_DIR+'train.csv')\n","train = pd.read_csv('../input/kagglenb006-back-translate-aug-data/train.csv')\n","#### AUGAUG\n","# train = pd.read_csv(INPUT_DIR+'train.csv')\n","test = pd.read_csv(INPUT_DIR+'test.csv')\n","submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n","print(f\"train.shape: {train.shape}\")\n","print(f\"test.shape: {test.shape}\")\n","print(f\"submission.shape: {submission.shape}\")\n","display(train.head())\n","display(test.head())\n","display(submission.head())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":613},"executionInfo":{"elapsed":1167,"status":"ok","timestamp":1655687969448,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"UCsnldv5vMMq","outputId":"507658a3-159b-4fa0-ab15-f702bf077084"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                 id context  score     anchor                  target  is_aug                                       context_text\n","0  37d61fd2272659b1     A47   0.50  abatement  abatement of pollution       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4     A47   0.75  abatement          act of abating       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232     A47   0.25  abatement         active catalyst       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e     A47   0.50  abatement     eliminating process       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6     A47   0.00  abatement           forest region       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."],"text/html":["\n","  <div id=\"df-539e6c16-ae16-43e5-ab99-6206d206a4e1\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>is_aug</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-539e6c16-ae16-43e5-ab99-6206d206a4e1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-539e6c16-ae16-43e5-ab99-6206d206a4e1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-539e6c16-ae16-43e5-ab99-6206d206a4e1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                 id              anchor                         target context                                       context_text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"],"text/html":["\n","  <div id=\"df-7c3cd37e-ac08-4c82-8724-25b1e52b0fbf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","      <td>PHYSICS. OPTICS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c3cd37e-ac08-4c82-8724-25b1e52b0fbf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7c3cd37e-ac08-4c82-8724-25b1e52b0fbf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7c3cd37e-ac08-4c82-8724-25b1e52b0fbf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","def get_cpc_texts():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('../input/cpc-data/CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'../input/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","cpc_texts = get_cpc_texts()\n","torch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\n","train['context_text'] = train['context'].map(cpc_texts)\n","test['context_text'] = test['context'].map(cpc_texts)\n","display(train.head())\n","display(test.head())"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1655687969449,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"PJvUJQujvMMr","outputId":"58d09967-898e-41be-b9c1-69d3d50d8730"},"outputs":[{"output_type":"display_data","data":{"text/plain":["                 id context  score     anchor                  target  is_aug                                       context_text                                  text                                              text2\n","0  37d61fd2272659b1     A47   0.50  abatement  abatement of pollution       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]abatement of pollution  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4     A47   0.75  abatement          act of abating       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          abatement[SEP]act of abating  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232     A47   0.25  abatement         active catalyst       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...         abatement[SEP]active catalyst  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e     A47   0.50  abatement     eliminating process       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     abatement[SEP]eliminating process  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6     A47   0.00  abatement           forest region       0  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...           abatement[SEP]forest region  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."],"text/html":["\n","  <div id=\"df-7fed4c51-ca02-4ba9-9232-d40b1eaa4627\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>is_aug</th>\n","      <th>context_text</th>\n","      <th>text</th>\n","      <th>text2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]abatement of pollution</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]act of abating</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]active catalyst</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]eliminating process</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>0</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]forest region</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fed4c51-ca02-4ba9-9232-d40b1eaa4627')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7fed4c51-ca02-4ba9-9232-d40b1eaa4627 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7fed4c51-ca02-4ba9-9232-d40b1eaa4627');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["                 id              anchor                         target context                                       context_text                                              text                                              text2\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS        opc drum[SEP]inorganic photoconductor drum                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...             adjust gas flow[SEP]altering gas flow  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...                 lower trunnion[SEP]lower locating  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...                   cap component[SEP]upper portion  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE  neural stimulation[SEP]artificial neural network      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"],"text/html":["\n","  <div id=\"df-7fd8286e-2922-483d-b714-0bdd43d9887d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>context_text</th>\n","      <th>text</th>\n","      <th>text2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","      <td>PHYSICS. OPTICS</td>\n","      <td>opc drum[SEP]inorganic photoconductor drum</td>\n","      <td>PHYSICS. OPTICS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","      <td>adjust gas flow[SEP]altering gas flow</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","      <td>lower trunnion[SEP]lower locating</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","      <td>cap component[SEP]upper portion</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","      <td>neural stimulation[SEP]artificial neural network</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7fd8286e-2922-483d-b714-0bdd43d9887d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7fd8286e-2922-483d-b714-0bdd43d9887d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7fd8286e-2922-483d-b714-0bdd43d9887d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["# train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n","\n","train['text'] = train['anchor'] + '[SEP]' + train['target']\n","test['text'] = test['anchor'] + '[SEP]' + test['target']\n","\n","train['text2'] = train['context_text']\n","test['text2'] = test['context_text']\n","\n","\n","display(train.head())\n","display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"zuhGVmnivMMs"},"source":["# EDA"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"elapsed":24,"status":"ok","timestamp":1655687969450,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"CdwSw4u5vMMs","outputId":"cb1f9bc3-3570-41e4-81a4-d5182190250a"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f2927d21090>"]},"metadata":{},"execution_count":9},{"output_type":"display_data","data":{"text/plain":["<Figure size 432x288 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["train['score'].hist()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1655687969451,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"GJBRJnjevMMs","outputId":"53e263c9-5bf3-4cb1-8094-223b78a5d40b"},"outputs":[{"output_type":"display_data","data":{"text/plain":["B    32056\n","H    24644\n","G    23870\n","C    21085\n","A    16372\n","F    16214\n","E     6122\n","D     5114\n","Name: context, dtype: int64"]},"metadata":{}}],"source":["display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"62MFTSvavMMt"},"source":["- Y is not in training data, but may be in test data?"]},{"cell_type":"markdown","metadata":{"id":"9e05b6c4"},"source":["# CV split"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3884,"status":"ok","timestamp":1655687973318,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"3ba287c4","outputId":"104e5ea5-18f5-4d0f-e9db-14900a3cc6f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["660 73\n","660 73\n","659 74\n","659 74\n","660 73\n","659 74\n","660 73\n","660 73\n","660 73\n","660 73\n","107    99241\n","108    98717\n","102    98482\n","105    98461\n","103    98329\n","101    98108\n","106    98075\n","104    97308\n","109    97165\n","100    97150\n","0       3954\n","9       3947\n","4       3902\n","6       3647\n","1       3634\n","3       3604\n","2       3524\n","5       3517\n","8       3487\n","7       3257\n","Name: fold, dtype: int64\n"]}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","# Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","# train['fold'] = train['fold'].astype(int)\n","# display(train.groupby('fold').size())\n","\n","\n","#### AUG\n","aug = train[train['is_aug']==1].reset_index(drop=True)\n","train = train[train['is_aug']==0].reset_index(drop=True)\n","#### AUGAUG\n","\n","\n","# Credits to https://www.kaggle.com/code/hannes82/pppm-deberta-v3-large-closing-the-cv-lb-gap/notebook#CV-split\n","#credits to: https://www.kaggle.com/code/abhishek/creating-folds-properly-hopefully-p\n","\n","!pip install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train = train.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")\n","del dfx\n","\n","\n","\n","#### AUG\n","res = []\n","for fold in range(CFG.n_fold):\n","    val_ids = train.loc[train['fold']==fold, 'id'].values\n","    to_add_aug = aug[~aug['id'].isin(val_ids)].reset_index(drop=True)\n","    to_add_aug['fold'] = fold+100\n","    res.append(to_add_aug)\n","\n","to_add_aug = pd.concat(res, axis=0, ignore_index=True)\n","train = pd.concat([train, to_add_aug], axis=0, ignore_index=True)\n","del aug, to_add_aug, res, val_ids\n","#### AUGAUG\n","\n","print(train.fold.value_counts())"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655687973320,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"4c3ce877"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"918a28aa"},"source":["# tokenizer"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3233,"status":"ok","timestamp":1655687976545,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"H4pgQRxAvMMv","outputId":"7e730abb-bd57-4b63-fc3d-dd33eb35e95a"},"outputs":[{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"14da40cf"},"source":["# Dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["b79b138039494721b105a1b0bd4c5fed","fa92a0bc789743d3a57236cdb41b29ed","127610ebd60e4ee9997d324dd04ded81","f63a186b2fa34e4f90e3c2866e536a35","fc09a66bc800456e9f39dbffbc80a1c5","90f58d38edbe4ab88480dd26be7555ce","8bd7307d059b47ee9c113e099c2d702e","20dd2d625fdb4dd2bab63dfea3fcafa8","1b5d82697e344c1183f9a6fa9d302d95","aeb95f4d1ce248e1ae111cdb7fcd7c14","127c4c7efdbf449abf1d0dc3e0b9d5af","73c96f639acc486e8303d30c09be1066","4d0568af34044925929947ff5fe13a51","b45c1300b2814035b7ee9bd463922740","b78d548f21f746f0b34e05d57edae04d","2fd0aec5d12c4166b1175a0daf002ce1","14075c01b071412eaf78ce645a100d36","2c97648f4a11412087307cdf1e2cabfe","3f6b449c859348a2add8ed52114d9040","bf2b2f219b6e4e1db3e41a983f2b2716","eff760ed44d746adbc80aaba1a88ebc8","179bd11a11e44342bb69e35bb9061767","72adde662b954fc09d4fd0de86e78618","4cfeaacd91694ec5ad6ce0339284652d","5e159af98d9a4edc9cf8b1d67c5a6da4","22aef91e333544629bb275b69f66594e","e24db575522b4968854a5a19cb2a2505","026cef6ad8244ff78febb5be9c4725bf","d25b54c6556a427c82cce284a9c72660","e0e9eb116cb04850bd61acd5e79da9cb","fd59fb0ba889487aa9a861ed43a640cc","5daca19182ac45b3b55f27db686b4f8b","6bba8a58025a451db5a329eda0e9ecca"]},"executionInfo":{"elapsed":169057,"status":"ok","timestamp":1655688145569,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"c00327b0","outputId":"b808c022-6c31-4872-bfad-be4128448f13"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/136 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b79b138039494721b105a1b0bd4c5fed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1017509 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"73c96f639acc486e8303d30c09be1066"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1017509 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72adde662b954fc09d4fd0de86e78618"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["max_len: 134\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","# CFG.max_len = max(max(lengths_dict['anchor'])+max(lengths_dict['target'])+3, max(lengths_dict['context_text'])+2)\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1655688145570,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"9f791a19"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text, text2):\n","    inputs = cfg.tokenizer(text, text2,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.texts2 = df['text2'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item], self.texts2[item])\n","        #inputs2 = prepare_input(self.cfg, self.texts2[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        #return inputs, inputs2, label\n","        return inputs, label"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1655688145571,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"a200bd5b","outputId":"b3bbfa19-37de-400f-98b5-052c504664e9"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\ntrain_dataset = TrainDataset(CFG, train)\\ninputs, label = train_dataset[0]\\nprint(inputs)\\nprint(label)\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":16}],"source":["\"\"\"\n","train_dataset = TrainDataset(CFG, train)\n","inputs, label = train_dataset[0]\n","print(inputs)\n","print(label)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"e04d6363"},"source":["# Model"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1655688145572,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"4c5bab44"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.attention = nn.Sequential(\n","            nn.Linear(self.config.hidden_size, 512),\n","            nn.Tanh(),\n","            nn.Linear(512, 1),\n","            nn.Softmax(dim=1)\n","        )\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","        \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        \n","        # outputs2 = self.model(**inputs2)\n","        # last_hidden_states2 = outputs2[0]\n","        \n","        # feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        #feature2 = torch.mean(last_hidden_states2, dim=1)\n","        #feature += feature2\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"deee9675"},"source":["# Helpler functions"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":470,"status":"ok","timestamp":1655688146028,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"c8263b0c"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","#### AWP\n","#def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler, score, awp):\n","#### AWPAWP\n","    model.train()\n","    # AWP\n","    #scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    # AWPAWP\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs2.items():\n","        #     inputs2[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","\n","        #### AWP\n","        if score > 0.75:\n","            awp.attack_backward(inputs['input_ids'], labels, inputs['attention_mask'], step) \n","        #### AWPAWP\n","\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs2.items():\n","        #     inputs2[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs[1].items():\n","        #     inputs[1][k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","source":["#### AWP\n","class AWP:\n","    def __init__(\n","        self,\n","        model,\n","        optimizer,\n","        adv_param=\"weight\",\n","        adv_lr=1,\n","        adv_eps=0.2,\n","        start_epoch=0,\n","        adv_step=1,\n","        scaler=None\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.start_epoch = start_epoch\n","        self.adv_step = adv_step\n","        self.backup = {}\n","        self.backup_eps = {}\n","        self.scaler = scaler\n","\n","    def attack_backward(self, x, y, attention_mask,epoch):\n","        if (self.adv_lr == 0) or (epoch < self.start_epoch):\n","            return None\n","\n","        self._save() \n","        for i in range(self.adv_step):\n","            self._attack_step() \n","            with torch.cuda.amp.autocast():\n","                adv_loss, tr_logits = self.model(input_ids=x, attention_mask=attention_mask, labels=y)\n","                adv_loss = adv_loss.mean()\n","            self.optimizer.zero_grad()\n","            self.scaler.scale(adv_loss).backward()\n","            \n","        self._restore()\n","\n","    def _attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","                # param.data.clamp_(*self.backup_eps[name])\n","\n","    def _save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def _restore(self,):\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}\n","\n","#### AWPAWP"],"metadata":{"id":"CI1gkNrPRgan","executionInfo":{"status":"ok","timestamp":1655688146029,"user_tz":-540,"elapsed":13,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1655688146031,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"bed940e1"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    \n","    #### AUG\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    train_folds_aug = train_folds[train_folds['fold']==fold+100].reset_index(drop=True)\n","    train_folds_base = train_folds[train_folds['fold']<100].reset_index(drop=True)\n","    train_folds = pd.concat([train_folds_base, train_folds_aug], axis=0, ignore_index=True)\n","    del train_folds_aug, train_folds_base\n","    #### AUGAUG\n","    # train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = 0.\n","    #### AWP\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    awp = AWP(model,\n","              optimizer,\n","              adv_lr=CFG.adv_lr,\n","              adv_eps=CFG.adv_eps,\n","              start_epoch=num_train_steps/CFG.epochs,\n","              scaler=scaler)\n","    score = 0.\n","    #### AWPAWP\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        #### AWP\n","        #avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler, score, awp)\n","        #### AWPAWP\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6cc76b1e","outputId":"2e2d1f91-37dc-474c-cbf4-34959c21c611"},"outputs":[{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/8104] Elapsed 0m 0s (remain 128m 2s) Loss: 0.6897(0.6897) Grad: 82265.1875  LR: 0.00002000  \n","Epoch: [1][100/8104] Elapsed 0m 27s (remain 36m 46s) Loss: 0.6345(0.6471) Grad: 57884.4648  LR: 0.00002000  \n","Epoch: [1][200/8104] Elapsed 0m 54s (remain 35m 42s) Loss: 0.4056(0.6240) Grad: 25806.0586  LR: 0.00002000  \n","Epoch: [1][300/8104] Elapsed 1m 21s (remain 35m 6s) Loss: 0.5177(0.6125) Grad: 42087.2617  LR: 0.00002000  \n","Epoch: [1][400/8104] Elapsed 1m 48s (remain 34m 36s) Loss: 0.5347(0.6039) Grad: 27203.1055  LR: 0.00001999  \n","Epoch: [1][500/8104] Elapsed 2m 14s (remain 34m 6s) Loss: 0.5750(0.5987) Grad: 20769.9648  LR: 0.00001999  \n","Epoch: [1][600/8104] Elapsed 2m 41s (remain 33m 38s) Loss: 0.5476(0.5919) Grad: 19834.2676  LR: 0.00001998  \n","Epoch: [1][700/8104] Elapsed 3m 8s (remain 33m 13s) Loss: 0.5240(0.5869) Grad: 24147.8984  LR: 0.00001998  \n","Epoch: [1][800/8104] Elapsed 3m 35s (remain 32m 44s) Loss: 0.5636(0.5834) Grad: 24220.3262  LR: 0.00001997  \n","Epoch: [1][900/8104] Elapsed 4m 2s (remain 32m 16s) Loss: 0.6079(0.5822) Grad: 60045.5938  LR: 0.00001996  \n","Epoch: [1][1000/8104] Elapsed 4m 28s (remain 31m 48s) Loss: 0.6406(0.5807) Grad: 48194.0586  LR: 0.00001995  \n","Epoch: [1][1100/8104] Elapsed 4m 55s (remain 31m 20s) Loss: 0.5863(0.5780) Grad: 24809.6055  LR: 0.00001994  \n","Epoch: [1][1200/8104] Elapsed 5m 22s (remain 30m 52s) Loss: 0.5712(0.5761) Grad: 23721.5234  LR: 0.00001993  \n","Epoch: [1][1300/8104] Elapsed 5m 49s (remain 30m 25s) Loss: 0.6446(0.5747) Grad: 18265.3359  LR: 0.00001992  \n","Epoch: [1][1400/8104] Elapsed 6m 15s (remain 29m 57s) Loss: 0.5873(0.5731) Grad: 23807.8320  LR: 0.00001991  \n","Epoch: [1][1500/8104] Elapsed 6m 42s (remain 29m 29s) Loss: 0.5059(0.5715) Grad: 18457.2617  LR: 0.00001989  \n","Epoch: [1][1600/8104] Elapsed 7m 9s (remain 29m 2s) Loss: 0.4797(0.5702) Grad: 10166.0742  LR: 0.00001988  \n","Epoch: [1][1700/8104] Elapsed 7m 35s (remain 28m 35s) Loss: 0.5360(0.5691) Grad: 22723.5566  LR: 0.00001986  \n","Epoch: [1][1800/8104] Elapsed 8m 2s (remain 28m 9s) Loss: 0.5878(0.5682) Grad: 82238.8516  LR: 0.00001985  \n","Epoch: [1][1900/8104] Elapsed 8m 29s (remain 27m 42s) Loss: 0.4837(0.5666) Grad: 21302.2207  LR: 0.00001983  \n","Epoch: [1][2000/8104] Elapsed 8m 56s (remain 27m 15s) Loss: 0.5864(0.5655) Grad: 20637.0137  LR: 0.00001981  \n","Epoch: [1][2100/8104] Elapsed 9m 22s (remain 26m 47s) Loss: 0.5977(0.5644) Grad: 39052.9102  LR: 0.00001979  \n","Epoch: [1][2200/8104] Elapsed 9m 49s (remain 26m 20s) Loss: 0.6053(0.5635) Grad: 59456.8828  LR: 0.00001977  \n","Epoch: [1][2300/8104] Elapsed 10m 16s (remain 25m 53s) Loss: 0.4064(0.5622) Grad: 21949.9902  LR: 0.00001975  \n","Epoch: [1][2400/8104] Elapsed 10m 42s (remain 25m 26s) Loss: 0.5122(0.5608) Grad: 51648.7148  LR: 0.00001973  \n","Epoch: [1][2500/8104] Elapsed 11m 9s (remain 25m 0s) Loss: 0.5290(0.5598) Grad: 134761.3594  LR: 0.00001971  \n","Epoch: [1][2600/8104] Elapsed 11m 36s (remain 24m 33s) Loss: 0.4141(0.5591) Grad: 25675.3457  LR: 0.00001968  \n","Epoch: [1][2700/8104] Elapsed 12m 3s (remain 24m 6s) Loss: 0.3174(0.5586) Grad: 44370.7188  LR: 0.00001966  \n","Epoch: [1][2800/8104] Elapsed 12m 29s (remain 23m 39s) Loss: 0.4626(0.5581) Grad: 36945.8828  LR: 0.00001963  \n","Epoch: [1][2900/8104] Elapsed 12m 56s (remain 23m 12s) Loss: 0.4273(0.5574) Grad: 47493.9258  LR: 0.00001961  \n","Epoch: [1][3000/8104] Elapsed 13m 23s (remain 22m 46s) Loss: 0.5763(0.5566) Grad: 85109.5391  LR: 0.00001958  \n","Epoch: [1][3100/8104] Elapsed 13m 50s (remain 22m 19s) Loss: 0.4639(0.5558) Grad: 75135.9062  LR: 0.00001955  \n","Epoch: [1][3200/8104] Elapsed 14m 17s (remain 21m 52s) Loss: 0.6095(0.5555) Grad: 25852.0742  LR: 0.00001952  \n","Epoch: [1][3300/8104] Elapsed 14m 43s (remain 21m 25s) Loss: 0.5889(0.5550) Grad: 31926.2012  LR: 0.00001949  \n","Epoch: [1][3400/8104] Elapsed 15m 10s (remain 20m 59s) Loss: 0.4155(0.5541) Grad: 15803.0752  LR: 0.00001946  \n","Epoch: [1][3500/8104] Elapsed 15m 37s (remain 20m 32s) Loss: 0.7230(0.5535) Grad: 109251.8047  LR: 0.00001943  \n","Epoch: [1][3600/8104] Elapsed 16m 4s (remain 20m 5s) Loss: 0.5120(0.5529) Grad: 41477.2422  LR: 0.00001940  \n","Epoch: [1][3700/8104] Elapsed 16m 30s (remain 19m 38s) Loss: 0.5980(0.5526) Grad: 20420.7051  LR: 0.00001936  \n","Epoch: [1][3800/8104] Elapsed 16m 57s (remain 19m 11s) Loss: 0.6076(0.5522) Grad: 75760.0547  LR: 0.00001933  \n","Epoch: [1][3900/8104] Elapsed 17m 24s (remain 18m 44s) Loss: 0.4303(0.5515) Grad: 34550.8438  LR: 0.00001929  \n","Epoch: [1][4000/8104] Elapsed 17m 50s (remain 18m 18s) Loss: 0.5593(0.5509) Grad: 36161.3125  LR: 0.00001926  \n","Epoch: [1][4100/8104] Elapsed 18m 17s (remain 17m 51s) Loss: 0.5314(0.5502) Grad: 32236.5723  LR: 0.00001922  \n","Epoch: [1][4200/8104] Elapsed 18m 44s (remain 17m 24s) Loss: 0.4765(0.5495) Grad: 69588.7500  LR: 0.00001918  \n","Epoch: [1][4300/8104] Elapsed 19m 11s (remain 16m 57s) Loss: 0.6510(0.5491) Grad: 51748.8945  LR: 0.00001914  \n","Epoch: [1][4400/8104] Elapsed 19m 37s (remain 16m 30s) Loss: 0.4935(0.5487) Grad: 145134.9062  LR: 0.00001910  \n","Epoch: [1][4500/8104] Elapsed 20m 4s (remain 16m 4s) Loss: 0.4195(0.5483) Grad: 162306.9062  LR: 0.00001906  \n","Epoch: [1][4600/8104] Elapsed 20m 31s (remain 15m 37s) Loss: 0.5631(0.5479) Grad: 94656.2500  LR: 0.00001902  \n","Epoch: [1][4700/8104] Elapsed 20m 57s (remain 15m 10s) Loss: 0.6535(0.5472) Grad: 108104.3516  LR: 0.00001898  \n","Epoch: [1][4800/8104] Elapsed 21m 24s (remain 14m 43s) Loss: 0.5850(0.5470) Grad: 57186.6641  LR: 0.00001894  \n","Epoch: [1][4900/8104] Elapsed 21m 51s (remain 14m 16s) Loss: 0.5867(0.5465) Grad: 92515.8125  LR: 0.00001889  \n","Epoch: [1][5000/8104] Elapsed 22m 17s (remain 13m 50s) Loss: 0.5169(0.5460) Grad: 129154.9688  LR: 0.00001885  \n","Epoch: [1][5100/8104] Elapsed 22m 44s (remain 13m 23s) Loss: 0.4937(0.5455) Grad: 92112.7578  LR: 0.00001880  \n","Epoch: [1][5200/8104] Elapsed 23m 11s (remain 12m 56s) Loss: 0.4221(0.5452) Grad: 68839.9297  LR: 0.00001876  \n","Epoch: [1][5300/8104] Elapsed 23m 37s (remain 12m 29s) Loss: 0.6446(0.5450) Grad: 434012.6250  LR: 0.00001871  \n","Epoch: [1][5400/8104] Elapsed 24m 4s (remain 12m 2s) Loss: 0.4432(0.5445) Grad: 19702.8984  LR: 0.00001866  \n","Epoch: [1][5500/8104] Elapsed 24m 31s (remain 11m 36s) Loss: 0.5759(0.5441) Grad: 161909.8594  LR: 0.00001861  \n","Epoch: [1][5600/8104] Elapsed 24m 58s (remain 11m 9s) Loss: 0.5200(0.5438) Grad: 77822.1016  LR: 0.00001856  \n","Epoch: [1][5700/8104] Elapsed 25m 24s (remain 10m 42s) Loss: 0.5703(0.5432) Grad: 62002.8789  LR: 0.00001851  \n","Epoch: [1][5800/8104] Elapsed 25m 51s (remain 10m 16s) Loss: 0.4806(0.5428) Grad: 75620.8984  LR: 0.00001846  \n","Epoch: [1][5900/8104] Elapsed 26m 18s (remain 9m 49s) Loss: 0.5087(0.5423) Grad: 121485.5781  LR: 0.00001841  \n","Epoch: [1][6000/8104] Elapsed 26m 45s (remain 9m 22s) Loss: 0.5466(0.5419) Grad: 32838.2891  LR: 0.00001836  \n","Epoch: [1][6100/8104] Elapsed 27m 12s (remain 8m 55s) Loss: 0.4527(0.5415) Grad: 41778.3945  LR: 0.00001830  \n","Epoch: [1][6200/8104] Elapsed 27m 38s (remain 8m 29s) Loss: 0.4901(0.5413) Grad: 111192.4453  LR: 0.00001825  \n","Epoch: [1][6300/8104] Elapsed 28m 5s (remain 8m 2s) Loss: 0.4173(0.5409) Grad: 65509.1602  LR: 0.00001819  \n","Epoch: [1][6400/8104] Elapsed 28m 32s (remain 7m 35s) Loss: 0.6049(0.5407) Grad: 913999.7500  LR: 0.00001814  \n","Epoch: [1][6500/8104] Elapsed 28m 58s (remain 7m 8s) Loss: 0.5792(0.5404) Grad: 94890.0703  LR: 0.00001808  \n","Epoch: [1][6600/8104] Elapsed 29m 25s (remain 6m 42s) Loss: 0.5902(0.5400) Grad: 324063.9375  LR: 0.00001802  \n","Epoch: [1][6700/8104] Elapsed 29m 52s (remain 6m 15s) Loss: 0.6022(0.5395) Grad: 66762.8438  LR: 0.00001796  \n","Epoch: [1][6800/8104] Elapsed 30m 18s (remain 5m 48s) Loss: 0.4371(0.5391) Grad: 231992.4844  LR: 0.00001791  \n","Epoch: [1][6900/8104] Elapsed 30m 45s (remain 5m 21s) Loss: 0.4220(0.5389) Grad: 47338.0508  LR: 0.00001785  \n","Epoch: [1][7000/8104] Elapsed 31m 12s (remain 4m 54s) Loss: 0.5073(0.5385) Grad: 224689.1406  LR: 0.00001779  \n","Epoch: [1][7100/8104] Elapsed 31m 38s (remain 4m 28s) Loss: 0.5912(0.5381) Grad: 35229.8438  LR: 0.00001772  \n","Epoch: [1][7200/8104] Elapsed 32m 5s (remain 4m 1s) Loss: 0.4482(0.5377) Grad: 193373.5781  LR: 0.00001766  \n","Epoch: [1][7300/8104] Elapsed 32m 32s (remain 3m 34s) Loss: 0.6316(0.5375) Grad: 261400.3125  LR: 0.00001760  \n","Epoch: [1][7400/8104] Elapsed 32m 58s (remain 3m 7s) Loss: 0.6365(0.5370) Grad: 96989.9609  LR: 0.00001754  \n","Epoch: [1][7500/8104] Elapsed 33m 25s (remain 2m 41s) Loss: 0.5288(0.5367) Grad: 49748.3242  LR: 0.00001747  \n","Epoch: [1][7600/8104] Elapsed 33m 52s (remain 2m 14s) Loss: 0.4230(0.5364) Grad: 78223.3359  LR: 0.00001741  \n","Epoch: [1][7700/8104] Elapsed 34m 18s (remain 1m 47s) Loss: 0.4265(0.5362) Grad: 302703.5312  LR: 0.00001734  \n","Epoch: [1][7800/8104] Elapsed 34m 45s (remain 1m 21s) Loss: 0.5737(0.5359) Grad: 263377.6250  LR: 0.00001728  \n","Epoch: [1][7900/8104] Elapsed 35m 12s (remain 0m 54s) Loss: 0.4496(0.5356) Grad: 96182.6406  LR: 0.00001721  \n","Epoch: [1][8000/8104] Elapsed 35m 38s (remain 0m 27s) Loss: 0.4351(0.5354) Grad: 35458.7344  LR: 0.00001714  \n","Epoch: [1][8100/8104] Elapsed 36m 5s (remain 0m 0s) Loss: 0.5354(0.5350) Grad: 150520.6406  LR: 0.00001707  \n","Epoch: [1][8103/8104] Elapsed 36m 6s (remain 0m 0s) Loss: 0.5577(0.5350) Grad: 60779.4727  LR: 0.00001707  \n","EVAL: [0/248] Elapsed 0m 0s (remain 2m 42s) Loss: 0.4724(0.4724) \n","EVAL: [100/248] Elapsed 0m 16s (remain 0m 24s) Loss: 0.4280(0.5505) \n","EVAL: [200/248] Elapsed 0m 32s (remain 0m 7s) Loss: 0.4339(0.5755) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5350  avg_val_loss: 0.5696  time: 2207s\n","Epoch 1 - Score: 0.8016\n","Epoch 1 - Save Best Score: 0.8016 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 40s (remain 0m 0s) Loss: 0.6349(0.5696) \n","Epoch: [2][0/8104] Elapsed 0m 0s (remain 110m 3s) Loss: 0.5642(0.5642) Grad: 36357.0859  LR: 0.00001707  \n","Epoch: [2][100/8104] Elapsed 0m 27s (remain 36m 56s) Loss: 0.4412(0.4983) Grad: 55761.8945  LR: 0.00001700  \n","Epoch: [2][200/8104] Elapsed 0m 54s (remain 35m 52s) Loss: 0.4436(0.4985) Grad: 74584.1016  LR: 0.00001693  \n","Epoch: [2][300/8104] Elapsed 1m 21s (remain 35m 11s) Loss: 0.5189(0.4987) Grad: 64352.6250  LR: 0.00001686  \n","Epoch: [2][400/8104] Elapsed 1m 48s (remain 34m 38s) Loss: 0.5403(0.4996) Grad: 51375.3281  LR: 0.00001679  \n","Epoch: [2][500/8104] Elapsed 2m 15s (remain 34m 9s) Loss: 0.5327(0.5016) Grad: 108060.3359  LR: 0.00001672  \n","Epoch: [2][600/8104] Elapsed 2m 41s (remain 33m 40s) Loss: 0.4023(0.5018) Grad: 37461.3867  LR: 0.00001665  \n","Epoch: [2][700/8104] Elapsed 3m 8s (remain 33m 10s) Loss: 0.4239(0.5023) Grad: 93362.7500  LR: 0.00001657  \n","Epoch: [2][800/8104] Elapsed 3m 35s (remain 32m 42s) Loss: 0.6007(0.5024) Grad: 176615.9219  LR: 0.00001650  \n","Epoch: [2][900/8104] Elapsed 4m 2s (remain 32m 16s) Loss: 0.6241(0.5025) Grad: 252478.9844  LR: 0.00001643  \n","Epoch: [2][1000/8104] Elapsed 4m 29s (remain 31m 48s) Loss: 0.3535(0.5035) Grad: 96023.3438  LR: 0.00001635  \n","Epoch: [2][1100/8104] Elapsed 4m 55s (remain 31m 21s) Loss: 0.4515(0.5043) Grad: 90407.3047  LR: 0.00001628  \n","Epoch: [2][1200/8104] Elapsed 5m 22s (remain 30m 54s) Loss: 0.5371(0.5048) Grad: 145473.6562  LR: 0.00001620  \n","Epoch: [2][1300/8104] Elapsed 5m 49s (remain 30m 26s) Loss: 0.4690(0.5039) Grad: 111473.8281  LR: 0.00001613  \n","Epoch: [2][1400/8104] Elapsed 6m 16s (remain 29m 59s) Loss: 0.4362(0.5051) Grad: 108024.6719  LR: 0.00001605  \n","Epoch: [2][1500/8104] Elapsed 6m 42s (remain 29m 31s) Loss: 0.6065(0.5049) Grad: 267806.1562  LR: 0.00001597  \n","Epoch: [2][1600/8104] Elapsed 7m 9s (remain 29m 4s) Loss: 0.5229(0.5045) Grad: 107170.6641  LR: 0.00001589  \n","Epoch: [2][1700/8104] Elapsed 7m 36s (remain 28m 37s) Loss: 0.3930(0.5051) Grad: 231387.1875  LR: 0.00001582  \n","Epoch: [2][1800/8104] Elapsed 8m 2s (remain 28m 10s) Loss: 0.5528(0.5053) Grad: 240794.5469  LR: 0.00001574  \n","Epoch: [2][1900/8104] Elapsed 8m 29s (remain 27m 43s) Loss: 0.5421(0.5051) Grad: 106677.2422  LR: 0.00001566  \n","Epoch: [2][2000/8104] Elapsed 8m 56s (remain 27m 15s) Loss: 0.6117(0.5051) Grad: 217483.5000  LR: 0.00001558  \n","Epoch: [2][2100/8104] Elapsed 9m 23s (remain 26m 48s) Loss: 0.4116(0.5041) Grad: 98688.6875  LR: 0.00001550  \n","Epoch: [2][2200/8104] Elapsed 9m 49s (remain 26m 21s) Loss: 0.5343(0.5037) Grad: 42471.7344  LR: 0.00001541  \n","Epoch: [2][2300/8104] Elapsed 10m 16s (remain 25m 54s) Loss: 0.4697(0.5036) Grad: 37342.6836  LR: 0.00001533  \n","Epoch: [2][2400/8104] Elapsed 10m 42s (remain 25m 27s) Loss: 0.4795(0.5035) Grad: 41602.3086  LR: 0.00001525  \n","Epoch: [2][2500/8104] Elapsed 11m 9s (remain 24m 59s) Loss: 0.5138(0.5033) Grad: 25032.8203  LR: 0.00001517  \n","Epoch: [2][2600/8104] Elapsed 11m 36s (remain 24m 33s) Loss: 0.4869(0.5033) Grad: 44946.7031  LR: 0.00001508  \n","Epoch: [2][2700/8104] Elapsed 12m 2s (remain 24m 6s) Loss: 0.5157(0.5030) Grad: 171962.0156  LR: 0.00001500  \n","Epoch: [2][2800/8104] Elapsed 12m 29s (remain 23m 39s) Loss: 0.5613(0.5031) Grad: 39322.0508  LR: 0.00001492  \n","Epoch: [2][2900/8104] Elapsed 12m 56s (remain 23m 12s) Loss: 0.5904(0.5034) Grad: 523345.5312  LR: 0.00001483  \n","Epoch: [2][3000/8104] Elapsed 13m 23s (remain 22m 45s) Loss: 0.5868(0.5036) Grad: 169502.7656  LR: 0.00001475  \n","Epoch: [2][3100/8104] Elapsed 13m 49s (remain 22m 19s) Loss: 0.5083(0.5030) Grad: 46268.9023  LR: 0.00001466  \n","Epoch: [2][3200/8104] Elapsed 14m 16s (remain 21m 52s) Loss: 0.4474(0.5029) Grad: 25798.3027  LR: 0.00001458  \n","Epoch: [2][3300/8104] Elapsed 14m 43s (remain 21m 25s) Loss: 0.5210(0.5030) Grad: 49595.0938  LR: 0.00001449  \n","Epoch: [2][3400/8104] Elapsed 15m 10s (remain 20m 58s) Loss: 0.4690(0.5030) Grad: 44375.4961  LR: 0.00001440  \n","Epoch: [2][3500/8104] Elapsed 15m 37s (remain 20m 32s) Loss: 0.4492(0.5033) Grad: 158408.1250  LR: 0.00001431  \n","Epoch: [2][3600/8104] Elapsed 16m 3s (remain 20m 5s) Loss: 0.4924(0.5034) Grad: 34760.9141  LR: 0.00001423  \n","Epoch: [2][3700/8104] Elapsed 16m 30s (remain 19m 38s) Loss: 0.5929(0.5037) Grad: 25213.3711  LR: 0.00001414  \n","Epoch: [2][3800/8104] Elapsed 16m 57s (remain 19m 11s) Loss: 0.5583(0.5039) Grad: 58591.3008  LR: 0.00001405  \n","Epoch: [2][3900/8104] Elapsed 17m 23s (remain 18m 44s) Loss: 0.5398(0.5041) Grad: 33231.4883  LR: 0.00001396  \n","Epoch: [2][4000/8104] Elapsed 17m 50s (remain 18m 17s) Loss: 0.5651(0.5041) Grad: 41770.9336  LR: 0.00001387  \n","Epoch: [2][4100/8104] Elapsed 18m 17s (remain 17m 51s) Loss: 0.5369(0.5042) Grad: 13454.6055  LR: 0.00001378  \n","Epoch: [2][4200/8104] Elapsed 18m 44s (remain 17m 24s) Loss: 0.3675(0.5043) Grad: 29820.7656  LR: 0.00001369  \n","Epoch: [2][4300/8104] Elapsed 19m 10s (remain 16m 57s) Loss: 0.4982(0.5042) Grad: 217257.7031  LR: 0.00001360  \n","Epoch: [2][4400/8104] Elapsed 19m 37s (remain 16m 30s) Loss: 0.5184(0.5041) Grad: 21703.2949  LR: 0.00001351  \n","Epoch: [2][4500/8104] Elapsed 20m 4s (remain 16m 4s) Loss: 0.5487(0.5046) Grad: 25562.0293  LR: 0.00001342  \n","Epoch: [2][4600/8104] Elapsed 20m 31s (remain 15m 37s) Loss: 0.4894(0.5044) Grad: 18398.2188  LR: 0.00001333  \n","Epoch: [2][4700/8104] Elapsed 20m 58s (remain 15m 10s) Loss: 0.3218(0.5042) Grad: 52318.8594  LR: 0.00001324  \n","Epoch: [2][4800/8104] Elapsed 21m 24s (remain 14m 43s) Loss: 0.3985(0.5045) Grad: 38955.6211  LR: 0.00001315  \n","Epoch: [2][4900/8104] Elapsed 21m 51s (remain 14m 17s) Loss: 0.4748(0.5045) Grad: 217053.7188  LR: 0.00001305  \n","Epoch: [2][5000/8104] Elapsed 22m 18s (remain 13m 50s) Loss: 0.6651(0.5042) Grad: 53016.0547  LR: 0.00001296  \n","Epoch: [2][5100/8104] Elapsed 22m 44s (remain 13m 23s) Loss: 0.4363(0.5039) Grad: 23026.9004  LR: 0.00001287  \n","Epoch: [2][5200/8104] Elapsed 23m 11s (remain 12m 56s) Loss: 0.6241(0.5038) Grad: 292176.8125  LR: 0.00001278  \n","Epoch: [2][5300/8104] Elapsed 23m 38s (remain 12m 29s) Loss: 0.6184(0.5039) Grad: 204018.1250  LR: 0.00001268  \n","Epoch: [2][5400/8104] Elapsed 24m 5s (remain 12m 3s) Loss: 0.3535(0.5037) Grad: 25045.9219  LR: 0.00001259  \n","Epoch: [2][5500/8104] Elapsed 24m 31s (remain 11m 36s) Loss: 0.4505(0.5037) Grad: 70950.7109  LR: 0.00001250  \n","Epoch: [2][5600/8104] Elapsed 24m 58s (remain 11m 9s) Loss: 0.5984(0.5037) Grad: 33760.5625  LR: 0.00001240  \n","Epoch: [2][5700/8104] Elapsed 25m 25s (remain 10m 42s) Loss: 0.4577(0.5036) Grad: 122591.5703  LR: 0.00001231  \n","Epoch: [2][5800/8104] Elapsed 25m 52s (remain 10m 16s) Loss: 0.5153(0.5035) Grad: 22130.7930  LR: 0.00001221  \n","Epoch: [2][5900/8104] Elapsed 26m 18s (remain 9m 49s) Loss: 0.5636(0.5033) Grad: 72438.3125  LR: 0.00001212  \n","Epoch: [2][6000/8104] Elapsed 26m 45s (remain 9m 22s) Loss: 0.5592(0.5033) Grad: 536731.3125  LR: 0.00001202  \n","Epoch: [2][6100/8104] Elapsed 27m 12s (remain 8m 55s) Loss: 0.4834(0.5031) Grad: 50929.8672  LR: 0.00001193  \n","Epoch: [2][6200/8104] Elapsed 27m 38s (remain 8m 29s) Loss: 0.6015(0.5030) Grad: 57658.7305  LR: 0.00001183  \n","Epoch: [2][6300/8104] Elapsed 28m 5s (remain 8m 2s) Loss: 0.4953(0.5032) Grad: 60817.8672  LR: 0.00001174  \n","Epoch: [2][6400/8104] Elapsed 28m 32s (remain 7m 35s) Loss: 0.4813(0.5033) Grad: 50670.5938  LR: 0.00001164  \n","Epoch: [2][6500/8104] Elapsed 28m 59s (remain 7m 8s) Loss: 0.4903(0.5032) Grad: 92282.0000  LR: 0.00001155  \n","Epoch: [2][6600/8104] Elapsed 29m 25s (remain 6m 42s) Loss: 0.4471(0.5031) Grad: 61642.8867  LR: 0.00001145  \n","Epoch: [2][6700/8104] Elapsed 29m 52s (remain 6m 15s) Loss: 0.4372(0.5029) Grad: 70032.5547  LR: 0.00001136  \n","Epoch: [2][6800/8104] Elapsed 30m 19s (remain 5m 48s) Loss: 0.6792(0.5028) Grad: 1096964.7500  LR: 0.00001126  \n","Epoch: [2][6900/8104] Elapsed 30m 46s (remain 5m 21s) Loss: 0.4748(0.5028) Grad: 27676.3613  LR: 0.00001116  \n","Epoch: [2][7000/8104] Elapsed 31m 12s (remain 4m 55s) Loss: 0.3586(0.5027) Grad: 77098.9766  LR: 0.00001107  \n","Epoch: [2][7100/8104] Elapsed 31m 39s (remain 4m 28s) Loss: 0.5742(0.5025) Grad: 35736.7070  LR: 0.00001097  \n","Epoch: [2][7200/8104] Elapsed 32m 6s (remain 4m 1s) Loss: 0.4358(0.5025) Grad: 68738.0547  LR: 0.00001087  \n","Epoch: [2][7300/8104] Elapsed 32m 32s (remain 3m 34s) Loss: 0.5638(0.5023) Grad: 184600.3906  LR: 0.00001078  \n","Epoch: [2][7400/8104] Elapsed 32m 59s (remain 3m 8s) Loss: 0.4107(0.5021) Grad: 65769.8516  LR: 0.00001068  \n","Epoch: [2][7500/8104] Elapsed 33m 26s (remain 2m 41s) Loss: 0.4957(0.5019) Grad: 505969.2812  LR: 0.00001058  \n","Epoch: [2][7600/8104] Elapsed 33m 53s (remain 2m 14s) Loss: 0.6075(0.5017) Grad: 377189.7500  LR: 0.00001049  \n","Epoch: [2][7700/8104] Elapsed 34m 19s (remain 1m 47s) Loss: 0.4565(0.5015) Grad: 22441.3691  LR: 0.00001039  \n","Epoch: [2][7800/8104] Elapsed 34m 46s (remain 1m 21s) Loss: 0.3786(0.5013) Grad: 123612.2422  LR: 0.00001029  \n","Epoch: [2][7900/8104] Elapsed 35m 13s (remain 0m 54s) Loss: 0.5040(0.5013) Grad: 44712.5430  LR: 0.00001020  \n","Epoch: [2][8000/8104] Elapsed 35m 39s (remain 0m 27s) Loss: 0.4922(0.5011) Grad: 76351.7422  LR: 0.00001010  \n","Epoch: [2][8100/8104] Elapsed 36m 6s (remain 0m 0s) Loss: 0.4652(0.5009) Grad: 11309.3916  LR: 0.00001000  \n","Epoch: [2][8103/8104] Elapsed 36m 7s (remain 0m 0s) Loss: 0.4278(0.5008) Grad: 30253.1543  LR: 0.00001000  \n","EVAL: [0/248] Elapsed 0m 0s (remain 2m 42s) Loss: 0.5006(0.5006) \n","EVAL: [100/248] Elapsed 0m 16s (remain 0m 24s) Loss: 0.4101(0.5639) \n","EVAL: [200/248] Elapsed 0m 32s (remain 0m 7s) Loss: 0.5936(0.5939) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5008  avg_val_loss: 0.5919  time: 2207s\n","Epoch 2 - Score: 0.7855\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 40s (remain 0m 0s) Loss: 0.6404(0.5919) \n","Epoch: [3][0/8104] Elapsed 0m 0s (remain 109m 34s) Loss: 0.4616(0.4616) Grad: 58915.5703  LR: 0.00001000  \n","Epoch: [3][100/8104] Elapsed 0m 27s (remain 36m 13s) Loss: 0.3288(0.4898) Grad: 14916.8955  LR: 0.00000990  \n","Epoch: [3][200/8104] Elapsed 0m 54s (remain 35m 23s) Loss: 0.5239(0.4932) Grad: 18004.6992  LR: 0.00000981  \n","Epoch: [3][300/8104] Elapsed 1m 20s (remain 34m 49s) Loss: 0.4770(0.4922) Grad: 20910.7480  LR: 0.00000971  \n","Epoch: [3][400/8104] Elapsed 1m 47s (remain 34m 20s) Loss: 0.5078(0.4896) Grad: 6255.8330  LR: 0.00000961  \n","Epoch: [3][500/8104] Elapsed 2m 13s (remain 33m 51s) Loss: 0.4634(0.4925) Grad: 20350.1055  LR: 0.00000952  \n","Epoch: [3][600/8104] Elapsed 2m 40s (remain 33m 22s) Loss: 0.5468(0.4939) Grad: 40471.6484  LR: 0.00000942  \n","Epoch: [3][700/8104] Elapsed 3m 7s (remain 32m 54s) Loss: 0.4442(0.4933) Grad: 11627.3770  LR: 0.00000932  \n","Epoch: [3][800/8104] Elapsed 3m 33s (remain 32m 27s) Loss: 0.3125(0.4924) Grad: 11588.3730  LR: 0.00000922  \n","Epoch: [3][900/8104] Elapsed 4m 0s (remain 32m 0s) Loss: 0.4207(0.4925) Grad: 29207.8438  LR: 0.00000913  \n","Epoch: [3][1000/8104] Elapsed 4m 26s (remain 31m 33s) Loss: 0.4818(0.4931) Grad: 38278.0508  LR: 0.00000903  \n","Epoch: [3][1100/8104] Elapsed 4m 53s (remain 31m 6s) Loss: 0.5350(0.4932) Grad: 11945.1387  LR: 0.00000894  \n","Epoch: [3][1200/8104] Elapsed 5m 20s (remain 30m 41s) Loss: 0.5669(0.4930) Grad: 135176.2344  LR: 0.00000884  \n","Epoch: [3][1300/8104] Elapsed 5m 46s (remain 30m 14s) Loss: 0.5048(0.4931) Grad: 88547.7344  LR: 0.00000874  \n","Epoch: [3][1400/8104] Elapsed 6m 13s (remain 29m 47s) Loss: 0.4433(0.4930) Grad: 8157.1030  LR: 0.00000865  \n","Epoch: [3][1500/8104] Elapsed 6m 40s (remain 29m 21s) Loss: 0.4616(0.4931) Grad: 99489.2734  LR: 0.00000855  \n","Epoch: [3][1600/8104] Elapsed 7m 7s (remain 28m 54s) Loss: 0.4206(0.4930) Grad: 26823.7148  LR: 0.00000846  \n","Epoch: [3][1700/8104] Elapsed 7m 33s (remain 28m 28s) Loss: 0.4630(0.4924) Grad: 42576.8086  LR: 0.00000836  \n","Epoch: [3][1800/8104] Elapsed 8m 0s (remain 28m 1s) Loss: 0.4558(0.4926) Grad: 20434.5723  LR: 0.00000826  \n","Epoch: [3][1900/8104] Elapsed 8m 27s (remain 27m 34s) Loss: 0.5815(0.4923) Grad: 42711.4688  LR: 0.00000817  \n","Epoch: [3][2000/8104] Elapsed 8m 53s (remain 27m 7s) Loss: 0.5005(0.4919) Grad: 88313.6094  LR: 0.00000807  \n","Epoch: [3][2100/8104] Elapsed 9m 20s (remain 26m 40s) Loss: 0.4786(0.4920) Grad: 44766.5664  LR: 0.00000798  \n","Epoch: [3][2200/8104] Elapsed 9m 46s (remain 26m 14s) Loss: 0.3558(0.4917) Grad: 66275.3516  LR: 0.00000788  \n","Epoch: [3][2300/8104] Elapsed 10m 13s (remain 25m 47s) Loss: 0.5079(0.4914) Grad: 88286.9688  LR: 0.00000779  \n","Epoch: [3][2400/8104] Elapsed 10m 40s (remain 25m 21s) Loss: 0.5472(0.4911) Grad: 28395.8066  LR: 0.00000769  \n","Epoch: [3][2500/8104] Elapsed 11m 7s (remain 24m 55s) Loss: 0.5206(0.4905) Grad: 51883.5625  LR: 0.00000760  \n","Epoch: [3][2600/8104] Elapsed 11m 34s (remain 24m 28s) Loss: 0.3597(0.4905) Grad: 87088.0391  LR: 0.00000751  \n","Epoch: [3][2700/8104] Elapsed 12m 0s (remain 24m 1s) Loss: 0.4507(0.4907) Grad: 51309.1836  LR: 0.00000741  \n","Epoch: [3][2800/8104] Elapsed 12m 27s (remain 23m 35s) Loss: 0.3508(0.4910) Grad: 24964.3027  LR: 0.00000732  \n","Epoch: [3][2900/8104] Elapsed 12m 54s (remain 23m 8s) Loss: 0.5022(0.4912) Grad: 45398.8867  LR: 0.00000723  \n","Epoch: [3][3000/8104] Elapsed 13m 20s (remain 22m 41s) Loss: 0.4592(0.4910) Grad: 99086.2031  LR: 0.00000713  \n","Epoch: [3][3100/8104] Elapsed 13m 47s (remain 22m 14s) Loss: 0.4361(0.4913) Grad: 95565.4922  LR: 0.00000704  \n","Epoch: [3][3200/8104] Elapsed 14m 13s (remain 21m 48s) Loss: 0.5886(0.4912) Grad: 74149.5547  LR: 0.00000695  \n","Epoch: [3][3300/8104] Elapsed 14m 40s (remain 21m 21s) Loss: 0.3878(0.4914) Grad: 40195.2656  LR: 0.00000686  \n","Epoch: [3][3400/8104] Elapsed 15m 7s (remain 20m 54s) Loss: 0.4417(0.4911) Grad: 48674.1016  LR: 0.00000676  \n","Epoch: [3][3500/8104] Elapsed 15m 33s (remain 20m 27s) Loss: 0.5099(0.4911) Grad: 28227.0938  LR: 0.00000667  \n","Epoch: [3][3600/8104] Elapsed 16m 0s (remain 20m 1s) Loss: 0.4250(0.4913) Grad: 35172.6172  LR: 0.00000658  \n","Epoch: [3][3700/8104] Elapsed 16m 27s (remain 19m 34s) Loss: 0.5213(0.4913) Grad: 89077.0078  LR: 0.00000649  \n","Epoch: [3][3800/8104] Elapsed 16m 54s (remain 19m 7s) Loss: 0.4981(0.4914) Grad: 98032.4688  LR: 0.00000640  \n","Epoch: [3][3900/8104] Elapsed 17m 20s (remain 18m 41s) Loss: 0.4820(0.4914) Grad: 713728.6875  LR: 0.00000631  \n","Epoch: [3][4000/8104] Elapsed 17m 47s (remain 18m 14s) Loss: 0.5637(0.4911) Grad: 61450.2656  LR: 0.00000622  \n","Epoch: [3][4100/8104] Elapsed 18m 13s (remain 17m 47s) Loss: 0.5140(0.4910) Grad: 81609.3203  LR: 0.00000613  \n","Epoch: [3][4200/8104] Elapsed 18m 40s (remain 17m 20s) Loss: 0.4034(0.4908) Grad: 87118.1094  LR: 0.00000604  \n","Epoch: [3][4300/8104] Elapsed 19m 7s (remain 16m 54s) Loss: 0.4327(0.4907) Grad: 29085.2422  LR: 0.00000595  \n","Epoch: [3][4400/8104] Elapsed 19m 33s (remain 16m 27s) Loss: 0.5071(0.4905) Grad: 32852.9375  LR: 0.00000586  \n","Epoch: [3][4500/8104] Elapsed 20m 0s (remain 16m 0s) Loss: 0.5360(0.4904) Grad: 160365.4375  LR: 0.00000578  \n","Epoch: [3][4600/8104] Elapsed 20m 27s (remain 15m 34s) Loss: 0.3367(0.4899) Grad: 125986.1172  LR: 0.00000569  \n","Epoch: [3][4700/8104] Elapsed 20m 53s (remain 15m 7s) Loss: 0.4823(0.4897) Grad: 43693.1250  LR: 0.00000560  \n","Epoch: [3][4800/8104] Elapsed 21m 20s (remain 14m 40s) Loss: 0.5368(0.4896) Grad: 93875.7109  LR: 0.00000551  \n","Epoch: [3][4900/8104] Elapsed 21m 47s (remain 14m 14s) Loss: 0.5018(0.4896) Grad: 144725.8438  LR: 0.00000543  \n","Epoch: [3][5000/8104] Elapsed 22m 13s (remain 13m 47s) Loss: 0.6280(0.4896) Grad: 91974.7500  LR: 0.00000534  \n","Epoch: [3][5100/8104] Elapsed 22m 40s (remain 13m 21s) Loss: 0.3231(0.4895) Grad: 127001.8203  LR: 0.00000526  \n","Epoch: [3][5200/8104] Elapsed 23m 7s (remain 12m 54s) Loss: 0.3589(0.4895) Grad: 29475.2129  LR: 0.00000517  \n","Epoch: [3][5300/8104] Elapsed 23m 34s (remain 12m 27s) Loss: 0.4716(0.4893) Grad: 85316.0703  LR: 0.00000509  \n","Epoch: [3][5400/8104] Elapsed 24m 0s (remain 12m 0s) Loss: 0.4707(0.4892) Grad: 64442.9297  LR: 0.00000500  \n","Epoch: [3][5500/8104] Elapsed 24m 27s (remain 11m 34s) Loss: 0.5885(0.4893) Grad: 132166.5781  LR: 0.00000492  \n","Epoch: [3][5600/8104] Elapsed 24m 53s (remain 11m 7s) Loss: 0.4770(0.4892) Grad: 48989.8984  LR: 0.00000484  \n","Epoch: [3][5700/8104] Elapsed 25m 20s (remain 10m 40s) Loss: 0.4367(0.4891) Grad: 96813.9375  LR: 0.00000475  \n","Epoch: [3][5800/8104] Elapsed 25m 47s (remain 10m 14s) Loss: 0.4948(0.4891) Grad: 87386.1641  LR: 0.00000467  \n","Epoch: [3][5900/8104] Elapsed 26m 14s (remain 9m 47s) Loss: 0.4097(0.4893) Grad: 89797.1094  LR: 0.00000459  \n","Epoch: [3][6000/8104] Elapsed 26m 40s (remain 9m 20s) Loss: 0.5012(0.4891) Grad: 151800.2500  LR: 0.00000451  \n","Epoch: [3][6100/8104] Elapsed 27m 7s (remain 8m 54s) Loss: 0.5159(0.4889) Grad: 53292.7891  LR: 0.00000443  \n","Epoch: [3][6200/8104] Elapsed 27m 34s (remain 8m 27s) Loss: 0.3891(0.4888) Grad: 92643.1562  LR: 0.00000435  \n","Epoch: [3][6300/8104] Elapsed 28m 0s (remain 8m 0s) Loss: 0.4957(0.4888) Grad: 23975.1738  LR: 0.00000427  \n","Epoch: [3][6400/8104] Elapsed 28m 27s (remain 7m 34s) Loss: 0.6030(0.4888) Grad: 42105.3242  LR: 0.00000419  \n","Epoch: [3][6500/8104] Elapsed 28m 54s (remain 7m 7s) Loss: 0.5173(0.4888) Grad: 7037.9907  LR: 0.00000411  \n","Epoch: [3][6600/8104] Elapsed 29m 21s (remain 6m 40s) Loss: 0.4989(0.4890) Grad: 74288.3203  LR: 0.00000403  \n","Epoch: [3][6700/8104] Elapsed 29m 47s (remain 6m 14s) Loss: 0.3690(0.4892) Grad: 6599.3472  LR: 0.00000395  \n","Epoch: [3][6800/8104] Elapsed 30m 14s (remain 5m 47s) Loss: 0.4603(0.4891) Grad: 33951.9688  LR: 0.00000388  \n","Epoch: [3][6900/8104] Elapsed 30m 41s (remain 5m 20s) Loss: 0.4835(0.4890) Grad: 185714.4219  LR: 0.00000380  \n","Epoch: [3][7000/8104] Elapsed 31m 8s (remain 4m 54s) Loss: 0.4990(0.4890) Grad: 86551.0000  LR: 0.00000372  \n","Epoch: [3][7100/8104] Elapsed 31m 34s (remain 4m 27s) Loss: 0.5888(0.4890) Grad: 52340.0195  LR: 0.00000365  \n","Epoch: [3][7200/8104] Elapsed 32m 1s (remain 4m 0s) Loss: 0.4715(0.4891) Grad: 29583.8809  LR: 0.00000357  \n","Epoch: [3][7300/8104] Elapsed 32m 28s (remain 3m 34s) Loss: 0.4795(0.4891) Grad: 9845.5439  LR: 0.00000350  \n","Epoch: [3][7400/8104] Elapsed 32m 55s (remain 3m 7s) Loss: 0.2958(0.4890) Grad: 54921.9961  LR: 0.00000343  \n","Epoch: [3][7500/8104] Elapsed 33m 21s (remain 2m 40s) Loss: 0.5224(0.4888) Grad: 38113.4688  LR: 0.00000335  \n","Epoch: [3][7600/8104] Elapsed 33m 48s (remain 2m 14s) Loss: 0.4634(0.4888) Grad: 8519.0977  LR: 0.00000328  \n","Epoch: [3][7700/8104] Elapsed 34m 15s (remain 1m 47s) Loss: 0.5493(0.4888) Grad: 16201.2686  LR: 0.00000321  \n","Epoch: [3][7800/8104] Elapsed 34m 41s (remain 1m 20s) Loss: 0.4202(0.4889) Grad: 9984.7012  LR: 0.00000314  \n","Epoch: [3][7900/8104] Elapsed 35m 8s (remain 0m 54s) Loss: 0.5196(0.4889) Grad: 33978.8828  LR: 0.00000307  \n","Epoch: [3][8000/8104] Elapsed 35m 35s (remain 0m 27s) Loss: 0.4014(0.4888) Grad: 9635.5068  LR: 0.00000300  \n","Epoch: [3][8100/8104] Elapsed 36m 2s (remain 0m 0s) Loss: 0.4944(0.4888) Grad: 60686.5352  LR: 0.00000293  \n","Epoch: [3][8103/8104] Elapsed 36m 2s (remain 0m 0s) Loss: 0.3649(0.4888) Grad: 18414.9453  LR: 0.00000293  \n","EVAL: [0/248] Elapsed 0m 0s (remain 2m 45s) Loss: 0.4885(0.4885) \n","EVAL: [100/248] Elapsed 0m 16s (remain 0m 24s) Loss: 0.4042(0.5737) \n","EVAL: [200/248] Elapsed 0m 32s (remain 0m 7s) Loss: 0.5496(0.6072) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.4888  avg_val_loss: 0.6021  time: 2203s\n","Epoch 3 - Score: 0.7860\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 40s (remain 0m 0s) Loss: 0.6287(0.6021) \n","Epoch: [4][0/8104] Elapsed 0m 0s (remain 110m 55s) Loss: 0.3451(0.3451) Grad: 26007.0273  LR: 0.00000293  \n","Epoch: [4][100/8104] Elapsed 0m 27s (remain 36m 23s) Loss: 0.4770(0.4813) Grad: 36768.7969  LR: 0.00000286  \n","Epoch: [4][200/8104] Elapsed 0m 54s (remain 35m 32s) Loss: 0.4651(0.4844) Grad: 73357.6562  LR: 0.00000279  \n","Epoch: [4][300/8104] Elapsed 1m 20s (remain 34m 58s) Loss: 0.4671(0.4872) Grad: 26213.3496  LR: 0.00000273  \n","Epoch: [4][400/8104] Elapsed 1m 47s (remain 34m 31s) Loss: 0.5341(0.4864) Grad: 100819.1953  LR: 0.00000266  \n","Epoch: [4][500/8104] Elapsed 2m 14s (remain 34m 0s) Loss: 0.5695(0.4863) Grad: 30573.7539  LR: 0.00000259  \n","Epoch: [4][600/8104] Elapsed 2m 41s (remain 33m 31s) Loss: 0.4984(0.4857) Grad: 24521.9473  LR: 0.00000253  \n","Epoch: [4][700/8104] Elapsed 3m 7s (remain 33m 3s) Loss: 0.4785(0.4854) Grad: 105444.7344  LR: 0.00000247  \n","Epoch: [4][800/8104] Elapsed 3m 34s (remain 32m 35s) Loss: 0.4519(0.4864) Grad: 77174.4219  LR: 0.00000240  \n","Epoch: [4][900/8104] Elapsed 4m 1s (remain 32m 8s) Loss: 0.5254(0.4862) Grad: 37502.0547  LR: 0.00000234  \n","Epoch: [4][1000/8104] Elapsed 4m 27s (remain 31m 40s) Loss: 0.4366(0.4860) Grad: 17200.1191  LR: 0.00000228  \n","Epoch: [4][1100/8104] Elapsed 4m 54s (remain 31m 13s) Loss: 0.5072(0.4861) Grad: 18647.9004  LR: 0.00000222  \n","Epoch: [4][1200/8104] Elapsed 5m 21s (remain 30m 46s) Loss: 0.5542(0.4869) Grad: 74370.4062  LR: 0.00000216  \n","Epoch: [4][1300/8104] Elapsed 5m 48s (remain 30m 20s) Loss: 0.5413(0.4863) Grad: 33653.3828  LR: 0.00000210  \n","Epoch: [4][1400/8104] Elapsed 6m 14s (remain 29m 53s) Loss: 0.3687(0.4854) Grad: 15929.7617  LR: 0.00000204  \n","Epoch: [4][1500/8104] Elapsed 6m 41s (remain 29m 26s) Loss: 0.5188(0.4851) Grad: 56878.0430  LR: 0.00000198  \n","Epoch: [4][1600/8104] Elapsed 7m 8s (remain 29m 0s) Loss: 0.4630(0.4849) Grad: 21827.6074  LR: 0.00000192  \n","Epoch: [4][1700/8104] Elapsed 7m 35s (remain 28m 33s) Loss: 0.4902(0.4846) Grad: 2032.3116  LR: 0.00000186  \n","Epoch: [4][1800/8104] Elapsed 8m 1s (remain 28m 6s) Loss: 0.4746(0.4845) Grad: 14398.1680  LR: 0.00000181  \n","Epoch: [4][1900/8104] Elapsed 8m 28s (remain 27m 39s) Loss: 0.4452(0.4843) Grad: 11784.4043  LR: 0.00000175  \n","Epoch: [4][2000/8104] Elapsed 8m 55s (remain 27m 12s) Loss: 0.4223(0.4842) Grad: 10297.3535  LR: 0.00000170  \n","Epoch: [4][2100/8104] Elapsed 9m 22s (remain 26m 45s) Loss: 0.5171(0.4845) Grad: 14686.5684  LR: 0.00000165  \n","Epoch: [4][2200/8104] Elapsed 9m 48s (remain 26m 18s) Loss: 0.4923(0.4843) Grad: 12036.7646  LR: 0.00000159  \n","Epoch: [4][2300/8104] Elapsed 10m 15s (remain 25m 52s) Loss: 0.5145(0.4842) Grad: 12725.1270  LR: 0.00000154  \n","Epoch: [4][2400/8104] Elapsed 10m 41s (remain 25m 24s) Loss: 0.5073(0.4840) Grad: 54455.7539  LR: 0.00000149  \n","Epoch: [4][2500/8104] Elapsed 11m 8s (remain 24m 57s) Loss: 0.4964(0.4846) Grad: 5840.7095  LR: 0.00000144  \n","Epoch: [4][2600/8104] Elapsed 11m 35s (remain 24m 30s) Loss: 0.4674(0.4841) Grad: 65579.0000  LR: 0.00000139  \n","Epoch: [4][2700/8104] Elapsed 12m 1s (remain 24m 3s) Loss: 0.5652(0.4840) Grad: 46739.6953  LR: 0.00000134  \n","Epoch: [4][2800/8104] Elapsed 12m 28s (remain 23m 37s) Loss: 0.4938(0.4841) Grad: 87589.5156  LR: 0.00000129  \n","Epoch: [4][2900/8104] Elapsed 12m 55s (remain 23m 10s) Loss: 0.4364(0.4837) Grad: 8899.8633  LR: 0.00000125  \n","Epoch: [4][3000/8104] Elapsed 13m 22s (remain 22m 43s) Loss: 0.4714(0.4834) Grad: 3706.1079  LR: 0.00000120  \n","Epoch: [4][3100/8104] Elapsed 13m 48s (remain 22m 16s) Loss: 0.4196(0.4834) Grad: 2968.1819  LR: 0.00000115  \n","Epoch: [4][3200/8104] Elapsed 14m 15s (remain 21m 50s) Loss: 0.4062(0.4832) Grad: 14759.5625  LR: 0.00000111  \n","Epoch: [4][3300/8104] Elapsed 14m 41s (remain 21m 23s) Loss: 0.3782(0.4833) Grad: 19149.9883  LR: 0.00000106  \n","Epoch: [4][3400/8104] Elapsed 15m 8s (remain 20m 56s) Loss: 0.5338(0.4836) Grad: 18044.7656  LR: 0.00000102  \n","Epoch: [4][3500/8104] Elapsed 15m 35s (remain 20m 29s) Loss: 0.4464(0.4835) Grad: 19204.1445  LR: 0.00000098  \n","Epoch: [4][3600/8104] Elapsed 16m 2s (remain 20m 3s) Loss: 0.4288(0.4835) Grad: 24085.8457  LR: 0.00000094  \n","Epoch: [4][3700/8104] Elapsed 16m 28s (remain 19m 36s) Loss: 0.5144(0.4837) Grad: 18343.1191  LR: 0.00000090  \n","Epoch: [4][3800/8104] Elapsed 16m 55s (remain 19m 9s) Loss: 0.5615(0.4838) Grad: 25660.5879  LR: 0.00000086  \n","Epoch: [4][3900/8104] Elapsed 17m 22s (remain 18m 43s) Loss: 0.4711(0.4839) Grad: 11139.9189  LR: 0.00000082  \n","Epoch: [4][4000/8104] Elapsed 17m 49s (remain 18m 16s) Loss: 0.5296(0.4838) Grad: 57851.6289  LR: 0.00000078  \n","Epoch: [4][4100/8104] Elapsed 18m 15s (remain 17m 49s) Loss: 0.4284(0.4840) Grad: 1287829.2500  LR: 0.00000074  \n","Epoch: [4][4200/8104] Elapsed 18m 42s (remain 17m 23s) Loss: 0.4206(0.4842) Grad: 23550.8633  LR: 0.00000071  \n","Epoch: [4][4300/8104] Elapsed 19m 9s (remain 16m 56s) Loss: 0.4320(0.4841) Grad: 71032.9766  LR: 0.00000067  \n","Epoch: [4][4400/8104] Elapsed 19m 36s (remain 16m 29s) Loss: 0.4722(0.4845) Grad: 12900.7803  LR: 0.00000064  \n","Epoch: [4][4500/8104] Elapsed 20m 2s (remain 16m 2s) Loss: 0.4579(0.4846) Grad: 55930.9961  LR: 0.00000060  \n","Epoch: [4][4600/8104] Elapsed 20m 29s (remain 15m 36s) Loss: 0.4817(0.4845) Grad: 39016.8516  LR: 0.00000057  \n","Epoch: [4][4700/8104] Elapsed 20m 56s (remain 15m 9s) Loss: 0.4793(0.4845) Grad: 1998.8093  LR: 0.00000054  \n","Epoch: [4][4800/8104] Elapsed 21m 23s (remain 14m 42s) Loss: 0.4736(0.4845) Grad: 97220.2344  LR: 0.00000051  \n","Epoch: [4][4900/8104] Elapsed 21m 50s (remain 14m 16s) Loss: 0.3578(0.4844) Grad: 11139.1426  LR: 0.00000048  \n","Epoch: [4][5000/8104] Elapsed 22m 16s (remain 13m 49s) Loss: 0.4712(0.4844) Grad: 2652.8582  LR: 0.00000045  \n","Epoch: [4][5100/8104] Elapsed 22m 43s (remain 13m 22s) Loss: 0.4283(0.4841) Grad: 9980.6338  LR: 0.00000042  \n","Epoch: [4][5200/8104] Elapsed 23m 10s (remain 12m 56s) Loss: 0.4278(0.4841) Grad: 13683.7295  LR: 0.00000039  \n","Epoch: [4][5300/8104] Elapsed 23m 37s (remain 12m 29s) Loss: 0.3940(0.4841) Grad: 111874.7578  LR: 0.00000037  \n","Epoch: [4][5400/8104] Elapsed 24m 4s (remain 12m 2s) Loss: 0.5322(0.4842) Grad: 72463.9609  LR: 0.00000034  \n","Epoch: [4][5500/8104] Elapsed 24m 30s (remain 11m 35s) Loss: 0.4866(0.4840) Grad: 32357.4141  LR: 0.00000032  \n","Epoch: [4][5600/8104] Elapsed 24m 57s (remain 11m 9s) Loss: 0.4280(0.4838) Grad: 2864.9841  LR: 0.00000029  \n","Epoch: [4][5700/8104] Elapsed 25m 24s (remain 10m 42s) Loss: 0.3848(0.4838) Grad: 4807.7383  LR: 0.00000027  \n","Epoch: [4][5800/8104] Elapsed 25m 50s (remain 10m 15s) Loss: 0.5022(0.4839) Grad: 30655.5898  LR: 0.00000025  \n","Epoch: [4][5900/8104] Elapsed 26m 17s (remain 9m 49s) Loss: 0.5163(0.4840) Grad: 18816.1016  LR: 0.00000023  \n","Epoch: [4][6000/8104] Elapsed 26m 44s (remain 9m 22s) Loss: 0.3971(0.4842) Grad: 49235.4961  LR: 0.00000021  \n","Epoch: [4][6100/8104] Elapsed 27m 11s (remain 8m 55s) Loss: 0.3868(0.4841) Grad: 26859.2715  LR: 0.00000019  \n","Epoch: [4][6200/8104] Elapsed 27m 37s (remain 8m 28s) Loss: 0.6260(0.4841) Grad: 92088.4141  LR: 0.00000017  \n","Epoch: [4][6300/8104] Elapsed 28m 4s (remain 8m 2s) Loss: 0.4952(0.4840) Grad: 13754.4961  LR: 0.00000015  \n","Epoch: [4][6400/8104] Elapsed 28m 31s (remain 7m 35s) Loss: 0.4365(0.4840) Grad: 6853.9414  LR: 0.00000014  \n","Epoch: [4][6500/8104] Elapsed 28m 58s (remain 7m 8s) Loss: 0.4114(0.4837) Grad: 1156.6255  LR: 0.00000012  \n","Epoch: [4][6600/8104] Elapsed 29m 24s (remain 6m 41s) Loss: 0.5146(0.4837) Grad: 63474.7188  LR: 0.00000011  \n","Epoch: [4][6700/8104] Elapsed 29m 51s (remain 6m 15s) Loss: 0.4041(0.4839) Grad: 13331.3145  LR: 0.00000009  \n","Epoch: [4][6800/8104] Elapsed 30m 18s (remain 5m 48s) Loss: 0.4878(0.4839) Grad: 10630.7686  LR: 0.00000008  \n","Epoch: [4][6900/8104] Elapsed 30m 44s (remain 5m 21s) Loss: 0.5334(0.4839) Grad: 4544.4707  LR: 0.00000007  \n","Epoch: [4][7000/8104] Elapsed 31m 11s (remain 4m 54s) Loss: 0.5099(0.4838) Grad: 60507.5273  LR: 0.00000006  \n","Epoch: [4][7100/8104] Elapsed 31m 38s (remain 4m 28s) Loss: 0.5713(0.4836) Grad: 81712.2266  LR: 0.00000005  \n","Epoch: [4][7200/8104] Elapsed 32m 4s (remain 4m 1s) Loss: 0.4219(0.4837) Grad: 33992.3242  LR: 0.00000004  \n","Epoch: [4][7300/8104] Elapsed 32m 31s (remain 3m 34s) Loss: 0.4224(0.4836) Grad: 157326.4375  LR: 0.00000003  \n","Epoch: [4][7400/8104] Elapsed 32m 58s (remain 3m 7s) Loss: 0.3883(0.4836) Grad: 143405.6250  LR: 0.00000002  \n","Epoch: [4][7500/8104] Elapsed 33m 25s (remain 2m 41s) Loss: 0.5068(0.4837) Grad: 157538.0312  LR: 0.00000002  \n","Epoch: [4][7600/8104] Elapsed 33m 51s (remain 2m 14s) Loss: 0.3845(0.4836) Grad: 4931.8213  LR: 0.00000001  \n","Epoch: [4][7700/8104] Elapsed 34m 18s (remain 1m 47s) Loss: 0.5398(0.4834) Grad: 82778.6562  LR: 0.00000001  \n","Epoch: [4][7800/8104] Elapsed 34m 45s (remain 1m 20s) Loss: 0.4117(0.4833) Grad: 39410.1797  LR: 0.00000000  \n","Epoch: [4][7900/8104] Elapsed 35m 12s (remain 0m 54s) Loss: 0.4268(0.4834) Grad: 62778.1055  LR: 0.00000000  \n","Epoch: [4][8000/8104] Elapsed 35m 38s (remain 0m 27s) Loss: 0.5316(0.4833) Grad: 175325.1562  LR: 0.00000000  \n","Epoch: [4][8100/8104] Elapsed 36m 5s (remain 0m 0s) Loss: 0.5122(0.4831) Grad: 87669.5000  LR: 0.00000000  \n","Epoch: [4][8103/8104] Elapsed 36m 6s (remain 0m 0s) Loss: 0.4238(0.4831) Grad: 101673.2969  LR: 0.00000000  \n","EVAL: [0/248] Elapsed 0m 0s (remain 2m 38s) Loss: 0.4892(0.4892) \n","EVAL: [100/248] Elapsed 0m 16s (remain 0m 24s) Loss: 0.4025(0.5828) \n","EVAL: [200/248] Elapsed 0m 32s (remain 0m 7s) Loss: 0.5078(0.6176) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4831  avg_val_loss: 0.6122  time: 2207s\n","Epoch 4 - Score: 0.7814\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [247/248] Elapsed 0m 40s (remain 0m 0s) Loss: 0.6285(0.6122) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","Score: 0.8016\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Epoch: [1][0/8184] Elapsed 0m 0s (remain 105m 52s) Loss: 0.7450(0.7450) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/8184] Elapsed 0m 27s (remain 36m 36s) Loss: 0.6589(0.6554) Grad: 29620.6348  LR: 0.00002000  \n","Epoch: [1][200/8184] Elapsed 0m 54s (remain 35m 48s) Loss: 0.6550(0.6355) Grad: 29204.9824  LR: 0.00002000  \n","Epoch: [1][300/8184] Elapsed 1m 20s (remain 35m 15s) Loss: 0.5916(0.6217) Grad: 32879.5898  LR: 0.00002000  \n","Epoch: [1][400/8184] Elapsed 1m 47s (remain 34m 42s) Loss: 0.6796(0.6147) Grad: 37658.8086  LR: 0.00001999  \n","Epoch: [1][500/8184] Elapsed 2m 13s (remain 34m 10s) Loss: 0.7979(0.6089) Grad: 23743.0898  LR: 0.00001999  \n","Epoch: [1][600/8184] Elapsed 2m 40s (remain 33m 43s) Loss: 0.5208(0.6035) Grad: 31243.9551  LR: 0.00001998  \n","Epoch: [1][700/8184] Elapsed 3m 6s (remain 33m 16s) Loss: 0.6265(0.5982) Grad: 38157.2383  LR: 0.00001998  \n","Epoch: [1][800/8184] Elapsed 3m 33s (remain 32m 49s) Loss: 0.6853(0.5951) Grad: 11561.6855  LR: 0.00001997  \n","Epoch: [1][900/8184] Elapsed 4m 0s (remain 32m 22s) Loss: 0.4651(0.5907) Grad: 5646.1089  LR: 0.00001996  \n","Epoch: [1][1000/8184] Elapsed 4m 27s (remain 31m 56s) Loss: 0.5167(0.5881) Grad: 3997.2363  LR: 0.00001995  \n","Epoch: [1][1100/8184] Elapsed 4m 53s (remain 31m 28s) Loss: 0.5001(0.5864) Grad: 2942.6462  LR: 0.00001994  \n","Epoch: [1][1200/8184] Elapsed 5m 20s (remain 31m 3s) Loss: 0.5502(0.5840) Grad: 3812.9939  LR: 0.00001993  \n","Epoch: [1][1300/8184] Elapsed 5m 47s (remain 30m 36s) Loss: 0.6882(0.5819) Grad: 17540.8613  LR: 0.00001992  \n","Epoch: [1][1400/8184] Elapsed 6m 13s (remain 30m 8s) Loss: 0.6017(0.5798) Grad: 6458.4272  LR: 0.00001991  \n","Epoch: [1][1500/8184] Elapsed 6m 40s (remain 29m 41s) Loss: 0.4913(0.5790) Grad: 7396.7822  LR: 0.00001990  \n","Epoch: [1][1600/8184] Elapsed 7m 6s (remain 29m 15s) Loss: 0.5411(0.5774) Grad: 7058.4678  LR: 0.00001988  \n","Epoch: [1][1700/8184] Elapsed 7m 33s (remain 28m 48s) Loss: 0.4195(0.5753) Grad: 5901.8853  LR: 0.00001987  \n","Epoch: [1][1800/8184] Elapsed 8m 0s (remain 28m 22s) Loss: 0.7776(0.5740) Grad: 18679.6621  LR: 0.00001985  \n","Epoch: [1][1900/8184] Elapsed 8m 26s (remain 27m 55s) Loss: 0.5687(0.5732) Grad: 4136.5405  LR: 0.00001983  \n","Epoch: [1][2000/8184] Elapsed 8m 53s (remain 27m 28s) Loss: 0.5784(0.5720) Grad: 5733.5425  LR: 0.00001982  \n","Epoch: [1][2100/8184] Elapsed 9m 20s (remain 27m 1s) Loss: 0.5434(0.5707) Grad: 8405.6074  LR: 0.00001980  \n","Epoch: [1][2200/8184] Elapsed 9m 46s (remain 26m 34s) Loss: 0.4854(0.5693) Grad: 6239.0654  LR: 0.00001978  \n","Epoch: [1][2300/8184] Elapsed 10m 13s (remain 26m 8s) Loss: 0.6631(0.5680) Grad: 6081.8374  LR: 0.00001976  \n","Epoch: [1][2400/8184] Elapsed 10m 40s (remain 25m 41s) Loss: 0.4503(0.5673) Grad: 18893.0996  LR: 0.00001974  \n","Epoch: [1][2500/8184] Elapsed 11m 6s (remain 25m 15s) Loss: 0.5791(0.5665) Grad: 31473.1328  LR: 0.00001971  \n","Epoch: [1][2600/8184] Elapsed 11m 33s (remain 24m 48s) Loss: 0.5973(0.5657) Grad: 41971.2891  LR: 0.00001969  \n","Epoch: [1][2700/8184] Elapsed 12m 0s (remain 24m 21s) Loss: 0.6443(0.5648) Grad: 23214.8789  LR: 0.00001967  \n","Epoch: [1][2800/8184] Elapsed 12m 26s (remain 23m 55s) Loss: 0.4628(0.5640) Grad: 6445.3120  LR: 0.00001964  \n","Epoch: [1][2900/8184] Elapsed 12m 53s (remain 23m 28s) Loss: 0.4260(0.5633) Grad: 13566.3584  LR: 0.00001961  \n","Epoch: [1][3000/8184] Elapsed 13m 19s (remain 23m 1s) Loss: 0.5433(0.5624) Grad: 7075.4780  LR: 0.00001959  \n","Epoch: [1][3100/8184] Elapsed 13m 46s (remain 22m 34s) Loss: 0.4914(0.5618) Grad: 5592.2920  LR: 0.00001956  \n","Epoch: [1][3200/8184] Elapsed 14m 13s (remain 22m 8s) Loss: 0.4952(0.5608) Grad: 7637.5688  LR: 0.00001953  \n","Epoch: [1][3300/8184] Elapsed 14m 39s (remain 21m 41s) Loss: 0.6354(0.5600) Grad: 7397.2100  LR: 0.00001950  \n","Epoch: [1][3400/8184] Elapsed 15m 6s (remain 21m 14s) Loss: 0.5691(0.5595) Grad: 5295.5186  LR: 0.00001947  \n","Epoch: [1][3500/8184] Elapsed 15m 32s (remain 20m 47s) Loss: 0.5149(0.5583) Grad: 7147.2046  LR: 0.00001944  \n","Epoch: [1][3600/8184] Elapsed 15m 59s (remain 20m 21s) Loss: 0.5596(0.5577) Grad: 17474.6211  LR: 0.00001941  \n","Epoch: [1][3700/8184] Elapsed 16m 26s (remain 19m 54s) Loss: 0.5774(0.5574) Grad: 7634.4971  LR: 0.00001938  \n","Epoch: [1][3800/8184] Elapsed 16m 52s (remain 19m 28s) Loss: 0.4893(0.5568) Grad: 16293.1494  LR: 0.00001934  \n","Epoch: [1][3900/8184] Elapsed 17m 19s (remain 19m 1s) Loss: 0.5186(0.5563) Grad: 25320.2148  LR: 0.00001931  \n","Epoch: [1][4000/8184] Elapsed 17m 46s (remain 18m 34s) Loss: 0.5243(0.5556) Grad: 6707.0166  LR: 0.00001927  \n","Epoch: [1][4100/8184] Elapsed 18m 12s (remain 18m 8s) Loss: 0.4893(0.5553) Grad: 17652.0938  LR: 0.00001924  \n","Epoch: [1][4200/8184] Elapsed 18m 39s (remain 17m 41s) Loss: 0.6399(0.5545) Grad: 6584.8457  LR: 0.00001920  \n","Epoch: [1][4300/8184] Elapsed 19m 6s (remain 17m 14s) Loss: 0.3739(0.5542) Grad: 22722.6973  LR: 0.00001916  \n","Epoch: [1][4400/8184] Elapsed 19m 32s (remain 16m 48s) Loss: 0.4855(0.5536) Grad: 21331.5449  LR: 0.00001912  \n","Epoch: [1][4500/8184] Elapsed 19m 59s (remain 16m 21s) Loss: 0.3977(0.5533) Grad: 11616.2480  LR: 0.00001908  \n","Epoch: [1][4600/8184] Elapsed 20m 26s (remain 15m 54s) Loss: 0.5533(0.5530) Grad: 24490.5059  LR: 0.00001904  \n","Epoch: [1][4700/8184] Elapsed 20m 52s (remain 15m 28s) Loss: 0.4922(0.5524) Grad: 25169.1660  LR: 0.00001900  \n","Epoch: [1][4800/8184] Elapsed 21m 19s (remain 15m 1s) Loss: 0.4665(0.5519) Grad: 8828.8213  LR: 0.00001896  \n","Epoch: [1][4900/8184] Elapsed 21m 46s (remain 14m 35s) Loss: 0.5777(0.5513) Grad: 52253.5664  LR: 0.00001891  \n","Epoch: [1][5000/8184] Elapsed 22m 12s (remain 14m 8s) Loss: 0.5530(0.5504) Grad: 20210.3809  LR: 0.00001887  \n","Epoch: [1][5100/8184] Elapsed 22m 39s (remain 13m 41s) Loss: 0.5638(0.5502) Grad: 6190.9980  LR: 0.00001883  \n","Epoch: [1][5200/8184] Elapsed 23m 6s (remain 13m 14s) Loss: 0.5570(0.5496) Grad: 5150.9336  LR: 0.00001878  \n","Epoch: [1][5300/8184] Elapsed 23m 32s (remain 12m 48s) Loss: 0.4999(0.5491) Grad: 15234.8867  LR: 0.00001873  \n","Epoch: [1][5400/8184] Elapsed 23m 59s (remain 12m 21s) Loss: 0.5036(0.5487) Grad: 10146.3906  LR: 0.00001869  \n","Epoch: [1][5500/8184] Elapsed 24m 26s (remain 11m 55s) Loss: 0.5430(0.5483) Grad: 15064.3643  LR: 0.00001864  \n","Epoch: [1][5600/8184] Elapsed 24m 52s (remain 11m 28s) Loss: 0.5417(0.5478) Grad: 7872.5811  LR: 0.00001859  \n","Epoch: [1][5700/8184] Elapsed 25m 19s (remain 11m 1s) Loss: 0.4633(0.5474) Grad: 26346.3105  LR: 0.00001854  \n","Epoch: [1][5800/8184] Elapsed 25m 45s (remain 10m 35s) Loss: 0.4261(0.5471) Grad: 8683.1201  LR: 0.00001849  \n","Epoch: [1][5900/8184] Elapsed 26m 12s (remain 10m 8s) Loss: 0.4552(0.5467) Grad: 9647.1787  LR: 0.00001844  \n","Epoch: [1][6000/8184] Elapsed 26m 39s (remain 9m 41s) Loss: 0.4172(0.5463) Grad: 20095.1172  LR: 0.00001839  \n","Epoch: [1][6100/8184] Elapsed 27m 6s (remain 9m 15s) Loss: 0.5858(0.5458) Grad: 8748.0664  LR: 0.00001833  \n","Epoch: [1][6200/8184] Elapsed 27m 32s (remain 8m 48s) Loss: 0.5465(0.5455) Grad: 17795.4219  LR: 0.00001828  \n","Epoch: [1][6300/8184] Elapsed 27m 59s (remain 8m 22s) Loss: 0.5465(0.5450) Grad: 10924.6562  LR: 0.00001823  \n","Epoch: [1][6400/8184] Elapsed 28m 26s (remain 7m 55s) Loss: 0.5148(0.5445) Grad: 28550.9238  LR: 0.00001817  \n","Epoch: [1][6500/8184] Elapsed 28m 53s (remain 7m 28s) Loss: 0.5715(0.5439) Grad: 19793.0312  LR: 0.00001812  \n","Epoch: [1][6600/8184] Elapsed 29m 20s (remain 7m 2s) Loss: 0.5250(0.5434) Grad: 24414.8711  LR: 0.00001806  \n","Epoch: [1][6700/8184] Elapsed 29m 46s (remain 6m 35s) Loss: 0.5762(0.5430) Grad: 101805.8594  LR: 0.00001800  \n","Epoch: [1][6800/8184] Elapsed 30m 13s (remain 6m 8s) Loss: 0.5138(0.5425) Grad: 28656.5586  LR: 0.00001794  \n","Epoch: [1][6900/8184] Elapsed 30m 40s (remain 5m 42s) Loss: 0.5755(0.5421) Grad: 23711.3340  LR: 0.00001789  \n","Epoch: [1][7000/8184] Elapsed 31m 7s (remain 5m 15s) Loss: 0.4783(0.5419) Grad: 30589.7266  LR: 0.00001783  \n","Epoch: [1][7100/8184] Elapsed 31m 33s (remain 4m 48s) Loss: 0.5455(0.5415) Grad: 22417.4453  LR: 0.00001777  \n","Epoch: [1][7200/8184] Elapsed 32m 0s (remain 4m 22s) Loss: 0.4230(0.5411) Grad: 33698.6562  LR: 0.00001771  \n","Epoch: [1][7300/8184] Elapsed 32m 27s (remain 3m 55s) Loss: 0.6272(0.5405) Grad: 77580.5703  LR: 0.00001764  \n","Epoch: [1][7400/8184] Elapsed 32m 54s (remain 3m 28s) Loss: 0.4895(0.5400) Grad: 17412.8945  LR: 0.00001758  \n","Epoch: [1][7500/8184] Elapsed 33m 20s (remain 3m 2s) Loss: 0.5497(0.5398) Grad: 15619.7861  LR: 0.00001752  \n","Epoch: [1][7600/8184] Elapsed 33m 47s (remain 2m 35s) Loss: 0.3851(0.5395) Grad: 27850.6973  LR: 0.00001746  \n","Epoch: [1][7700/8184] Elapsed 34m 14s (remain 2m 8s) Loss: 0.5213(0.5391) Grad: 16662.9688  LR: 0.00001739  \n","Epoch: [1][7800/8184] Elapsed 34m 41s (remain 1m 42s) Loss: 0.4323(0.5387) Grad: 40666.9219  LR: 0.00001733  \n","Epoch: [1][7900/8184] Elapsed 35m 7s (remain 1m 15s) Loss: 0.4799(0.5384) Grad: 24418.0059  LR: 0.00001726  \n","Epoch: [1][8000/8184] Elapsed 35m 34s (remain 0m 48s) Loss: 0.4945(0.5383) Grad: 45729.4570  LR: 0.00001719  \n","Epoch: [1][8100/8184] Elapsed 36m 1s (remain 0m 22s) Loss: 0.4947(0.5379) Grad: 43638.4727  LR: 0.00001713  \n","Epoch: [1][8183/8184] Elapsed 36m 23s (remain 0m 0s) Loss: 0.3591(0.5377) Grad: 29147.2559  LR: 0.00001707  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 31s) Loss: 0.6044(0.6044) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 21s) Loss: 0.3772(0.5406) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.6113(0.5531) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5377  avg_val_loss: 0.5507  time: 2221s\n","Epoch 1 - Score: 0.8283\n","Epoch 1 - Save Best Score: 0.8283 Model\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.0165(0.5507) \n","Epoch: [2][0/8184] Elapsed 0m 0s (remain 115m 51s) Loss: 0.4846(0.4846) Grad: 16742.3086  LR: 0.00001707  \n","Epoch: [2][100/8184] Elapsed 0m 27s (remain 37m 13s) Loss: 0.5306(0.5072) Grad: 55250.4336  LR: 0.00001700  \n","Epoch: [2][200/8184] Elapsed 0m 54s (remain 36m 17s) Loss: 0.4965(0.5002) Grad: 43612.1797  LR: 0.00001693  \n","Epoch: [2][300/8184] Elapsed 1m 21s (remain 35m 42s) Loss: 0.4758(0.5015) Grad: 70578.2734  LR: 0.00001686  \n","Epoch: [2][400/8184] Elapsed 1m 48s (remain 35m 4s) Loss: 0.5176(0.5021) Grad: 209920.3906  LR: 0.00001679  \n","Epoch: [2][500/8184] Elapsed 2m 15s (remain 34m 33s) Loss: 0.4480(0.5037) Grad: 28116.1543  LR: 0.00001672  \n","Epoch: [2][600/8184] Elapsed 2m 41s (remain 34m 2s) Loss: 0.3994(0.5024) Grad: 13370.5781  LR: 0.00001665  \n","Epoch: [2][700/8184] Elapsed 3m 8s (remain 33m 32s) Loss: 0.4977(0.5038) Grad: 111878.3359  LR: 0.00001658  \n","Epoch: [2][800/8184] Elapsed 3m 35s (remain 33m 4s) Loss: 0.3580(0.5036) Grad: 30858.5254  LR: 0.00001651  \n","Epoch: [2][900/8184] Elapsed 4m 2s (remain 32m 36s) Loss: 0.4282(0.5027) Grad: 48390.5039  LR: 0.00001643  \n","Epoch: [2][1000/8184] Elapsed 4m 28s (remain 32m 8s) Loss: 0.4104(0.5031) Grad: 27641.0723  LR: 0.00001636  \n","Epoch: [2][1100/8184] Elapsed 4m 55s (remain 31m 40s) Loss: 0.4948(0.5024) Grad: 112680.3047  LR: 0.00001629  \n","Epoch: [2][1200/8184] Elapsed 5m 22s (remain 31m 12s) Loss: 0.4472(0.5027) Grad: 67365.2969  LR: 0.00001621  \n","Epoch: [2][1300/8184] Elapsed 5m 48s (remain 30m 45s) Loss: 0.4978(0.5008) Grad: 266117.0312  LR: 0.00001614  \n","Epoch: [2][1400/8184] Elapsed 6m 15s (remain 30m 17s) Loss: 0.4349(0.5011) Grad: 64851.1797  LR: 0.00001606  \n","Epoch: [2][1500/8184] Elapsed 6m 42s (remain 29m 51s) Loss: 0.5697(0.5010) Grad: 40229.6133  LR: 0.00001598  \n","Epoch: [2][1600/8184] Elapsed 7m 8s (remain 29m 23s) Loss: 0.4367(0.5004) Grad: 46863.1250  LR: 0.00001591  \n","Epoch: [2][1700/8184] Elapsed 7m 35s (remain 28m 56s) Loss: 0.4841(0.5004) Grad: 30398.8184  LR: 0.00001583  \n","Epoch: [2][1800/8184] Elapsed 8m 2s (remain 28m 29s) Loss: 0.4681(0.5000) Grad: 47461.6250  LR: 0.00001575  \n","Epoch: [2][1900/8184] Elapsed 8m 29s (remain 28m 2s) Loss: 0.4400(0.4999) Grad: 104431.2500  LR: 0.00001567  \n","Epoch: [2][2000/8184] Elapsed 8m 55s (remain 27m 35s) Loss: 0.4420(0.5001) Grad: 55038.5703  LR: 0.00001559  \n","Epoch: [2][2100/8184] Elapsed 9m 22s (remain 27m 8s) Loss: 0.4970(0.5002) Grad: 106115.9062  LR: 0.00001551  \n","Epoch: [2][2200/8184] Elapsed 9m 49s (remain 26m 41s) Loss: 0.5461(0.4999) Grad: 16263.9951  LR: 0.00001543  \n","Epoch: [2][2300/8184] Elapsed 10m 15s (remain 26m 14s) Loss: 0.4146(0.4999) Grad: 17591.4824  LR: 0.00001535  \n","Epoch: [2][2400/8184] Elapsed 10m 42s (remain 25m 47s) Loss: 0.6159(0.4992) Grad: 112256.8516  LR: 0.00001527  \n","Epoch: [2][2500/8184] Elapsed 11m 9s (remain 25m 20s) Loss: 0.5059(0.4989) Grad: 66942.5547  LR: 0.00001519  \n","Epoch: [2][2600/8184] Elapsed 11m 35s (remain 24m 53s) Loss: 0.4829(0.4992) Grad: 156496.1250  LR: 0.00001511  \n","Epoch: [2][2700/8184] Elapsed 12m 2s (remain 24m 26s) Loss: 0.5322(0.4993) Grad: 93549.6172  LR: 0.00001502  \n","Epoch: [2][2800/8184] Elapsed 12m 29s (remain 24m 0s) Loss: 0.4169(0.4992) Grad: 140748.0625  LR: 0.00001494  \n","Epoch: [2][2900/8184] Elapsed 12m 56s (remain 23m 33s) Loss: 0.5352(0.4995) Grad: 19703.6797  LR: 0.00001486  \n","Epoch: [2][3000/8184] Elapsed 13m 22s (remain 23m 6s) Loss: 0.5203(0.4993) Grad: 107976.5703  LR: 0.00001477  \n","Epoch: [2][3100/8184] Elapsed 13m 49s (remain 22m 39s) Loss: 0.4623(0.4993) Grad: 127841.1172  LR: 0.00001469  \n","Epoch: [2][3200/8184] Elapsed 14m 16s (remain 22m 13s) Loss: 0.4058(0.4991) Grad: 81332.3828  LR: 0.00001460  \n","Epoch: [2][3300/8184] Elapsed 14m 42s (remain 21m 46s) Loss: 0.4856(0.4998) Grad: 25941.0508  LR: 0.00001452  \n","Epoch: [2][3400/8184] Elapsed 15m 9s (remain 21m 19s) Loss: 0.5833(0.5000) Grad: 232224.4844  LR: 0.00001443  \n","Epoch: [2][3500/8184] Elapsed 15m 36s (remain 20m 52s) Loss: 0.5799(0.5005) Grad: 257710.6875  LR: 0.00001434  \n","Epoch: [2][3600/8184] Elapsed 16m 3s (remain 20m 25s) Loss: 0.5069(0.5006) Grad: 17243.8691  LR: 0.00001426  \n","Epoch: [2][3700/8184] Elapsed 16m 30s (remain 19m 59s) Loss: 0.4615(0.5006) Grad: 157608.1719  LR: 0.00001417  \n","Epoch: [2][3800/8184] Elapsed 16m 56s (remain 19m 32s) Loss: 0.5142(0.5005) Grad: 40123.7500  LR: 0.00001408  \n","Epoch: [2][3900/8184] Elapsed 17m 23s (remain 19m 5s) Loss: 0.3502(0.5006) Grad: 41249.9922  LR: 0.00001400  \n","Epoch: [2][4000/8184] Elapsed 17m 50s (remain 18m 39s) Loss: 0.5699(0.5008) Grad: 24358.7715  LR: 0.00001391  \n","Epoch: [2][4100/8184] Elapsed 18m 17s (remain 18m 12s) Loss: 0.5280(0.5012) Grad: 18063.8438  LR: 0.00001382  \n","Epoch: [2][4200/8184] Elapsed 18m 44s (remain 17m 45s) Loss: 0.6016(0.5012) Grad: 29316.9707  LR: 0.00001373  \n","Epoch: [2][4300/8184] Elapsed 19m 10s (remain 17m 18s) Loss: 0.4682(0.5009) Grad: 54627.3438  LR: 0.00001364  \n","Epoch: [2][4400/8184] Elapsed 19m 37s (remain 16m 52s) Loss: 0.3814(0.5009) Grad: 12535.7305  LR: 0.00001355  \n","Epoch: [2][4500/8184] Elapsed 20m 4s (remain 16m 25s) Loss: 0.4877(0.5012) Grad: 18201.9277  LR: 0.00001346  \n","Epoch: [2][4600/8184] Elapsed 20m 31s (remain 15m 58s) Loss: 0.4604(0.5011) Grad: 17038.1836  LR: 0.00001337  \n","Epoch: [2][4700/8184] Elapsed 20m 57s (remain 15m 31s) Loss: 0.5213(0.5010) Grad: 85211.9375  LR: 0.00001328  \n","Epoch: [2][4800/8184] Elapsed 21m 24s (remain 15m 5s) Loss: 0.4332(0.5008) Grad: 20162.4961  LR: 0.00001319  \n","Epoch: [2][4900/8184] Elapsed 21m 51s (remain 14m 38s) Loss: 0.3607(0.5008) Grad: 10798.4805  LR: 0.00001310  \n","Epoch: [2][5000/8184] Elapsed 22m 17s (remain 14m 11s) Loss: 0.5633(0.5006) Grad: 17517.8516  LR: 0.00001301  \n","Epoch: [2][5100/8184] Elapsed 22m 44s (remain 13m 44s) Loss: 0.5529(0.5006) Grad: 71921.6484  LR: 0.00001292  \n","Epoch: [2][5200/8184] Elapsed 23m 11s (remain 13m 18s) Loss: 0.4142(0.5007) Grad: 20470.5312  LR: 0.00001282  \n","Epoch: [2][5300/8184] Elapsed 23m 38s (remain 12m 51s) Loss: 0.5881(0.5006) Grad: 28732.2559  LR: 0.00001273  \n","Epoch: [2][5400/8184] Elapsed 24m 4s (remain 12m 24s) Loss: 0.4988(0.5004) Grad: 41433.2070  LR: 0.00001264  \n","Epoch: [2][5500/8184] Elapsed 24m 31s (remain 11m 57s) Loss: 0.4805(0.5002) Grad: 16478.5234  LR: 0.00001255  \n","Epoch: [2][5600/8184] Elapsed 24m 58s (remain 11m 30s) Loss: 0.4128(0.5004) Grad: 30047.9902  LR: 0.00001245  \n","Epoch: [2][5700/8184] Elapsed 25m 24s (remain 11m 4s) Loss: 0.5995(0.5004) Grad: 15365.9443  LR: 0.00001236  \n","Epoch: [2][5800/8184] Elapsed 25m 51s (remain 10m 37s) Loss: 0.5506(0.5002) Grad: 22964.3262  LR: 0.00001227  \n","Epoch: [2][5900/8184] Elapsed 26m 18s (remain 10m 10s) Loss: 0.4414(0.5000) Grad: 14001.1123  LR: 0.00001217  \n","Epoch: [2][6000/8184] Elapsed 26m 45s (remain 9m 43s) Loss: 0.5003(0.4999) Grad: 17267.6562  LR: 0.00001208  \n","Epoch: [2][6100/8184] Elapsed 27m 11s (remain 9m 17s) Loss: 0.3655(0.4998) Grad: 35736.0820  LR: 0.00001199  \n","Epoch: [2][6200/8184] Elapsed 27m 38s (remain 8m 50s) Loss: 0.6194(0.4997) Grad: 169485.8906  LR: 0.00001189  \n","Epoch: [2][6300/8184] Elapsed 28m 5s (remain 8m 23s) Loss: 0.5203(0.4999) Grad: 25741.5430  LR: 0.00001180  \n","Epoch: [2][6400/8184] Elapsed 28m 32s (remain 7m 56s) Loss: 0.4352(0.4998) Grad: 49563.7109  LR: 0.00001170  \n","Epoch: [2][6500/8184] Elapsed 28m 58s (remain 7m 30s) Loss: 0.5305(0.4998) Grad: 30290.5742  LR: 0.00001161  \n","Epoch: [2][6600/8184] Elapsed 29m 25s (remain 7m 3s) Loss: 0.5210(0.4998) Grad: 44548.3828  LR: 0.00001151  \n","Epoch: [2][6700/8184] Elapsed 29m 52s (remain 6m 36s) Loss: 0.3873(0.4996) Grad: 26561.6309  LR: 0.00001142  \n","Epoch: [2][6800/8184] Elapsed 30m 19s (remain 6m 9s) Loss: 0.5050(0.4996) Grad: 20547.5117  LR: 0.00001132  \n","Epoch: [2][6900/8184] Elapsed 30m 45s (remain 5m 43s) Loss: 0.4175(0.4995) Grad: 53479.2500  LR: 0.00001123  \n","Epoch: [2][7000/8184] Elapsed 31m 12s (remain 5m 16s) Loss: 0.4036(0.4996) Grad: 32392.9492  LR: 0.00001113  \n","Epoch: [2][7100/8184] Elapsed 31m 39s (remain 4m 49s) Loss: 0.5114(0.4996) Grad: 37272.7188  LR: 0.00001104  \n","Epoch: [2][7200/8184] Elapsed 32m 5s (remain 4m 22s) Loss: 0.6011(0.4995) Grad: 109292.7422  LR: 0.00001094  \n","Epoch: [2][7300/8184] Elapsed 32m 32s (remain 3m 56s) Loss: 0.5028(0.4993) Grad: 50843.8047  LR: 0.00001085  \n","Epoch: [2][7400/8184] Elapsed 32m 59s (remain 3m 29s) Loss: 0.3853(0.4993) Grad: 26352.5664  LR: 0.00001075  \n","Epoch: [2][7500/8184] Elapsed 33m 26s (remain 3m 2s) Loss: 0.4798(0.4992) Grad: 46143.0820  LR: 0.00001065  \n","Epoch: [2][7600/8184] Elapsed 33m 52s (remain 2m 35s) Loss: 0.6550(0.4989) Grad: 81399.4844  LR: 0.00001056  \n","Epoch: [2][7700/8184] Elapsed 34m 19s (remain 2m 9s) Loss: 0.3741(0.4989) Grad: 47165.7812  LR: 0.00001046  \n","Epoch: [2][7800/8184] Elapsed 34m 46s (remain 1m 42s) Loss: 0.3957(0.4989) Grad: 89577.7969  LR: 0.00001037  \n","Epoch: [2][7900/8184] Elapsed 35m 13s (remain 1m 15s) Loss: 0.4326(0.4989) Grad: 35234.7969  LR: 0.00001027  \n","Epoch: [2][8000/8184] Elapsed 35m 39s (remain 0m 48s) Loss: 0.5820(0.4989) Grad: 69359.2266  LR: 0.00001018  \n","Epoch: [2][8100/8184] Elapsed 36m 6s (remain 0m 22s) Loss: 0.4819(0.4989) Grad: 125145.1016  LR: 0.00001008  \n","Epoch: [2][8183/8184] Elapsed 36m 28s (remain 0m 0s) Loss: 0.5183(0.4987) Grad: 47559.1758  LR: 0.00001000  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 34s) Loss: 0.7922(0.7922) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 21s) Loss: 0.3792(0.5583) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.6195(0.5673) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.4987  avg_val_loss: 0.5631  time: 2226s\n","Epoch 2 - Score: 0.8268\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 37s (remain 0m 0s) Loss: 0.0267(0.5631) \n","Epoch: [3][0/8184] Elapsed 0m 0s (remain 112m 41s) Loss: 0.5461(0.5461) Grad: 81612.4219  LR: 0.00001000  \n","Epoch: [3][100/8184] Elapsed 0m 27s (remain 36m 54s) Loss: 0.5444(0.4842) Grad: 42223.5156  LR: 0.00000990  \n","Epoch: [3][200/8184] Elapsed 0m 54s (remain 36m 2s) Loss: 0.5334(0.4813) Grad: 32712.0195  LR: 0.00000981  \n","Epoch: [3][300/8184] Elapsed 1m 21s (remain 35m 26s) Loss: 0.4196(0.4821) Grad: 35670.6719  LR: 0.00000971  \n","Epoch: [3][400/8184] Elapsed 1m 47s (remain 34m 55s) Loss: 0.5701(0.4831) Grad: 75591.2734  LR: 0.00000962  \n","Epoch: [3][500/8184] Elapsed 2m 14s (remain 34m 26s) Loss: 0.5587(0.4810) Grad: 90891.1172  LR: 0.00000952  \n","Epoch: [3][600/8184] Elapsed 2m 41s (remain 33m 57s) Loss: 0.4630(0.4820) Grad: 6237.1157  LR: 0.00000942  \n","Epoch: [3][700/8184] Elapsed 3m 8s (remain 33m 31s) Loss: 0.4853(0.4845) Grad: 67757.3594  LR: 0.00000933  \n","Epoch: [3][800/8184] Elapsed 3m 35s (remain 33m 2s) Loss: 0.6079(0.4851) Grad: 30839.5723  LR: 0.00000923  \n","Epoch: [3][900/8184] Elapsed 4m 1s (remain 32m 34s) Loss: 0.4855(0.4865) Grad: 61932.4531  LR: 0.00000914  \n","Epoch: [3][1000/8184] Elapsed 4m 28s (remain 32m 6s) Loss: 0.5705(0.4853) Grad: 56493.8164  LR: 0.00000904  \n","Epoch: [3][1100/8184] Elapsed 4m 55s (remain 31m 39s) Loss: 0.4141(0.4854) Grad: 129566.3906  LR: 0.00000895  \n","Epoch: [3][1200/8184] Elapsed 5m 21s (remain 31m 11s) Loss: 0.5984(0.4856) Grad: 124093.3281  LR: 0.00000885  \n","Epoch: [3][1300/8184] Elapsed 5m 48s (remain 30m 43s) Loss: 0.5135(0.4867) Grad: 148280.1406  LR: 0.00000875  \n","Epoch: [3][1400/8184] Elapsed 6m 15s (remain 30m 16s) Loss: 0.5225(0.4862) Grad: 203404.3594  LR: 0.00000866  \n","Epoch: [3][1500/8184] Elapsed 6m 41s (remain 29m 49s) Loss: 0.5593(0.4861) Grad: 19441.2969  LR: 0.00000856  \n","Epoch: [3][1600/8184] Elapsed 7m 8s (remain 29m 23s) Loss: 0.5331(0.4856) Grad: 19768.3730  LR: 0.00000847  \n","Epoch: [3][1700/8184] Elapsed 7m 35s (remain 28m 55s) Loss: 0.5390(0.4864) Grad: 4242.1025  LR: 0.00000837  \n","Epoch: [3][1800/8184] Elapsed 8m 2s (remain 28m 28s) Loss: 0.5598(0.4869) Grad: 22932.7676  LR: 0.00000828  \n","Epoch: [3][1900/8184] Elapsed 8m 28s (remain 28m 1s) Loss: 0.5503(0.4873) Grad: 10521.8867  LR: 0.00000819  \n","Epoch: [3][2000/8184] Elapsed 8m 55s (remain 27m 35s) Loss: 0.4831(0.4877) Grad: 48704.4141  LR: 0.00000809  \n","Epoch: [3][2100/8184] Elapsed 9m 22s (remain 27m 7s) Loss: 0.4644(0.4885) Grad: 26630.8535  LR: 0.00000800  \n","Epoch: [3][2200/8184] Elapsed 9m 48s (remain 26m 40s) Loss: 0.4206(0.4886) Grad: 145019.8594  LR: 0.00000790  \n","Epoch: [3][2300/8184] Elapsed 10m 15s (remain 26m 13s) Loss: 0.4011(0.4891) Grad: 6295.2656  LR: 0.00000781  \n","Epoch: [3][2400/8184] Elapsed 10m 42s (remain 25m 47s) Loss: 0.4359(0.4889) Grad: 3246.9641  LR: 0.00000772  \n","Epoch: [3][2500/8184] Elapsed 11m 8s (remain 25m 20s) Loss: 0.5032(0.4889) Grad: 31781.9668  LR: 0.00000762  \n","Epoch: [3][2600/8184] Elapsed 11m 35s (remain 24m 53s) Loss: 0.5755(0.4890) Grad: 41079.9883  LR: 0.00000753  \n","Epoch: [3][2700/8184] Elapsed 12m 2s (remain 24m 26s) Loss: 0.4191(0.4890) Grad: 30097.6543  LR: 0.00000744  \n","Epoch: [3][2800/8184] Elapsed 12m 29s (remain 24m 0s) Loss: 0.5359(0.4889) Grad: 61563.2656  LR: 0.00000734  \n","Epoch: [3][2900/8184] Elapsed 12m 56s (remain 23m 33s) Loss: 0.6007(0.4890) Grad: 75408.4531  LR: 0.00000725  \n","Epoch: [3][3000/8184] Elapsed 13m 23s (remain 23m 7s) Loss: 0.3861(0.4889) Grad: 98779.9609  LR: 0.00000716  \n","Epoch: [3][3100/8184] Elapsed 13m 49s (remain 22m 40s) Loss: 0.4959(0.4889) Grad: 44947.4375  LR: 0.00000707  \n","Epoch: [3][3200/8184] Elapsed 14m 17s (remain 22m 14s) Loss: 0.5002(0.4891) Grad: 39059.3047  LR: 0.00000698  \n","Epoch: [3][3300/8184] Elapsed 14m 43s (remain 21m 47s) Loss: 0.4761(0.4887) Grad: 35643.1289  LR: 0.00000688  \n","Epoch: [3][3400/8184] Elapsed 15m 10s (remain 21m 20s) Loss: 0.4221(0.4889) Grad: 70725.7031  LR: 0.00000679  \n","Epoch: [3][3500/8184] Elapsed 15m 37s (remain 20m 54s) Loss: 0.4506(0.4891) Grad: 42067.8438  LR: 0.00000670  \n","Epoch: [3][3600/8184] Elapsed 16m 4s (remain 20m 27s) Loss: 0.5588(0.4891) Grad: 31134.4961  LR: 0.00000661  \n","Epoch: [3][3700/8184] Elapsed 16m 31s (remain 20m 0s) Loss: 0.4125(0.4888) Grad: 38857.4258  LR: 0.00000652  \n","Epoch: [3][3800/8184] Elapsed 16m 58s (remain 19m 33s) Loss: 0.3778(0.4889) Grad: 28768.5410  LR: 0.00000643  \n","Epoch: [3][3900/8184] Elapsed 17m 24s (remain 19m 7s) Loss: 0.4838(0.4885) Grad: 12133.7607  LR: 0.00000634  \n","Epoch: [3][4000/8184] Elapsed 17m 51s (remain 18m 40s) Loss: 0.4534(0.4886) Grad: 9926.8330  LR: 0.00000625  \n","Epoch: [3][4100/8184] Elapsed 18m 18s (remain 18m 13s) Loss: 0.4732(0.4886) Grad: 22420.0000  LR: 0.00000617  \n","Epoch: [3][4200/8184] Elapsed 18m 45s (remain 17m 46s) Loss: 0.3547(0.4887) Grad: 60238.3125  LR: 0.00000608  \n","Epoch: [3][4300/8184] Elapsed 19m 12s (remain 17m 20s) Loss: 0.4477(0.4885) Grad: 56337.7070  LR: 0.00000599  \n","Epoch: [3][4400/8184] Elapsed 19m 39s (remain 16m 53s) Loss: 0.4757(0.4887) Grad: 77820.2812  LR: 0.00000590  \n","Epoch: [3][4500/8184] Elapsed 20m 5s (remain 16m 26s) Loss: 0.4718(0.4888) Grad: 4854.5552  LR: 0.00000581  \n","Epoch: [3][4600/8184] Elapsed 20m 32s (remain 15m 59s) Loss: 0.5712(0.4888) Grad: 915326.8125  LR: 0.00000573  \n","Epoch: [3][4700/8184] Elapsed 20m 59s (remain 15m 32s) Loss: 0.4569(0.4887) Grad: 22156.9316  LR: 0.00000564  \n","Epoch: [3][4800/8184] Elapsed 21m 25s (remain 15m 6s) Loss: 0.5845(0.4888) Grad: 18072.6719  LR: 0.00000555  \n","Epoch: [3][4900/8184] Elapsed 21m 52s (remain 14m 39s) Loss: 0.5067(0.4887) Grad: 5040.5737  LR: 0.00000547  \n","Epoch: [3][5000/8184] Elapsed 22m 19s (remain 14m 12s) Loss: 0.5427(0.4888) Grad: 18522.1797  LR: 0.00000538  \n","Epoch: [3][5100/8184] Elapsed 22m 46s (remain 13m 45s) Loss: 0.4861(0.4888) Grad: 321786.0000  LR: 0.00000530  \n","Epoch: [3][5200/8184] Elapsed 23m 13s (remain 13m 19s) Loss: 0.3601(0.4888) Grad: 99915.0859  LR: 0.00000521  \n","Epoch: [3][5300/8184] Elapsed 23m 39s (remain 12m 52s) Loss: 0.4201(0.4888) Grad: 27136.6660  LR: 0.00000513  \n","Epoch: [3][5400/8184] Elapsed 24m 6s (remain 12m 25s) Loss: 0.4287(0.4888) Grad: 48790.7148  LR: 0.00000505  \n","Epoch: [3][5500/8184] Elapsed 24m 33s (remain 11m 58s) Loss: 0.5661(0.4888) Grad: 185913.9219  LR: 0.00000496  \n","Epoch: [3][5600/8184] Elapsed 25m 0s (remain 11m 31s) Loss: 0.3746(0.4885) Grad: 13859.2793  LR: 0.00000488  \n","Epoch: [3][5700/8184] Elapsed 25m 27s (remain 11m 5s) Loss: 0.4338(0.4886) Grad: 49363.0664  LR: 0.00000480  \n","Epoch: [3][5800/8184] Elapsed 25m 53s (remain 10m 38s) Loss: 0.4998(0.4887) Grad: 15435.5918  LR: 0.00000472  \n","Epoch: [3][5900/8184] Elapsed 26m 20s (remain 10m 11s) Loss: 0.4597(0.4886) Grad: 162059.4688  LR: 0.00000463  \n","Epoch: [3][6000/8184] Elapsed 26m 47s (remain 9m 44s) Loss: 0.6537(0.4886) Grad: 213736.2188  LR: 0.00000455  \n","Epoch: [3][6100/8184] Elapsed 27m 14s (remain 9m 17s) Loss: 0.5097(0.4885) Grad: 118855.3750  LR: 0.00000447  \n","Epoch: [3][6200/8184] Elapsed 27m 40s (remain 8m 51s) Loss: 0.4132(0.4885) Grad: 123204.5703  LR: 0.00000439  \n","Epoch: [3][6300/8184] Elapsed 28m 7s (remain 8m 24s) Loss: 0.4637(0.4886) Grad: 61170.9492  LR: 0.00000431  \n","Epoch: [3][6400/8184] Elapsed 28m 34s (remain 7m 57s) Loss: 0.3991(0.4885) Grad: 43374.9766  LR: 0.00000424  \n","Epoch: [3][6500/8184] Elapsed 29m 1s (remain 7m 30s) Loss: 0.5417(0.4886) Grad: 13383.7256  LR: 0.00000416  \n","Epoch: [3][6600/8184] Elapsed 29m 27s (remain 7m 3s) Loss: 0.4977(0.4885) Grad: 148245.9531  LR: 0.00000408  \n","Epoch: [3][6700/8184] Elapsed 29m 54s (remain 6m 37s) Loss: 0.4773(0.4884) Grad: 17609.8477  LR: 0.00000400  \n","Epoch: [3][6800/8184] Elapsed 30m 21s (remain 6m 10s) Loss: 0.5696(0.4884) Grad: 20565.8652  LR: 0.00000393  \n","Epoch: [3][6900/8184] Elapsed 30m 48s (remain 5m 43s) Loss: 0.4034(0.4885) Grad: 3861.8708  LR: 0.00000385  \n","Epoch: [3][7000/8184] Elapsed 31m 14s (remain 5m 16s) Loss: 0.5672(0.4886) Grad: 38377.7500  LR: 0.00000378  \n","Epoch: [3][7100/8184] Elapsed 31m 41s (remain 4m 50s) Loss: 0.4784(0.4885) Grad: 11448.4248  LR: 0.00000370  \n","Epoch: [3][7200/8184] Elapsed 32m 8s (remain 4m 23s) Loss: 0.4513(0.4883) Grad: 75520.7969  LR: 0.00000363  \n","Epoch: [3][7300/8184] Elapsed 32m 35s (remain 3m 56s) Loss: 0.3609(0.4881) Grad: 28371.9980  LR: 0.00000355  \n","Epoch: [3][7400/8184] Elapsed 33m 1s (remain 3m 29s) Loss: 0.5525(0.4882) Grad: 16831.2930  LR: 0.00000348  \n","Epoch: [3][7500/8184] Elapsed 33m 28s (remain 3m 2s) Loss: 0.5345(0.4882) Grad: 100197.7344  LR: 0.00000341  \n","Epoch: [3][7600/8184] Elapsed 33m 55s (remain 2m 36s) Loss: 0.3885(0.4884) Grad: 45954.3594  LR: 0.00000334  \n","Epoch: [3][7700/8184] Elapsed 34m 22s (remain 2m 9s) Loss: 0.4154(0.4885) Grad: 25213.8633  LR: 0.00000326  \n","Epoch: [3][7800/8184] Elapsed 34m 48s (remain 1m 42s) Loss: 0.4666(0.4886) Grad: 23171.6426  LR: 0.00000319  \n","Epoch: [3][7900/8184] Elapsed 35m 15s (remain 1m 15s) Loss: 0.4984(0.4886) Grad: 3898.9707  LR: 0.00000312  \n","Epoch: [3][8000/8184] Elapsed 35m 41s (remain 0m 48s) Loss: 0.5067(0.4884) Grad: 5392.5615  LR: 0.00000305  \n","Epoch: [3][8100/8184] Elapsed 36m 8s (remain 0m 22s) Loss: 0.4472(0.4884) Grad: 66619.2969  LR: 0.00000299  \n","Epoch: [3][8183/8184] Elapsed 36m 30s (remain 0m 0s) Loss: 0.4733(0.4883) Grad: 47285.7812  LR: 0.00000293  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 31s) Loss: 0.8488(0.8488) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 20s) Loss: 0.3762(0.5786) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.6200(0.5853) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.4883  avg_val_loss: 0.5809  time: 2228s\n","Epoch 3 - Score: 0.8134\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.0998(0.5809) \n","Epoch: [4][0/8184] Elapsed 0m 0s (remain 116m 28s) Loss: 0.3423(0.3423) Grad: 12461.4365  LR: 0.00000293  \n","Epoch: [4][100/8184] Elapsed 0m 27s (remain 36m 49s) Loss: 0.3956(0.4910) Grad: 74350.4531  LR: 0.00000286  \n","Epoch: [4][200/8184] Elapsed 0m 54s (remain 35m 53s) Loss: 0.4845(0.4832) Grad: 106993.8203  LR: 0.00000279  \n","Epoch: [4][300/8184] Elapsed 1m 20s (remain 35m 18s) Loss: 0.4454(0.4859) Grad: 41678.3945  LR: 0.00000273  \n","Epoch: [4][400/8184] Elapsed 1m 47s (remain 34m 46s) Loss: 0.3796(0.4845) Grad: 52844.8789  LR: 0.00000266  \n","Epoch: [4][500/8184] Elapsed 2m 14s (remain 34m 16s) Loss: 0.4822(0.4848) Grad: 109648.9062  LR: 0.00000260  \n","Epoch: [4][600/8184] Elapsed 2m 40s (remain 33m 48s) Loss: 0.4399(0.4859) Grad: 1449870.5000  LR: 0.00000253  \n","Epoch: [4][700/8184] Elapsed 3m 7s (remain 33m 20s) Loss: 0.4710(0.4876) Grad: 3318.8640  LR: 0.00000247  \n","Epoch: [4][800/8184] Elapsed 3m 33s (remain 32m 52s) Loss: 0.4794(0.4876) Grad: 21347.1699  LR: 0.00000241  \n","Epoch: [4][900/8184] Elapsed 4m 0s (remain 32m 25s) Loss: 0.4071(0.4862) Grad: 58780.9844  LR: 0.00000234  \n","Epoch: [4][1000/8184] Elapsed 4m 27s (remain 31m 58s) Loss: 0.4359(0.4869) Grad: 1920.8834  LR: 0.00000228  \n","Epoch: [4][1100/8184] Elapsed 4m 54s (remain 31m 33s) Loss: 0.4195(0.4867) Grad: 10206.3789  LR: 0.00000222  \n","Epoch: [4][1200/8184] Elapsed 5m 20s (remain 31m 6s) Loss: 0.5230(0.4863) Grad: 8303.8867  LR: 0.00000216  \n","Epoch: [4][1300/8184] Elapsed 5m 47s (remain 30m 39s) Loss: 0.3224(0.4859) Grad: 2712.8872  LR: 0.00000210  \n","Epoch: [4][1400/8184] Elapsed 6m 14s (remain 30m 12s) Loss: 0.4879(0.4858) Grad: 14741.2832  LR: 0.00000204  \n","Epoch: [4][1500/8184] Elapsed 6m 41s (remain 29m 46s) Loss: 0.6017(0.4863) Grad: 14107.2051  LR: 0.00000199  \n","Epoch: [4][1600/8184] Elapsed 7m 8s (remain 29m 20s) Loss: 0.5336(0.4875) Grad: 10645.0420  LR: 0.00000193  \n","Epoch: [4][1700/8184] Elapsed 7m 34s (remain 28m 53s) Loss: 0.4526(0.4868) Grad: 63044.8047  LR: 0.00000187  \n","Epoch: [4][1800/8184] Elapsed 8m 1s (remain 28m 26s) Loss: 0.4946(0.4866) Grad: 11288.0391  LR: 0.00000182  \n","Epoch: [4][1900/8184] Elapsed 8m 28s (remain 28m 0s) Loss: 0.4719(0.4863) Grad: 39157.1758  LR: 0.00000176  \n","Epoch: [4][2000/8184] Elapsed 8m 55s (remain 27m 34s) Loss: 0.6035(0.4860) Grad: 67621.8125  LR: 0.00000171  \n","Epoch: [4][2100/8184] Elapsed 9m 22s (remain 27m 7s) Loss: 0.5151(0.4856) Grad: 18266.9043  LR: 0.00000166  \n","Epoch: [4][2200/8184] Elapsed 9m 48s (remain 26m 40s) Loss: 0.5420(0.4857) Grad: 15524.4922  LR: 0.00000160  \n","Epoch: [4][2300/8184] Elapsed 10m 15s (remain 26m 14s) Loss: 0.4314(0.4853) Grad: 37761.0430  LR: 0.00000155  \n","Epoch: [4][2400/8184] Elapsed 10m 42s (remain 25m 47s) Loss: 0.5225(0.4853) Grad: 9856.9121  LR: 0.00000150  \n","Epoch: [4][2500/8184] Elapsed 11m 9s (remain 25m 20s) Loss: 0.3947(0.4851) Grad: 32853.2852  LR: 0.00000145  \n","Epoch: [4][2600/8184] Elapsed 11m 35s (remain 24m 53s) Loss: 0.4593(0.4851) Grad: 120682.7109  LR: 0.00000140  \n","Epoch: [4][2700/8184] Elapsed 12m 2s (remain 24m 26s) Loss: 0.3496(0.4846) Grad: 5984.4116  LR: 0.00000135  \n","Epoch: [4][2800/8184] Elapsed 12m 29s (remain 23m 59s) Loss: 0.4884(0.4847) Grad: 39322.9531  LR: 0.00000130  \n","Epoch: [4][2900/8184] Elapsed 12m 56s (remain 23m 33s) Loss: 0.4549(0.4845) Grad: 41300.3320  LR: 0.00000126  \n","Epoch: [4][3000/8184] Elapsed 13m 22s (remain 23m 6s) Loss: 0.4118(0.4842) Grad: 35660.9258  LR: 0.00000121  \n","Epoch: [4][3100/8184] Elapsed 13m 49s (remain 22m 39s) Loss: 0.4528(0.4840) Grad: 1021599.6875  LR: 0.00000117  \n","Epoch: [4][3200/8184] Elapsed 14m 16s (remain 22m 13s) Loss: 0.5135(0.4838) Grad: 362129.5312  LR: 0.00000112  \n","Epoch: [4][3300/8184] Elapsed 14m 43s (remain 21m 46s) Loss: 0.4810(0.4837) Grad: 62483.7070  LR: 0.00000108  \n","Epoch: [4][3400/8184] Elapsed 15m 9s (remain 21m 19s) Loss: 0.5897(0.4839) Grad: 66068.5469  LR: 0.00000104  \n","Epoch: [4][3500/8184] Elapsed 15m 36s (remain 20m 52s) Loss: 0.5310(0.4841) Grad: 13410.9922  LR: 0.00000099  \n","Epoch: [4][3600/8184] Elapsed 16m 3s (remain 20m 26s) Loss: 0.5348(0.4843) Grad: 121919.3828  LR: 0.00000095  \n","Epoch: [4][3700/8184] Elapsed 16m 30s (remain 19m 59s) Loss: 0.4546(0.4844) Grad: 8318.4375  LR: 0.00000091  \n","Epoch: [4][3800/8184] Elapsed 16m 56s (remain 19m 32s) Loss: 0.4008(0.4845) Grad: 4015.6035  LR: 0.00000087  \n","Epoch: [4][3900/8184] Elapsed 17m 23s (remain 19m 5s) Loss: 0.5461(0.4844) Grad: 86216.8438  LR: 0.00000083  \n","Epoch: [4][4000/8184] Elapsed 17m 50s (remain 18m 38s) Loss: 0.4018(0.4844) Grad: 26436.7656  LR: 0.00000079  \n","Epoch: [4][4100/8184] Elapsed 18m 16s (remain 18m 12s) Loss: 0.4170(0.4843) Grad: 75653.6953  LR: 0.00000076  \n","Epoch: [4][4200/8184] Elapsed 18m 43s (remain 17m 45s) Loss: 0.5181(0.4844) Grad: 36889.1562  LR: 0.00000072  \n","Epoch: [4][4300/8184] Elapsed 19m 10s (remain 17m 18s) Loss: 0.3928(0.4845) Grad: 6454.2788  LR: 0.00000069  \n","Epoch: [4][4400/8184] Elapsed 19m 36s (remain 16m 51s) Loss: 0.3537(0.4844) Grad: 81956.8906  LR: 0.00000065  \n","Epoch: [4][4500/8184] Elapsed 20m 3s (remain 16m 24s) Loss: 0.3983(0.4842) Grad: 33467.7461  LR: 0.00000062  \n","Epoch: [4][4600/8184] Elapsed 20m 30s (remain 15m 58s) Loss: 0.5604(0.4843) Grad: 90311.6328  LR: 0.00000059  \n","Epoch: [4][4700/8184] Elapsed 20m 56s (remain 15m 31s) Loss: 0.3851(0.4839) Grad: 6473.5674  LR: 0.00000055  \n","Epoch: [4][4800/8184] Elapsed 21m 23s (remain 15m 4s) Loss: 0.5295(0.4838) Grad: 9594.3838  LR: 0.00000052  \n","Epoch: [4][4900/8184] Elapsed 21m 50s (remain 14m 37s) Loss: 0.5064(0.4838) Grad: 5952.5962  LR: 0.00000049  \n","Epoch: [4][5000/8184] Elapsed 22m 17s (remain 14m 11s) Loss: 0.5246(0.4840) Grad: 21818.5723  LR: 0.00000046  \n","Epoch: [4][5100/8184] Elapsed 22m 44s (remain 13m 44s) Loss: 0.5608(0.4840) Grad: 11577.3447  LR: 0.00000043  \n","Epoch: [4][5200/8184] Elapsed 23m 10s (remain 13m 17s) Loss: 0.4545(0.4841) Grad: 42172.0547  LR: 0.00000041  \n","Epoch: [4][5300/8184] Elapsed 23m 37s (remain 12m 50s) Loss: 0.6366(0.4843) Grad: 13639.6055  LR: 0.00000038  \n","Epoch: [4][5400/8184] Elapsed 24m 4s (remain 12m 24s) Loss: 0.3603(0.4843) Grad: 26488.2871  LR: 0.00000035  \n","Epoch: [4][5500/8184] Elapsed 24m 31s (remain 11m 57s) Loss: 0.4495(0.4844) Grad: 82317.7422  LR: 0.00000033  \n","Epoch: [4][5600/8184] Elapsed 24m 57s (remain 11m 30s) Loss: 0.4196(0.4844) Grad: 3423.7075  LR: 0.00000031  \n","Epoch: [4][5700/8184] Elapsed 25m 24s (remain 11m 4s) Loss: 0.4000(0.4844) Grad: 90367.0859  LR: 0.00000028  \n","Epoch: [4][5800/8184] Elapsed 25m 51s (remain 10m 37s) Loss: 0.5335(0.4846) Grad: 13283.4951  LR: 0.00000026  \n","Epoch: [4][5900/8184] Elapsed 26m 18s (remain 10m 10s) Loss: 0.3697(0.4847) Grad: 98578.6797  LR: 0.00000024  \n","Epoch: [4][6000/8184] Elapsed 26m 44s (remain 9m 43s) Loss: 0.5334(0.4845) Grad: 259340.8750  LR: 0.00000022  \n","Epoch: [4][6100/8184] Elapsed 27m 11s (remain 9m 17s) Loss: 0.4366(0.4845) Grad: 50413.4375  LR: 0.00000020  \n","Epoch: [4][6200/8184] Elapsed 27m 38s (remain 8m 50s) Loss: 0.4746(0.4845) Grad: 45021.0742  LR: 0.00000018  \n","Epoch: [4][6300/8184] Elapsed 28m 5s (remain 8m 23s) Loss: 0.4963(0.4844) Grad: 21968.5156  LR: 0.00000016  \n","Epoch: [4][6400/8184] Elapsed 28m 31s (remain 7m 56s) Loss: 0.4415(0.4843) Grad: 93685.5938  LR: 0.00000015  \n","Epoch: [4][6500/8184] Elapsed 28m 58s (remain 7m 30s) Loss: 0.4546(0.4845) Grad: 1466.4391  LR: 0.00000013  \n","Epoch: [4][6600/8184] Elapsed 29m 25s (remain 7m 3s) Loss: 0.5734(0.4845) Grad: 47485.1719  LR: 0.00000012  \n","Epoch: [4][6700/8184] Elapsed 29m 52s (remain 6m 36s) Loss: 0.4987(0.4843) Grad: 21687.7441  LR: 0.00000010  \n","Epoch: [4][6800/8184] Elapsed 30m 18s (remain 6m 9s) Loss: 0.4823(0.4844) Grad: 3259.0894  LR: 0.00000009  \n","Epoch: [4][6900/8184] Elapsed 30m 45s (remain 5m 43s) Loss: 0.4948(0.4842) Grad: 59854.6953  LR: 0.00000008  \n","Epoch: [4][7000/8184] Elapsed 31m 12s (remain 5m 16s) Loss: 0.6029(0.4843) Grad: 38010.2969  LR: 0.00000006  \n","Epoch: [4][7100/8184] Elapsed 31m 38s (remain 4m 49s) Loss: 0.4516(0.4841) Grad: 20831.4492  LR: 0.00000005  \n","Epoch: [4][7200/8184] Elapsed 32m 5s (remain 4m 22s) Loss: 0.5383(0.4840) Grad: 20013.2754  LR: 0.00000004  \n","Epoch: [4][7300/8184] Elapsed 32m 32s (remain 3m 56s) Loss: 0.4736(0.4843) Grad: 51001.9180  LR: 0.00000004  \n","Epoch: [4][7400/8184] Elapsed 32m 59s (remain 3m 29s) Loss: 0.5084(0.4844) Grad: 22563.0879  LR: 0.00000003  \n","Epoch: [4][7500/8184] Elapsed 33m 26s (remain 3m 2s) Loss: 0.4372(0.4845) Grad: 22995.5547  LR: 0.00000002  \n","Epoch: [4][7600/8184] Elapsed 33m 52s (remain 2m 35s) Loss: 0.4111(0.4846) Grad: 149021.1250  LR: 0.00000002  \n","Epoch: [4][7700/8184] Elapsed 34m 19s (remain 2m 9s) Loss: 0.4988(0.4846) Grad: 12445.1406  LR: 0.00000001  \n","Epoch: [4][7800/8184] Elapsed 34m 46s (remain 1m 42s) Loss: 0.3606(0.4847) Grad: 73104.4297  LR: 0.00000001  \n","Epoch: [4][7900/8184] Elapsed 35m 13s (remain 1m 15s) Loss: 0.5243(0.4846) Grad: 47986.9922  LR: 0.00000000  \n","Epoch: [4][8000/8184] Elapsed 35m 39s (remain 0m 48s) Loss: 0.4909(0.4845) Grad: 49076.4922  LR: 0.00000000  \n","Epoch: [4][8100/8184] Elapsed 36m 6s (remain 0m 22s) Loss: 0.5293(0.4843) Grad: 63185.8633  LR: 0.00000000  \n","Epoch: [4][8183/8184] Elapsed 36m 28s (remain 0m 0s) Loss: 0.5364(0.4844) Grad: 125189.7266  LR: 0.00000000  \n","EVAL: [0/228] Elapsed 0m 0s (remain 2m 31s) Loss: 0.8771(0.8771) \n","EVAL: [100/228] Elapsed 0m 16s (remain 0m 21s) Loss: 0.3876(0.5791) \n","EVAL: [200/228] Elapsed 0m 32s (remain 0m 4s) Loss: 0.6214(0.5864) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4844  avg_val_loss: 0.5818  time: 2226s\n","Epoch 4 - Score: 0.8115\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["EVAL: [227/228] Elapsed 0m 36s (remain 0m 0s) Loss: 0.1236(0.5818) \n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["========== fold: 1 result ==========\n","Score: 0.8283\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/8214] Elapsed 0m 0s (remain 115m 54s) Loss: 0.7130(0.7130) Grad: 94728.0625  LR: 0.00002000  \n","Epoch: [1][100/8214] Elapsed 0m 27s (remain 36m 48s) Loss: 0.6765(0.6466) Grad: 65783.7109  LR: 0.00002000  \n","Epoch: [1][200/8214] Elapsed 0m 54s (remain 36m 4s) Loss: 0.6217(0.6251) Grad: 54886.5742  LR: 0.00002000  \n","Epoch: [1][300/8214] Elapsed 1m 20s (remain 35m 26s) Loss: 0.5938(0.6169) Grad: 36847.3789  LR: 0.00002000  \n","Epoch: [1][400/8214] Elapsed 1m 47s (remain 34m 56s) Loss: 0.7634(0.6126) Grad: 71202.8828  LR: 0.00001999  \n","Epoch: [1][500/8214] Elapsed 2m 14s (remain 34m 25s) Loss: 0.6166(0.6075) Grad: 20813.7129  LR: 0.00001999  \n","Epoch: [1][600/8214] Elapsed 2m 40s (remain 33m 56s) Loss: 0.6161(0.6014) Grad: 17147.7520  LR: 0.00001998  \n","Epoch: [1][700/8214] Elapsed 3m 7s (remain 33m 28s) Loss: 0.6103(0.6076) Grad: 8124.0903  LR: 0.00001998  \n","Epoch: [1][800/8214] Elapsed 3m 34s (remain 33m 2s) Loss: 0.7805(0.6127) Grad: 34936.4688  LR: 0.00001997  \n","Epoch: [1][900/8214] Elapsed 4m 0s (remain 32m 34s) Loss: 0.5015(0.6155) Grad: 6081.6509  LR: 0.00001996  \n","Epoch: [1][1000/8214] Elapsed 4m 27s (remain 32m 7s) Loss: 0.6559(0.6171) Grad: 6572.0200  LR: 0.00001995  \n","Epoch: [1][1100/8214] Elapsed 4m 54s (remain 31m 39s) Loss: 0.6191(0.6197) Grad: 6476.7915  LR: 0.00001994  \n","Epoch: [1][1200/8214] Elapsed 5m 20s (remain 31m 13s) Loss: 0.7013(0.6226) Grad: 4165.6641  LR: 0.00001993  \n","Epoch: [1][1300/8214] Elapsed 5m 47s (remain 30m 46s) Loss: 0.6793(0.6252) Grad: 4444.2354  LR: 0.00001992  \n","Epoch: [1][1400/8214] Elapsed 6m 14s (remain 30m 19s) Loss: 0.6598(0.6275) Grad: 3230.4463  LR: 0.00001991  \n","Epoch: [1][1500/8214] Elapsed 6m 40s (remain 29m 52s) Loss: 0.6010(0.6295) Grad: 2949.1558  LR: 0.00001990  \n","Epoch: [1][1600/8214] Elapsed 7m 7s (remain 29m 25s) Loss: 0.6884(0.6315) Grad: 2437.3767  LR: 0.00001988  \n","Epoch: [1][1700/8214] Elapsed 7m 33s (remain 28m 58s) Loss: 0.6503(0.6331) Grad: 1464.2319  LR: 0.00001987  \n","Epoch: [1][1800/8214] Elapsed 8m 0s (remain 28m 30s) Loss: 0.6868(0.6343) Grad: 3369.4460  LR: 0.00001985  \n","Epoch: [1][1900/8214] Elapsed 8m 27s (remain 28m 4s) Loss: 0.6127(0.6356) Grad: 2421.1106  LR: 0.00001984  \n","Epoch: [1][2000/8214] Elapsed 8m 53s (remain 27m 37s) Loss: 0.7033(0.6365) Grad: 6248.9937  LR: 0.00001982  \n","Epoch: [1][2100/8214] Elapsed 9m 20s (remain 27m 10s) Loss: 0.6776(0.6372) Grad: 2668.7007  LR: 0.00001980  \n","Epoch: [1][2200/8214] Elapsed 9m 46s (remain 26m 43s) Loss: 0.5497(0.6379) Grad: 4568.2998  LR: 0.00001978  \n","Epoch: [1][2300/8214] Elapsed 10m 13s (remain 26m 16s) Loss: 0.6031(0.6384) Grad: 2501.5010  LR: 0.00001976  \n","Epoch: [1][2400/8214] Elapsed 10m 40s (remain 25m 50s) Loss: 0.6032(0.6391) Grad: 7278.9214  LR: 0.00001974  \n","Epoch: [1][2500/8214] Elapsed 11m 7s (remain 25m 23s) Loss: 0.7373(0.6398) Grad: 4449.1353  LR: 0.00001972  \n","Epoch: [1][2600/8214] Elapsed 11m 33s (remain 24m 57s) Loss: 0.6027(0.6404) Grad: 2855.0706  LR: 0.00001969  \n","Epoch: [1][2700/8214] Elapsed 12m 0s (remain 24m 30s) Loss: 0.5955(0.6409) Grad: 5453.2686  LR: 0.00001967  \n","Epoch: [1][2800/8214] Elapsed 12m 26s (remain 24m 3s) Loss: 0.6676(0.6415) Grad: 3815.9026  LR: 0.00001964  \n","Epoch: [1][2900/8214] Elapsed 12m 53s (remain 23m 36s) Loss: 0.6813(0.6422) Grad: 5532.2661  LR: 0.00001962  \n","Epoch: [1][3000/8214] Elapsed 13m 20s (remain 23m 9s) Loss: 0.6726(0.6428) Grad: 6906.2710  LR: 0.00001959  \n","Epoch: [1][3100/8214] Elapsed 13m 46s (remain 22m 43s) Loss: 0.6747(0.6431) Grad: 4220.2222  LR: 0.00001956  \n","Epoch: [1][3200/8214] Elapsed 14m 13s (remain 22m 16s) Loss: 0.6641(0.6435) Grad: 4988.6597  LR: 0.00001954  \n","Epoch: [1][3300/8214] Elapsed 14m 40s (remain 21m 49s) Loss: 0.6552(0.6439) Grad: 4840.4565  LR: 0.00001951  \n","Epoch: [1][3400/8214] Elapsed 15m 6s (remain 21m 23s) Loss: 0.6528(0.6443) Grad: 7694.8726  LR: 0.00001948  \n","Epoch: [1][3500/8214] Elapsed 15m 33s (remain 20m 56s) Loss: 0.7128(0.6447) Grad: 10485.2178  LR: 0.00001944  \n","Epoch: [1][3600/8214] Elapsed 16m 0s (remain 20m 30s) Loss: 0.6736(0.6450) Grad: 8488.2715  LR: 0.00001941  \n","Epoch: [1][3700/8214] Elapsed 16m 27s (remain 20m 3s) Loss: 0.6561(0.6451) Grad: 5943.0215  LR: 0.00001938  \n","Epoch: [1][3800/8214] Elapsed 16m 53s (remain 19m 36s) Loss: 0.6950(0.6454) Grad: 5888.8193  LR: 0.00001935  \n","Epoch: [1][3900/8214] Elapsed 17m 20s (remain 19m 10s) Loss: 0.6556(0.6455) Grad: 3960.3872  LR: 0.00001931  \n","Epoch: [1][4000/8214] Elapsed 17m 46s (remain 18m 43s) Loss: 0.6671(0.6456) Grad: 3896.8860  LR: 0.00001928  \n","Epoch: [1][4100/8214] Elapsed 18m 13s (remain 18m 16s) Loss: 0.6782(0.6459) Grad: 4792.5049  LR: 0.00001924  \n","Epoch: [1][4200/8214] Elapsed 18m 40s (remain 17m 49s) Loss: 0.6812(0.6462) Grad: 7883.8403  LR: 0.00001920  \n","Epoch: [1][4300/8214] Elapsed 19m 6s (remain 17m 23s) Loss: 0.6060(0.6464) Grad: 4576.2998  LR: 0.00001917  \n","Epoch: [1][4400/8214] Elapsed 19m 33s (remain 16m 56s) Loss: 0.7021(0.6467) Grad: 5135.5122  LR: 0.00001913  \n","Epoch: [1][4500/8214] Elapsed 19m 59s (remain 16m 29s) Loss: 0.6998(0.6470) Grad: 5511.8354  LR: 0.00001909  \n","Epoch: [1][4600/8214] Elapsed 20m 26s (remain 16m 3s) Loss: 0.7060(0.6473) Grad: 6257.2500  LR: 0.00001905  \n","Epoch: [1][4700/8214] Elapsed 20m 53s (remain 15m 36s) Loss: 0.5869(0.6476) Grad: 9467.1162  LR: 0.00001901  \n","Epoch: [1][4800/8214] Elapsed 21m 19s (remain 15m 9s) Loss: 0.6217(0.6477) Grad: 10981.2119  LR: 0.00001896  \n","Epoch: [1][4900/8214] Elapsed 21m 46s (remain 14m 43s) Loss: 0.6443(0.6479) Grad: 7995.9795  LR: 0.00001892  \n","Epoch: [1][5000/8214] Elapsed 22m 13s (remain 14m 16s) Loss: 0.6095(0.6480) Grad: 9840.1270  LR: 0.00001888  \n","Epoch: [1][5100/8214] Elapsed 22m 39s (remain 13m 49s) Loss: 0.6289(0.6482) Grad: 14547.2168  LR: 0.00001883  \n","Epoch: [1][5200/8214] Elapsed 23m 6s (remain 13m 23s) Loss: 0.6298(0.6484) Grad: 10628.1162  LR: 0.00001879  \n","Epoch: [1][5300/8214] Elapsed 23m 33s (remain 12m 56s) Loss: 0.6223(0.6485) Grad: 12913.9854  LR: 0.00001874  \n","Epoch: [1][5400/8214] Elapsed 24m 0s (remain 12m 30s) Loss: 0.6521(0.6488) Grad: 9758.8340  LR: 0.00001870  \n","Epoch: [1][5500/8214] Elapsed 24m 26s (remain 12m 3s) Loss: 0.7235(0.6488) Grad: 16254.5566  LR: 0.00001865  \n","Epoch: [1][5600/8214] Elapsed 24m 53s (remain 11m 36s) Loss: 0.7160(0.6488) Grad: 9943.1631  LR: 0.00001860  \n","Epoch: [1][5700/8214] Elapsed 25m 20s (remain 11m 10s) Loss: 0.6129(0.6491) Grad: 10437.3066  LR: 0.00001855  \n","Epoch: [1][5800/8214] Elapsed 25m 46s (remain 10m 43s) Loss: 0.5920(0.6492) Grad: 12810.9551  LR: 0.00001850  \n","Epoch: [1][5900/8214] Elapsed 26m 13s (remain 10m 16s) Loss: 0.6747(0.6492) Grad: 6256.3154  LR: 0.00001845  \n","Epoch: [1][6000/8214] Elapsed 26m 40s (remain 9m 50s) Loss: 0.6096(0.6493) Grad: 8326.6465  LR: 0.00001840  \n","Epoch: [1][6100/8214] Elapsed 27m 7s (remain 9m 23s) Loss: 0.7154(0.6495) Grad: 13825.6855  LR: 0.00001835  \n","Epoch: [1][6200/8214] Elapsed 27m 33s (remain 8m 56s) Loss: 0.6966(0.6496) Grad: 7618.0962  LR: 0.00001829  \n","Epoch: [1][6300/8214] Elapsed 28m 0s (remain 8m 30s) Loss: 0.6283(0.6496) Grad: 5715.5645  LR: 0.00001824  \n","Epoch: [1][6400/8214] Elapsed 28m 27s (remain 8m 3s) Loss: 0.6632(0.6497) Grad: 5680.1084  LR: 0.00001818  \n","Epoch: [1][6500/8214] Elapsed 28m 53s (remain 7m 36s) Loss: 0.6826(0.6497) Grad: 10328.8506  LR: 0.00001813  \n","Epoch: [1][6600/8214] Elapsed 29m 20s (remain 7m 10s) Loss: 0.7039(0.6498) Grad: 10147.3018  LR: 0.00001807  \n","Epoch: [1][6700/8214] Elapsed 29m 47s (remain 6m 43s) Loss: 0.7042(0.6498) Grad: 14409.6611  LR: 0.00001802  \n","Epoch: [1][6800/8214] Elapsed 30m 13s (remain 6m 16s) Loss: 0.6206(0.6501) Grad: 19663.9980  LR: 0.00001796  \n","Epoch: [1][6900/8214] Elapsed 30m 40s (remain 5m 50s) Loss: 0.7060(0.6502) Grad: 28500.6113  LR: 0.00001790  \n","Epoch: [1][7000/8214] Elapsed 31m 7s (remain 5m 23s) Loss: 0.6825(0.6502) Grad: 34772.0977  LR: 0.00001784  \n","Epoch: [1][7100/8214] Elapsed 31m 33s (remain 4m 56s) Loss: 0.6329(0.6504) Grad: 22493.0078  LR: 0.00001778  \n","Epoch: [1][7200/8214] Elapsed 32m 0s (remain 4m 30s) Loss: 0.6814(0.6503) Grad: 11332.4854  LR: 0.00001772  \n","Epoch: [1][7300/8214] Elapsed 32m 26s (remain 4m 3s) Loss: 0.6784(0.6505) Grad: 16152.6455  LR: 0.00001766  \n","Epoch: [1][7400/8214] Elapsed 32m 53s (remain 3m 36s) Loss: 0.6731(0.6505) Grad: 21846.4941  LR: 0.00001760  \n","Epoch: [1][7500/8214] Elapsed 33m 19s (remain 3m 10s) Loss: 0.6215(0.6505) Grad: 12452.9678  LR: 0.00001754  \n","Epoch: [1][7600/8214] Elapsed 33m 46s (remain 2m 43s) Loss: 0.6579(0.6506) Grad: 20438.4258  LR: 0.00001747  \n","Epoch: [1][7700/8214] Elapsed 34m 12s (remain 2m 16s) Loss: 0.5840(0.6506) Grad: 24863.1934  LR: 0.00001741  \n","Epoch: [1][7800/8214] Elapsed 34m 39s (remain 1m 50s) Loss: 0.6010(0.6506) Grad: 17583.5527  LR: 0.00001734  \n","Epoch: [1][7900/8214] Elapsed 35m 6s (remain 1m 23s) Loss: 0.7657(0.6506) Grad: 32231.3828  LR: 0.00001728  \n","Epoch: [1][8000/8214] Elapsed 35m 32s (remain 0m 56s) Loss: 0.7107(0.6506) Grad: 36937.5742  LR: 0.00001721  \n","Epoch: [1][8100/8214] Elapsed 35m 59s (remain 0m 30s) Loss: 0.6568(0.6507) Grad: 21880.6348  LR: 0.00001715  \n","Epoch: [1][8200/8214] Elapsed 36m 26s (remain 0m 3s) Loss: 0.6720(0.6508) Grad: 11735.3643  LR: 0.00001708  \n","Epoch: [1][8213/8214] Elapsed 36m 29s (remain 0m 0s) Loss: 0.6843(0.6508) Grad: 16869.5391  LR: 0.00001707  \n","EVAL: [0/221] Elapsed 0m 0s (remain 2m 24s) Loss: 0.6429(0.6429) \n","EVAL: [100/221] Elapsed 0m 16s (remain 0m 19s) Loss: 0.6888(0.6545) \n","EVAL: [200/221] Elapsed 0m 32s (remain 0m 3s) Loss: 0.6271(0.6535) \n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.6508  avg_val_loss: 0.6555  time: 2226s\n","Epoch 1 - Score: -0.0069\n"]},{"output_type":"stream","name":"stdout","text":["EVAL: [220/221] Elapsed 0m 35s (remain 0m 0s) Loss: 0.8441(0.6555) \n","Epoch: [2][0/8214] Elapsed 0m 0s (remain 113m 18s) Loss: 0.6357(0.6357) Grad: 19148.1309  LR: 0.00001707  \n","Epoch: [2][100/8214] Elapsed 0m 27s (remain 36m 58s) Loss: 0.6615(0.6586) Grad: 7647.6992  LR: 0.00001700  \n","Epoch: [2][200/8214] Elapsed 0m 54s (remain 36m 6s) Loss: 0.6836(0.6591) Grad: 18132.7773  LR: 0.00001693  \n","Epoch: [2][300/8214] Elapsed 1m 21s (remain 35m 33s) Loss: 0.6184(0.6565) Grad: 23713.7207  LR: 0.00001686  \n","Epoch: [2][400/8214] Elapsed 1m 47s (remain 35m 1s) Loss: 0.6084(0.6569) Grad: 45907.8281  LR: 0.00001679  \n","Epoch: [2][500/8214] Elapsed 2m 14s (remain 34m 30s) Loss: 0.6381(0.6571) Grad: 14621.3516  LR: 0.00001672  \n","Epoch: [2][600/8214] Elapsed 2m 41s (remain 34m 1s) Loss: 0.6922(0.6560) Grad: 33622.6523  LR: 0.00001665  \n","Epoch: [2][700/8214] Elapsed 3m 7s (remain 33m 33s) Loss: 0.6156(0.6561) Grad: 54753.9023  LR: 0.00001658  \n","Epoch: [2][800/8214] Elapsed 3m 34s (remain 33m 6s) Loss: 0.6194(0.6546) Grad: 67413.6406  LR: 0.00001651  \n","Epoch: [2][900/8214] Elapsed 4m 1s (remain 32m 40s) Loss: 0.6951(0.6545) Grad: 114938.0625  LR: 0.00001644  \n","Epoch: [2][1000/8214] Elapsed 4m 28s (remain 32m 12s) Loss: 0.6914(0.6542) Grad: 33058.6484  LR: 0.00001636  \n","Epoch: [2][1100/8214] Elapsed 4m 54s (remain 31m 44s) Loss: 0.6472(0.6542) Grad: 28565.2793  LR: 0.00001629  \n","Epoch: [2][1200/8214] Elapsed 5m 21s (remain 31m 17s) Loss: 0.6455(0.6543) Grad: 20147.9980  LR: 0.00001621  \n","Epoch: [2][1300/8214] Elapsed 5m 48s (remain 30m 49s) Loss: 0.6162(0.6547) Grad: 40396.0508  LR: 0.00001614  \n","Epoch: [2][1400/8214] Elapsed 6m 14s (remain 30m 22s) Loss: 0.6702(0.6548) Grad: 28475.3848  LR: 0.00001606  \n","Epoch: [2][1500/8214] Elapsed 6m 41s (remain 29m 55s) Loss: 0.7183(0.6548) Grad: 46941.4492  LR: 0.00001599  \n","Epoch: [2][1600/8214] Elapsed 7m 8s (remain 29m 29s) Loss: 0.6467(0.6543) Grad: 26430.2598  LR: 0.00001591  \n","Epoch: [2][1700/8214] Elapsed 7m 34s (remain 29m 2s) Loss: 0.6411(0.6545) Grad: 18951.0547  LR: 0.00001583  \n","Epoch: [2][1800/8214] Elapsed 8m 1s (remain 28m 35s) Loss: 0.6632(0.6545) Grad: 34254.6016  LR: 0.00001576  \n","Epoch: [2][1900/8214] Elapsed 8m 28s (remain 28m 8s) Loss: 0.7050(0.6549) Grad: 47615.1250  LR: 0.00001568  \n","Epoch: [2][2000/8214] Elapsed 8m 55s (remain 27m 41s) Loss: 0.7040(0.6548) Grad: 48240.6406  LR: 0.00001560  \n","Epoch: [2][2100/8214] Elapsed 9m 21s (remain 27m 14s) Loss: 0.6553(0.6549) Grad: 41026.9297  LR: 0.00001552  \n","Epoch: [2][2200/8214] Elapsed 9m 48s (remain 26m 47s) Loss: 0.6001(0.6547) Grad: 34891.3594  LR: 0.00001544  \n","Epoch: [2][2300/8214] Elapsed 10m 15s (remain 26m 20s) Loss: 0.6506(0.6547) Grad: 47962.9844  LR: 0.00001536  \n","Epoch: [2][2400/8214] Elapsed 10m 41s (remain 25m 54s) Loss: 0.6419(0.6545) Grad: 19632.7598  LR: 0.00001528  \n","Epoch: [2][2500/8214] Elapsed 11m 8s (remain 25m 27s) Loss: 0.6272(0.6545) Grad: 28875.3457  LR: 0.00001520  \n","Epoch: [2][2600/8214] Elapsed 11m 35s (remain 25m 0s) Loss: 0.6815(0.6545) Grad: 121736.8516  LR: 0.00001511  \n","Epoch: [2][2700/8214] Elapsed 12m 2s (remain 24m 33s) Loss: 0.6465(0.6546) Grad: 68527.5547  LR: 0.00001503  \n","Epoch: [2][2800/8214] Elapsed 12m 28s (remain 24m 7s) Loss: 0.6373(0.6547) Grad: 91990.4688  LR: 0.00001495  \n","Epoch: [2][2900/8214] Elapsed 12m 55s (remain 23m 40s) Loss: 0.6203(0.6547) Grad: 64435.6836  LR: 0.00001486  \n","Epoch: [2][3000/8214] Elapsed 13m 22s (remain 23m 13s) Loss: 0.5941(0.6546) Grad: 88392.5625  LR: 0.00001478  \n","Epoch: [2][3100/8214] Elapsed 13m 48s (remain 22m 46s) Loss: 0.6925(0.6547) Grad: 167803.6250  LR: 0.00001470  \n","Epoch: [2][3200/8214] Elapsed 14m 15s (remain 22m 19s) Loss: 0.6717(0.6548) Grad: 59273.8984  LR: 0.00001461  \n","Epoch: [2][3300/8214] Elapsed 14m 42s (remain 21m 53s) Loss: 0.6439(0.6547) Grad: 71903.6953  LR: 0.00001453  \n","Epoch: [2][3400/8214] Elapsed 15m 8s (remain 21m 26s) Loss: 0.6489(0.6547) Grad: 30891.4219  LR: 0.00001444  \n","Epoch: [2][3500/8214] Elapsed 15m 35s (remain 20m 59s) Loss: 0.6415(0.6546) Grad: 31795.3770  LR: 0.00001436  \n","Epoch: [2][3600/8214] Elapsed 16m 2s (remain 20m 32s) Loss: 0.6073(0.6544) Grad: 69489.3359  LR: 0.00001427  \n","Epoch: [2][3700/8214] Elapsed 16m 29s (remain 20m 6s) Loss: 0.5765(0.6545) Grad: 103824.2578  LR: 0.00001418  \n","Epoch: [2][3800/8214] Elapsed 16m 55s (remain 19m 39s) Loss: 0.6074(0.6546) Grad: 80974.6797  LR: 0.00001410  \n","Epoch: [2][3900/8214] Elapsed 17m 22s (remain 19m 12s) Loss: 0.7046(0.6546) Grad: 91726.6875  LR: 0.00001401  \n","Epoch: [2][4000/8214] Elapsed 17m 49s (remain 18m 45s) Loss: 0.6262(0.6544) Grad: 47254.8672  LR: 0.00001392  \n","Epoch: [2][4100/8214] Elapsed 18m 16s (remain 18m 19s) Loss: 0.7148(0.6545) Grad: 75368.0469  LR: 0.00001383  \n","Epoch: [2][4200/8214] Elapsed 18m 42s (remain 17m 52s) Loss: 0.6686(0.6546) Grad: 42800.1641  LR: 0.00001374  \n","Epoch: [2][4300/8214] Elapsed 19m 9s (remain 17m 25s) Loss: 0.6554(0.6547) Grad: 93009.9922  LR: 0.00001366  \n","Epoch: [2][4400/8214] Elapsed 19m 36s (remain 16m 59s) Loss: 0.6683(0.6548) Grad: 89160.0938  LR: 0.00001357  \n","Epoch: [2][4500/8214] Elapsed 20m 3s (remain 16m 32s) Loss: 0.6484(0.6548) Grad: 77169.4922  LR: 0.00001348  \n","Epoch: [2][4600/8214] Elapsed 20m 29s (remain 16m 5s) Loss: 0.6611(0.6550) Grad: 140540.8594  LR: 0.00001339  \n","Epoch: [2][4700/8214] Elapsed 20m 56s (remain 15m 38s) Loss: 0.6315(0.6550) Grad: 56579.6367  LR: 0.00001330  \n","Epoch: [2][4800/8214] Elapsed 21m 23s (remain 15m 12s) Loss: 0.7929(0.6549) Grad: 163665.5781  LR: 0.00001321  \n","Epoch: [2][4900/8214] Elapsed 21m 49s (remain 14m 45s) Loss: 0.6543(0.6550) Grad: 42151.7773  LR: 0.00001312  \n","Epoch: [2][5000/8214] Elapsed 22m 16s (remain 14m 18s) Loss: 0.7032(0.6550) Grad: 157131.2031  LR: 0.00001302  \n","Epoch: [2][5100/8214] Elapsed 22m 43s (remain 13m 51s) Loss: 0.6859(0.6550) Grad: 96018.2656  LR: 0.00001293  \n","Epoch: [2][5200/8214] Elapsed 23m 10s (remain 13m 25s) Loss: 0.6690(0.6549) Grad: 48849.7930  LR: 0.00001284  \n","Epoch: [2][5300/8214] Elapsed 23m 36s (remain 12m 58s) Loss: 0.6638(0.6550) Grad: 45481.5938  LR: 0.00001275  \n"]}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()\n","\n","\n","\n","\n","    # Push to LINE\n","    import requests\n","\n","    def send_line_notification(message):\n","        import json\n","        f = open(\"../../line.json\", \"r\")\n","        json_data = json.load(f)\n","        line_token = json_data[\"kagglePush\"]\n","        endpoint = 'https://notify-api.line.me/api/notify'\n","        message = \"\\n{}\".format(message)\n","        payload = {'message': message}\n","        headers = {'Authorization': 'Bearer {}'.format(line_token)}\n","        requests.post(endpoint, data=payload, headers=headers)\n","\n","    if CFG.wandb:\n","        send_line_notification(f\"Training of {CFG.wandbproject+'/'+CFG.wandbgroup+'/'+CFG.wandbname} has been done. See {run.url}\")\n","    else:\n","        send_line_notification(f\"Training of {CFG.wandbproject+'/'+CFG.wandbgroup+'/'+CFG.wandbname} has been done.\")"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"nb005t-deberta-v3-large.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b79b138039494721b105a1b0bd4c5fed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fa92a0bc789743d3a57236cdb41b29ed","IPY_MODEL_127610ebd60e4ee9997d324dd04ded81","IPY_MODEL_f63a186b2fa34e4f90e3c2866e536a35"],"layout":"IPY_MODEL_fc09a66bc800456e9f39dbffbc80a1c5"}},"fa92a0bc789743d3a57236cdb41b29ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90f58d38edbe4ab88480dd26be7555ce","placeholder":"​","style":"IPY_MODEL_8bd7307d059b47ee9c113e099c2d702e","value":"100%"}},"127610ebd60e4ee9997d324dd04ded81":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_20dd2d625fdb4dd2bab63dfea3fcafa8","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b5d82697e344c1183f9a6fa9d302d95","value":136}},"f63a186b2fa34e4f90e3c2866e536a35":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_aeb95f4d1ce248e1ae111cdb7fcd7c14","placeholder":"​","style":"IPY_MODEL_127c4c7efdbf449abf1d0dc3e0b9d5af","value":" 136/136 [00:00&lt;00:00, 1885.48it/s]"}},"fc09a66bc800456e9f39dbffbc80a1c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"90f58d38edbe4ab88480dd26be7555ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8bd7307d059b47ee9c113e099c2d702e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20dd2d625fdb4dd2bab63dfea3fcafa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b5d82697e344c1183f9a6fa9d302d95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"aeb95f4d1ce248e1ae111cdb7fcd7c14":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"127c4c7efdbf449abf1d0dc3e0b9d5af":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"73c96f639acc486e8303d30c09be1066":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4d0568af34044925929947ff5fe13a51","IPY_MODEL_b45c1300b2814035b7ee9bd463922740","IPY_MODEL_b78d548f21f746f0b34e05d57edae04d"],"layout":"IPY_MODEL_2fd0aec5d12c4166b1175a0daf002ce1"}},"4d0568af34044925929947ff5fe13a51":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_14075c01b071412eaf78ce645a100d36","placeholder":"​","style":"IPY_MODEL_2c97648f4a11412087307cdf1e2cabfe","value":"100%"}},"b45c1300b2814035b7ee9bd463922740":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3f6b449c859348a2add8ed52114d9040","max":1017509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bf2b2f219b6e4e1db3e41a983f2b2716","value":1017509}},"b78d548f21f746f0b34e05d57edae04d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_eff760ed44d746adbc80aaba1a88ebc8","placeholder":"​","style":"IPY_MODEL_179bd11a11e44342bb69e35bb9061767","value":" 1017509/1017509 [01:23&lt;00:00, 12345.05it/s]"}},"2fd0aec5d12c4166b1175a0daf002ce1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14075c01b071412eaf78ce645a100d36":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2c97648f4a11412087307cdf1e2cabfe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f6b449c859348a2add8ed52114d9040":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bf2b2f219b6e4e1db3e41a983f2b2716":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"eff760ed44d746adbc80aaba1a88ebc8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"179bd11a11e44342bb69e35bb9061767":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72adde662b954fc09d4fd0de86e78618":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4cfeaacd91694ec5ad6ce0339284652d","IPY_MODEL_5e159af98d9a4edc9cf8b1d67c5a6da4","IPY_MODEL_22aef91e333544629bb275b69f66594e"],"layout":"IPY_MODEL_e24db575522b4968854a5a19cb2a2505"}},"4cfeaacd91694ec5ad6ce0339284652d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_026cef6ad8244ff78febb5be9c4725bf","placeholder":"​","style":"IPY_MODEL_d25b54c6556a427c82cce284a9c72660","value":"100%"}},"5e159af98d9a4edc9cf8b1d67c5a6da4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0e9eb116cb04850bd61acd5e79da9cb","max":1017509,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fd59fb0ba889487aa9a861ed43a640cc","value":1017509}},"22aef91e333544629bb275b69f66594e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5daca19182ac45b3b55f27db686b4f8b","placeholder":"​","style":"IPY_MODEL_6bba8a58025a451db5a329eda0e9ecca","value":" 1017509/1017509 [01:25&lt;00:00, 11816.84it/s]"}},"e24db575522b4968854a5a19cb2a2505":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"026cef6ad8244ff78febb5be9c4725bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d25b54c6556a427c82cce284a9c72660":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0e9eb116cb04850bd61acd5e79da9cb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd59fb0ba889487aa9a861ed43a640cc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5daca19182ac45b3b55f27db686b4f8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6bba8a58025a451db5a329eda0e9ecca":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}