{"cells":[{"cell_type":"markdown","metadata":{"id":"e460cbb5"},"source":["# About this notebook\n","- tokenizer(anchor[SEP]target | CPC)\n","- Deberta-v3-large starter code\n","- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/pppm-pip-wheels)\n","- Inference notebook is [here](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n","\n","If this notebook is helpful, feel free to upvote :)"]},{"cell_type":"markdown","metadata":{"id":"xONchFYMvMMf"},"source":["# Directory settings"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6151,"status":"ok","timestamp":1655189822511,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"fa3b873b","outputId":"9a840b1f-ba96-4e2d-e1f5-ddf98a03c31c"},"outputs":[{"name":"stdout","output_type":"stream","text":["3.7.13 (default, Apr 24 2022, 01:04:09) \n","[GCC 7.5.0]\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/colab_notebooks/kaggle/us-patent-phrase-to-phrase-matching/notebooks\n"]}],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","comp_name = 'us-patent-phrase-to-phrase-matching'\n","nb_name = 'nb005t-deberta-v3-large'\n","\n","import sys\n","print(sys.version)\n","if \"google.colab\" in sys.modules:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    base = f\"/content/drive/MyDrive/colab_notebooks/kaggle/{comp_name}/notebooks\"\n","    %cd {base}\n","\n","\n","import os\n","INPUT_DIR = f'../input/{comp_name}/'\n","if 'kaggle_web_client' in sys.modules:\n","    OUTPUT_DIR = './'\n","else:\n","    OUTPUT_DIR = f'../input/{nb_name}/'\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"1d0c4430"},"source":["# CFG"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1655189822512,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"48dd82bb"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    wandb=True\n","    wandbproject=comp_name\n","    wandbgroup=nb_name\n","    wandbname='exp004'\n","    _wandb_kernel='riow1983'\n","    apex=True\n","    print_freq=100\n","    num_workers=8\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=8\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    #### AWP\n","    adv_lr=1e-6\n","    adv_eps=1e-3\n","    #### AWPAWP\n","    n_fold=4\n","    trn_fold=[0, 1, 2, 3]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]\n","    CFG.wandb = False"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"executionInfo":{"elapsed":7111,"status":"ok","timestamp":1655189829616,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"b88c983e","outputId":"0738b8c2-750f-4919-f0da-ddf14095e21c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.18)\n","Requirement already satisfied: psutil\u003e=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: sentry-sdk\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.12)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n","Requirement already satisfied: six\u003e=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: requests\u003c3,\u003e=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: docker-pycreds\u003e=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: shortuuid\u003e=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: promise\u003c3,\u003e=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: protobuf\u003c4.0dev,\u003e=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: GitPython\u003e=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: Click!=8.0.0,\u003e=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: gitdb\u003c5,\u003e=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.0.9)\n","Requirement already satisfied: typing-extensions\u003e=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython\u003e=1.0.0-\u003ewandb) (4.2.0)\n","Requirement already satisfied: smmap\u003c6,\u003e=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb\u003c5,\u003e=4.0.1-\u003eGitPython\u003e=1.0.0-\u003ewandb) (5.0.0)\n","Requirement already satisfied: idna\u003c3,\u003e=2.5 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2.10)\n","Requirement already satisfied: certifi\u003e=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (2022.5.18.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,\u003c1.26,\u003e=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (1.24.3)\n","Requirement already satisfied: chardet\u003c4,\u003e=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests\u003c3,\u003e=2.0.0-\u003ewandb) (3.0.4)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mriow1983\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.18"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in \u003ccode\u003e../input/nb005t-deberta-v3-large/wandb/run-20220614_065707-26oy5db1\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run \u003cstrong\u003e\u003ca href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching/runs/26oy5db1\" target=\"_blank\"\u003eexp004\u003c/a\u003e\u003c/strong\u003e to \u003ca href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching\" target=\"_blank\"\u003eWeights \u0026 Biases\u003c/a\u003e (\u003ca href=\"https://wandb.me/run\" target=\"_blank\"\u003edocs\u003c/a\u003e)\u003cbr/\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["wandb run id: 26oy5db1\n"]}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    if 'google.colab' in sys.modules:\n","        !pip install wandb\n","    import wandb\n","\n","    try:\n","        if 'kaggle_web_client' in sys.modules:\n","            from kaggle_secrets import UserSecretsClient\n","            user_secrets = UserSecretsClient()\n","            secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        else:\n","            import json\n","            f = open(\"../../wandb.json\", \"r\")\n","            json_data = json.load(f)\n","            secret_value_0 = json_data[\"wandb_api\"]\n","        wandb.login(key=secret_value_0)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W\u0026B account, go to Add-ons -\u003e Secrets and provide your W\u0026B access token. Use the Label name as wandb_api. \\nGet your W\u0026B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","    \n","    run = wandb.init(\n","        dir=OUTPUT_DIR,\n","        project=CFG.wandbproject,\n","        group=CFG.wandbgroup,\n","        name=CFG.wandbname, \n","        config=class2dict(CFG),\n","        job_type=\"train\",\n","        anonymous=anony)\n","    print(f\"wandb run id: {run.id}\")"]},{"cell_type":"markdown","metadata":{"id":"f2ed8ef2"},"source":["# Library"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17133,"status":"ok","timestamp":1655189846743,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"35916341","outputId":"3f007e7d-7dd5-4c08-ab13-d13eb7a571de"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.11.0+cu113\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.18.0\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","\n","# # PyTorchのバージョンを1.10.1に下げる (Google Colabなのでpipでやる)\n","# os.system('pip uninstall -y torch torchvision torchaudio')\n","# os.system('pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html')\n","\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","os.system('pip uninstall -y transformers')\n","os.system('pip uninstall -y tokenizers')\n","os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels transformers')\n","os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels tokenizers')\n","# os.system('python -m pip install transformers')\n","# os.system('python -m pip install tokenizers')\n","os.system('pip install sentencepiece')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","#### TFH\n","from transformers import AutoModelForTokenClassification\n","#### TFHTFH\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"fd586614"},"source":["# Utils"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1655189846744,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"d5c0ccc6"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"cb3d8e1e"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":34,"status":"ok","timestamp":1655189846745,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"bef012d3","outputId":"f2eb5ecd-2070-494d-e48b-1fe804da187a"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (36473, 5)\n","test.shape: (36, 4)\n","submission.shape: (36, 2)\n"]},{"data":{"text/html":["\n","  \u003cdiv id=\"df-aeab07d3-268b-4193-a22b-3a7ff33599b1\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeab07d3-268b-4193-a22b-3a7ff33599b1')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-aeab07d3-268b-4193-a22b-3a7ff33599b1 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-aeab07d3-268b-4193-a22b-3a7ff33599b1');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-8424cff0-721a-43a1-b77c-157bdd972841\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8424cff0-721a-43a1-b77c-157bdd972841')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-8424cff0-721a-43a1-b77c-157bdd972841 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-8424cff0-721a-43a1-b77c-157bdd972841');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n","2  36baf228038e314b      lower trunnion                 lower locating     B60\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-330e7d68-9955-4bc9-bb05-e478a789cf07\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003e0\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-330e7d68-9955-4bc9-bb05-e478a789cf07')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-330e7d68-9955-4bc9-bb05-e478a789cf07 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-330e7d68-9955-4bc9-bb05-e478a789cf07');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id  score\n","0  4112d61851461f60      0\n","1  09e418c93a776564      0\n","2  36baf228038e314b      0\n","3  1f37ead645e7f0c8      0\n","4  71a5b6ad068d531f      0"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv(INPUT_DIR+'train.csv')\n","test = pd.read_csv(INPUT_DIR+'test.csv')\n","submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n","print(f\"train.shape: {train.shape}\")\n","print(f\"test.shape: {test.shape}\")\n","print(f\"submission.shape: {submission.shape}\")\n","display(train.head())\n","display(test.head())\n","display(submission.head())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":613},"executionInfo":{"elapsed":618,"status":"ok","timestamp":1655189847350,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"UCsnldv5vMMq","outputId":"559b1f8d-37a8-4a87-ad46-ba2caf137e5c"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-d67bedd3-062d-4369-93e2-cbdca2077088\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d67bedd3-062d-4369-93e2-cbdca2077088')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-d67bedd3-062d-4369-93e2-cbdca2077088 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-d67bedd3-062d-4369-93e2-cbdca2077088');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-576bb3fa-7366-4392-a4ee-4129bda1030a\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-576bb3fa-7366-4392-a4ee-4129bda1030a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-576bb3fa-7366-4392-a4ee-4129bda1030a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-576bb3fa-7366-4392-a4ee-4129bda1030a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","def get_cpc_texts():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('../input/cpc-data/CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'../input/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","cpc_texts = get_cpc_texts()\n","torch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\n","train['context_text'] = train['context'].map(cpc_texts)\n","test['context_text'] = test['context'].map(cpc_texts)\n","display(train.head())\n","display(test.head())"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":41,"status":"ok","timestamp":1655189847351,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"PJvUJQujvMMr","outputId":"cef6cbef-ff0a-4892-aad7-de7f3b224297"},"outputs":[{"data":{"text/html":["\n","  \u003cdiv id=\"df-a10a2267-ddef-4666-99b2-25f36fbcd533\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003escore\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","      \u003cth\u003etext2\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e37d61fd2272659b1\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eabatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]abatement of pollution\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e7b9652b17b68b7a4\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eact of abating\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.75\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]act of abating\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36d72442aefd8232\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eactive catalyst\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.25\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]active catalyst\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e5296b0c19e1ce60e\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eeliminating process\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.50\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]eliminating process\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e54c1e3b9184cb5b6\u003c/td\u003e\n","      \u003ctd\u003eabatement\u003c/td\u003e\n","      \u003ctd\u003eforest region\u003c/td\u003e\n","      \u003ctd\u003eA47\u003c/td\u003e\n","      \u003ctd\u003e0.00\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","      \u003ctd\u003eabatement[SEP]forest region\u003c/td\u003e\n","      \u003ctd\u003eHUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a10a2267-ddef-4666-99b2-25f36fbcd533')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-a10a2267-ddef-4666-99b2-25f36fbcd533 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a10a2267-ddef-4666-99b2-25f36fbcd533');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text                                  text                                              text2\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]abatement of pollution  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          abatement[SEP]act of abating  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...         abatement[SEP]active catalyst  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     abatement[SEP]eliminating process  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...           abatement[SEP]forest region  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  \u003cdiv id=\"df-851673b9-f9fe-44c5-a467-3fa7eb1c5abd\"\u003e\n","    \u003cdiv class=\"colab-df-container\"\u003e\n","      \u003cdiv\u003e\n","\u003cstyle scoped\u003e\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","\u003c/style\u003e\n","\u003ctable border=\"1\" class=\"dataframe\"\u003e\n","  \u003cthead\u003e\n","    \u003ctr style=\"text-align: right;\"\u003e\n","      \u003cth\u003e\u003c/th\u003e\n","      \u003cth\u003eid\u003c/th\u003e\n","      \u003cth\u003eanchor\u003c/th\u003e\n","      \u003cth\u003etarget\u003c/th\u003e\n","      \u003cth\u003econtext\u003c/th\u003e\n","      \u003cth\u003econtext_text\u003c/th\u003e\n","      \u003cth\u003etext\u003c/th\u003e\n","      \u003cth\u003etext2\u003c/th\u003e\n","    \u003c/tr\u003e\n","  \u003c/thead\u003e\n","  \u003ctbody\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e0\u003c/th\u003e\n","      \u003ctd\u003e4112d61851461f60\u003c/td\u003e\n","      \u003ctd\u003eopc drum\u003c/td\u003e\n","      \u003ctd\u003einorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003eG02\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","      \u003ctd\u003eopc drum[SEP]inorganic photoconductor drum\u003c/td\u003e\n","      \u003ctd\u003ePHYSICS. OPTICS\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e1\u003c/th\u003e\n","      \u003ctd\u003e09e418c93a776564\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow\u003c/td\u003e\n","      \u003ctd\u003ealtering gas flow\u003c/td\u003e\n","      \u003ctd\u003eF23\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","      \u003ctd\u003eadjust gas flow[SEP]altering gas flow\u003c/td\u003e\n","      \u003ctd\u003eMECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e2\u003c/th\u003e\n","      \u003ctd\u003e36baf228038e314b\u003c/td\u003e\n","      \u003ctd\u003elower trunnion\u003c/td\u003e\n","      \u003ctd\u003elower locating\u003c/td\u003e\n","      \u003ctd\u003eB60\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","      \u003ctd\u003elower trunnion[SEP]lower locating\u003c/td\u003e\n","      \u003ctd\u003ePERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e3\u003c/th\u003e\n","      \u003ctd\u003e1f37ead645e7f0c8\u003c/td\u003e\n","      \u003ctd\u003ecap component\u003c/td\u003e\n","      \u003ctd\u003eupper portion\u003c/td\u003e\n","      \u003ctd\u003eD06\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","      \u003ctd\u003ecap component[SEP]upper portion\u003c/td\u003e\n","      \u003ctd\u003eTEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\u003c/td\u003e\n","    \u003c/tr\u003e\n","    \u003ctr\u003e\n","      \u003cth\u003e4\u003c/th\u003e\n","      \u003ctd\u003e71a5b6ad068d531f\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation\u003c/td\u003e\n","      \u003ctd\u003eartificial neural network\u003c/td\u003e\n","      \u003ctd\u003eH04\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","      \u003ctd\u003eneural stimulation[SEP]artificial neural network\u003c/td\u003e\n","      \u003ctd\u003eELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE\u003c/td\u003e\n","    \u003c/tr\u003e\n","  \u003c/tbody\u003e\n","\u003c/table\u003e\n","\u003c/div\u003e\n","      \u003cbutton class=\"colab-df-convert\" onclick=\"convertToInteractive('df-851673b9-f9fe-44c5-a467-3fa7eb1c5abd')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\"\u003e\n","        \n","  \u003csvg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\"\u003e\n","    \u003cpath d=\"M0 0h24v24H0V0z\" fill=\"none\"/\u003e\n","    \u003cpath d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/\u003e\u003cpath d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/\u003e\n","  \u003c/svg\u003e\n","      \u003c/button\u003e\n","      \n","  \u003cstyle\u003e\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  \u003c/style\u003e\n","\n","      \u003cscript\u003e\n","        const buttonEl =\n","          document.querySelector('#df-851673b9-f9fe-44c5-a467-3fa7eb1c5abd button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-851673b9-f9fe-44c5-a467-3fa7eb1c5abd');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '\u003ca target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb\u003edata table notebook\u003c/a\u003e'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      \u003c/script\u003e\n","    \u003c/div\u003e\n","  \u003c/div\u003e\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text                                              text                                              text2\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS        opc drum[SEP]inorganic photoconductor drum                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...             adjust gas flow[SEP]altering gas flow  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...                 lower trunnion[SEP]lower locating  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...                   cap component[SEP]upper portion  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE  neural stimulation[SEP]artificial neural network      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n","\n","train['text'] = train['anchor'] + '[SEP]' + train['target']\n","test['text'] = test['anchor'] + '[SEP]' + test['target']\n","\n","train['text2'] = train['context_text']\n","test['text2'] = test['context_text']\n","\n","\n","display(train.head())\n","display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"zuhGVmnivMMs"},"source":["# EDA"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"elapsed":377,"status":"ok","timestamp":1655189847690,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"CdwSw4u5vMMs","outputId":"5a3362ef-6550-4d57-cd54-071eeb46b73e"},"outputs":[{"data":{"text/plain":["\u003cmatplotlib.axes._subplots.AxesSubplot at 0x7fcccf5a4290\u003e"]},"execution_count":9,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 432x288 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["train['score'].hist()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":22,"status":"ok","timestamp":1655189847691,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"GJBRJnjevMMs","outputId":"26b51273-66a3-4ca9-9e91-f05cdecbf741"},"outputs":[{"data":{"text/plain":["B    8019\n","H    6195\n","G    6013\n","C    5288\n","A    4094\n","F    4054\n","E    1531\n","D    1279\n","Name: context, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"62MFTSvavMMt"},"source":["- Y is not in training data, but may be in test data?"]},{"cell_type":"markdown","metadata":{"id":"9e05b6c4"},"source":["# CV split"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2966,"status":"ok","timestamp":1655189850638,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"3ba287c4","outputId":"1d1b0766-acf5-426c-d50b-4d5f573d7bfa"},"outputs":[{"name":"stdout","output_type":"stream","text":["550 183\n","549 184\n","550 183\n","550 183\n","3    9622\n","0    9379\n","1    8860\n","2    8612\n","Name: fold, dtype: int64\n"]}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","# Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","# train['fold'] = train['fold'].astype(int)\n","# display(train.groupby('fold').size())\n","\n","\n","\n","# Credits to https://www.kaggle.com/code/hannes82/pppm-deberta-v3-large-closing-the-cv-lb-gap/notebook#CV-split\n","#credits to: https://www.kaggle.com/code/abhishek/creating-folds-properly-hopefully-p\n","\n","!pip install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train = train.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")\n","del dfx\n","print(train.fold.value_counts())"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1655189850640,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"4c3ce877"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"918a28aa"},"source":["# tokenizer"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3920,"status":"ok","timestamp":1655189854553,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"H4pgQRxAvMMv","outputId":"b5c656b2-0553-4a7a-ecfa-443a001fb2ba"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"14da40cf"},"source":["# Dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131},"executionInfo":{"elapsed":5541,"status":"ok","timestamp":1655189860082,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"c00327b0","outputId":"af65b6bf-e71f-4859-939d-44a6d862139f"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"6aece71288b44130a24eb3cabc4a64dd","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/136 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"bdc9f1c1a6c0451c8c2be96132b90bf1","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"484fd3df25aa443994c36118e1c349dc","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00\u003c?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_len: 133\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","# CFG.max_len = max(max(lengths_dict['anchor'])+max(lengths_dict['target'])+3, max(lengths_dict['context_text'])+2)\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1655189860083,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"9f791a19"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text, text2):\n","    inputs = cfg.tokenizer(text, text2,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.texts2 = df['text2'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item], self.texts2[item])\n","        #inputs2 = prepare_input(self.cfg, self.texts2[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        #return inputs, inputs2, label\n","        return inputs, label"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1655189860083,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"a200bd5b","outputId":"9c3983ac-d89f-410e-de54-1a39d31356d5"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_dataset = TrainDataset(CFG, train)\\ninputs, label = train_dataset[0]\\nprint(inputs)\\nprint(label)\\n'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","train_dataset = TrainDataset(CFG, train)\n","inputs, label = train_dataset[0]\n","print(inputs)\n","print(label)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"e04d6363"},"source":["# Model"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1655189860084,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"2zrMGZbdBI2i"},"outputs":[],"source":["#### TFH\n","class TransformerHead(nn.Module):\n","    def __init__(self, in_features, max_length, num_layers=1, nhead=8, num_targets=1):\n","        super().__init__()\n","\n","        self.transformer = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(d_model=in_features,\n","                                                                                          nhead=nhead),\n","                                                 num_layers=num_layers)\n","        self.row_fc = nn.Linear(in_features, 1)\n","        self.out_features = max_length\n","\n","    def forward(self, x):\n","        out = self.transformer(x)\n","        out = self.row_fc(out).squeeze(-1)\n","        return out\n","#### TFHTFH"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1655189860085,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"4c5bab44"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        \n","        #### TFH\n","        # self.attention = nn.Sequential(\n","        #     nn.Linear(self.config.hidden_size, 512),\n","        #     nn.Tanh(),\n","        #     nn.Linear(512, 1),\n","        #     nn.Softmax(dim=1)\n","        # )\n","        self.feature_extractor = AutoModelForTokenClassification.from_pretrained(\"../input/deberta-v3-large/deberta-v3-large\")\n","        in_features = self.feature_extractor.classifier.in_features\n","        self.attention = TransformerHead(in_features=in_features, max_length=CFG.max_len, num_layers=1, nhead=8, num_targets=1)\n","        #### TFHTFH\n","\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        #### TFH\n","        # self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        self.fc = nn.Linear(self.attention.out_features, self.cfg.target_size)\n","        #### TFHTFH\n","        \n","        self._init_weights(self.fc)\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    #### TFH  \n","    # def feature(self, inputs):\n","    #     outputs = self.model(**inputs)\n","    #     last_hidden_states = outputs[0]\n","        \n","    #     # outputs2 = self.model(**inputs2)\n","    #     # last_hidden_states2 = outputs2[0]\n","        \n","    #     # feature = torch.mean(last_hidden_states, 1)\n","    #     weights = self.attention(last_hidden_states)\n","    #     feature = torch.sum(weights * last_hidden_states, dim=1)\n","    #     #feature2 = torch.mean(last_hidden_states2, dim=1)\n","    #     #feature += feature2\n","    #     return feature\n","    \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.attention(last_hidden_states)\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output\n","    #### TFHTFH"]},{"cell_type":"markdown","metadata":{"id":"deee9675"},"source":["# Helpler functions"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":671,"status":"ok","timestamp":1655189860745,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"c8263b0c"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","#### AWP\n","#def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler, score, awp):\n","#### AWPAWP\n","    model.train()\n","    # AWP\n","    #scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    # AWPAWP\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs2.items():\n","        #     inputs2[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","\n","        #### AWP\n","        if score \u003e 0.75:\n","            awp.attack_backward(inputs['input_ids'], labels, inputs['attention_mask'], step) \n","        #### AWPAWP\n","\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs2.items():\n","        #     inputs2[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps \u003e 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs[1].items():\n","        #     inputs[1][k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1655189860745,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"CI1gkNrPRgan"},"outputs":[],"source":["#### AWP\n","class AWP:\n","    def __init__(\n","        self,\n","        model,\n","        optimizer,\n","        adv_param=\"weight\",\n","        adv_lr=1,\n","        adv_eps=0.2,\n","        start_epoch=0,\n","        adv_step=1,\n","        scaler=None\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.start_epoch = start_epoch\n","        self.adv_step = adv_step\n","        self.backup = {}\n","        self.backup_eps = {}\n","        self.scaler = scaler\n","\n","    def attack_backward(self, x, y, attention_mask,epoch):\n","        if (self.adv_lr == 0) or (epoch \u003c self.start_epoch):\n","            return None\n","\n","        self._save() \n","        for i in range(self.adv_step):\n","            self._attack_step() \n","            with torch.cuda.amp.autocast():\n","                adv_loss, tr_logits = self.model(input_ids=x, attention_mask=attention_mask, labels=y)\n","                adv_loss = adv_loss.mean()\n","            self.optimizer.zero_grad()\n","            self.scaler.scale(adv_loss).backward()\n","            \n","        self._restore()\n","\n","    def _attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","                # param.data.clamp_(*self.backup_eps[name])\n","\n","    def _save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def _restore(self,):\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}\n","\n","#### AWPAWP"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1655189860746,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"bed940e1"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model \u0026 optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = 0.\n","    #### AWP\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    awp = AWP(model,\n","              optimizer,\n","              adv_lr=CFG.adv_lr,\n","              adv_eps=CFG.adv_eps,\n","              start_epoch=num_train_steps/CFG.epochs,\n","              scaler=scaler)\n","    score = 0.\n","    #### AWPAWP\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        #### AWP\n","        #avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler, score, awp)\n","        #### AWPAWP\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score \u003c score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6cc76b1e"},"outputs":[{"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at ../input/deberta-v3-large/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3386] Elapsed 0m 0s (remain 56m 16s) Loss: 0.7154(0.7154) Grad: 194568.1406  LR: 0.00002000  \n","Epoch: [1][100/3386] Elapsed 0m 26s (remain 14m 22s) Loss: 0.5646(0.6579) Grad: 245190.9375  LR: 0.00002000  \n","Epoch: [1][200/3386] Elapsed 0m 52s (remain 13m 46s) Loss: 0.5020(0.6477) Grad: 63011.7461  LR: 0.00001999  \n","Epoch: [1][300/3386] Elapsed 1m 17s (remain 13m 15s) Loss: 0.6638(0.6300) Grad: 106463.8281  LR: 0.00001998  \n","Epoch: [1][400/3386] Elapsed 1m 43s (remain 12m 47s) Loss: 0.5170(0.6207) Grad: 52740.0156  LR: 0.00001996  \n","Epoch: [1][500/3386] Elapsed 2m 8s (remain 12m 21s) Loss: 0.6341(0.6145) Grad: 45606.6836  LR: 0.00001993  \n","Epoch: [1][600/3386] Elapsed 2m 34s (remain 11m 58s) Loss: 0.6397(0.6095) Grad: 50343.1953  LR: 0.00001990  \n","Epoch: [1][700/3386] Elapsed 3m 0s (remain 11m 32s) Loss: 0.5832(0.6060) Grad: 32401.4844  LR: 0.00001987  \n","Epoch: [1][800/3386] Elapsed 3m 26s (remain 11m 5s) Loss: 0.5601(0.6019) Grad: 57034.3789  LR: 0.00001983  \n","Epoch: [1][900/3386] Elapsed 3m 51s (remain 10m 39s) Loss: 0.6812(0.5986) Grad: 24064.0820  LR: 0.00001978  \n","Epoch: [1][1000/3386] Elapsed 4m 17s (remain 10m 13s) Loss: 0.6179(0.5962) Grad: 36477.3555  LR: 0.00001973  \n","Epoch: [1][1100/3386] Elapsed 4m 42s (remain 9m 47s) Loss: 0.5817(0.5941) Grad: 32086.3340  LR: 0.00001968  \n","Epoch: [1][1200/3386] Elapsed 5m 8s (remain 9m 21s) Loss: 0.3530(0.5913) Grad: 47271.8828  LR: 0.00001961  \n","Epoch: [1][1300/3386] Elapsed 5m 34s (remain 8m 55s) Loss: 0.5539(0.5888) Grad: 43906.3750  LR: 0.00001955  \n","Epoch: [1][1400/3386] Elapsed 6m 0s (remain 8m 30s) Loss: 0.5811(0.5868) Grad: 38620.0469  LR: 0.00001948  \n","Epoch: [1][1500/3386] Elapsed 6m 25s (remain 8m 4s) Loss: 0.5285(0.5844) Grad: 36277.3672  LR: 0.00001940  \n","Epoch: [1][1600/3386] Elapsed 6m 51s (remain 7m 38s) Loss: 0.8233(0.5832) Grad: 177906.7344  LR: 0.00001932  \n","Epoch: [1][1700/3386] Elapsed 7m 17s (remain 7m 12s) Loss: 0.6119(0.5822) Grad: 25454.4707  LR: 0.00001923  \n","Epoch: [1][1800/3386] Elapsed 7m 42s (remain 6m 47s) Loss: 0.6753(0.5817) Grad: 42378.6055  LR: 0.00001914  \n","Epoch: [1][1900/3386] Elapsed 8m 8s (remain 6m 21s) Loss: 0.4496(0.5810) Grad: 20966.8887  LR: 0.00001904  \n","Epoch: [1][2000/3386] Elapsed 8m 34s (remain 5m 55s) Loss: 0.5762(0.5803) Grad: 20498.6191  LR: 0.00001894  \n","Epoch: [1][2100/3386] Elapsed 8m 59s (remain 5m 30s) Loss: 0.3822(0.5793) Grad: 49249.8984  LR: 0.00001884  \n","Epoch: [1][2200/3386] Elapsed 9m 25s (remain 5m 4s) Loss: 0.5786(0.5792) Grad: 8860.0986  LR: 0.00001873  \n","Epoch: [1][2300/3386] Elapsed 9m 50s (remain 4m 38s) Loss: 0.3930(0.5781) Grad: 11051.0332  LR: 0.00001861  \n","Epoch: [1][2400/3386] Elapsed 10m 15s (remain 4m 12s) Loss: 0.4593(0.5767) Grad: 25562.8477  LR: 0.00001849  \n","Epoch: [1][2500/3386] Elapsed 10m 41s (remain 3m 46s) Loss: 0.5751(0.5761) Grad: 93864.3516  LR: 0.00001836  \n","Epoch: [1][2600/3386] Elapsed 11m 6s (remain 3m 21s) Loss: 0.5530(0.5749) Grad: 64721.4766  LR: 0.00001824  \n","Epoch: [1][2700/3386] Elapsed 11m 31s (remain 2m 55s) Loss: 0.5916(0.5740) Grad: 23728.5586  LR: 0.00001810  \n","Epoch: [1][2800/3386] Elapsed 11m 56s (remain 2m 29s) Loss: 0.4800(0.5728) Grad: 28435.2148  LR: 0.00001796  \n","Epoch: [1][2900/3386] Elapsed 12m 22s (remain 2m 4s) Loss: 0.5771(0.5720) Grad: 15160.6230  LR: 0.00001782  \n","Epoch: [1][3000/3386] Elapsed 12m 47s (remain 1m 38s) Loss: 0.6517(0.5716) Grad: 21231.4141  LR: 0.00001767  \n","Epoch: [1][3100/3386] Elapsed 13m 13s (remain 1m 12s) Loss: 0.6516(0.5707) Grad: 94692.0859  LR: 0.00001752  \n","Epoch: [1][3200/3386] Elapsed 13m 39s (remain 0m 47s) Loss: 0.5655(0.5699) Grad: 16262.3613  LR: 0.00001737  \n","Epoch: [1][3300/3386] Elapsed 14m 5s (remain 0m 21s) Loss: 0.5947(0.5694) Grad: 21097.6172  LR: 0.00001721  \n","Epoch: [1][3385/3386] Elapsed 14m 27s (remain 0m 0s) Loss: 0.5779(0.5689) Grad: 42133.4922  LR: 0.00001707  \n","EVAL: [0/1173] Elapsed 0m 0s (remain 13m 38s) Loss: 0.7134(0.7134) \n","EVAL: [100/1173] Elapsed 0m 9s (remain 1m 44s) Loss: 0.4729(0.5180) \n","EVAL: [200/1173] Elapsed 0m 18s (remain 1m 31s) Loss: 0.5108(0.5332) \n","EVAL: [300/1173] Elapsed 0m 28s (remain 1m 21s) Loss: 0.4824(0.5394) \n","EVAL: [400/1173] Elapsed 0m 37s (remain 1m 11s) Loss: 0.5160(0.5457) \n","EVAL: [500/1173] Elapsed 0m 46s (remain 1m 2s) Loss: 0.5640(0.5471) \n","EVAL: [600/1173] Elapsed 0m 55s (remain 0m 52s) Loss: 0.7635(0.5474) \n","EVAL: [700/1173] Elapsed 1m 4s (remain 0m 43s) Loss: 0.5434(0.5470) \n","EVAL: [800/1173] Elapsed 1m 13s (remain 0m 34s) Loss: 0.3383(0.5496) \n","EVAL: [900/1173] Elapsed 1m 22s (remain 0m 25s) Loss: 0.5981(0.5506) \n","EVAL: [1000/1173] Elapsed 1m 31s (remain 0m 15s) Loss: 0.6448(0.5525) \n","EVAL: [1100/1173] Elapsed 1m 41s (remain 0m 6s) Loss: 0.3774(0.5512) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5689  avg_val_loss: 0.5518  time: 975s\n","Epoch 1 - Score: 0.8139\n","Epoch 1 - Save Best Score: 0.8139 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1172/1173] Elapsed 1m 47s (remain 0m 0s) Loss: 0.6854(0.5518) \n","Epoch: [2][0/3386] Elapsed 0m 0s (remain 48m 18s) Loss: 0.5559(0.5559) Grad: 21995.3105  LR: 0.00001707  \n","Epoch: [2][100/3386] Elapsed 0m 26s (remain 14m 37s) Loss: 0.5426(0.5285) Grad: 38935.2617  LR: 0.00001690  \n","Epoch: [2][200/3386] Elapsed 0m 53s (remain 14m 12s) Loss: 0.5275(0.5287) Grad: 6343.1001  LR: 0.00001674  \n","Epoch: [2][300/3386] Elapsed 1m 20s (remain 13m 41s) Loss: 0.5876(0.5293) Grad: 100643.4844  LR: 0.00001656  \n","Epoch: [2][400/3386] Elapsed 1m 45s (remain 13m 5s) Loss: 0.3957(0.5266) Grad: 16392.4004  LR: 0.00001639  \n","Epoch: [2][500/3386] Elapsed 2m 10s (remain 12m 33s) Loss: 0.4899(0.5265) Grad: 20441.7051  LR: 0.00001621  \n","Epoch: [2][600/3386] Elapsed 2m 36s (remain 12m 4s) Loss: 0.5427(0.5290) Grad: 13150.2559  LR: 0.00001602  \n","Epoch: [2][700/3386] Elapsed 3m 1s (remain 11m 35s) Loss: 0.4502(0.5269) Grad: 31434.4590  LR: 0.00001583  \n","Epoch: [2][800/3386] Elapsed 3m 27s (remain 11m 8s) Loss: 0.5759(0.5274) Grad: 27516.8867  LR: 0.00001564  \n","Epoch: [2][900/3386] Elapsed 3m 52s (remain 10m 42s) Loss: 0.3759(0.5268) Grad: 37152.1875  LR: 0.00001545  \n","Epoch: [2][1000/3386] Elapsed 4m 18s (remain 10m 16s) Loss: 0.5512(0.5280) Grad: 14205.2236  LR: 0.00001526  \n","Epoch: [2][1100/3386] Elapsed 4m 43s (remain 9m 49s) Loss: 0.4371(0.5300) Grad: 19238.0234  LR: 0.00001506  \n","Epoch: [2][1200/3386] Elapsed 5m 9s (remain 9m 22s) Loss: 0.5437(0.5287) Grad: 35440.4258  LR: 0.00001486  \n","Epoch: [2][1300/3386] Elapsed 5m 34s (remain 8m 56s) Loss: 0.6880(0.5286) Grad: 34150.2227  LR: 0.00001465  \n","Epoch: [2][1400/3386] Elapsed 5m 59s (remain 8m 29s) Loss: 0.5246(0.5294) Grad: 26245.5918  LR: 0.00001445  \n","Epoch: [2][1500/3386] Elapsed 6m 25s (remain 8m 4s) Loss: 0.3843(0.5298) Grad: 24649.6191  LR: 0.00001424  \n","Epoch: [2][1600/3386] Elapsed 6m 50s (remain 7m 38s) Loss: 0.6079(0.5286) Grad: 25149.7168  LR: 0.00001403  \n","Epoch: [2][1700/3386] Elapsed 7m 16s (remain 7m 12s) Loss: 0.5459(0.5292) Grad: 49303.9961  LR: 0.00001381  \n","Epoch: [2][1800/3386] Elapsed 7m 41s (remain 6m 46s) Loss: 0.5715(0.5288) Grad: 7053.6548  LR: 0.00001360  \n","Epoch: [2][1900/3386] Elapsed 8m 7s (remain 6m 20s) Loss: 0.4765(0.5290) Grad: 14934.5713  LR: 0.00001338  \n","Epoch: [2][2000/3386] Elapsed 8m 32s (remain 5m 54s) Loss: 0.5230(0.5299) Grad: 29350.4219  LR: 0.00001316  \n","Epoch: [2][2100/3386] Elapsed 8m 58s (remain 5m 29s) Loss: 0.5967(0.5302) Grad: 10301.5293  LR: 0.00001294  \n","Epoch: [2][2200/3386] Elapsed 9m 23s (remain 5m 3s) Loss: 0.5364(0.5303) Grad: 28935.4414  LR: 0.00001272  \n","Epoch: [2][2300/3386] Elapsed 9m 48s (remain 4m 37s) Loss: 0.5484(0.5301) Grad: 20006.9180  LR: 0.00001249  \n","Epoch: [2][2400/3386] Elapsed 10m 14s (remain 4m 11s) Loss: 0.5899(0.5294) Grad: 25224.5312  LR: 0.00001227  \n","Epoch: [2][2500/3386] Elapsed 10m 39s (remain 3m 46s) Loss: 0.6027(0.5292) Grad: 137708.7812  LR: 0.00001204  \n","Epoch: [2][2600/3386] Elapsed 11m 4s (remain 3m 20s) Loss: 0.6489(0.5295) Grad: 114026.5469  LR: 0.00001181  \n","Epoch: [2][2700/3386] Elapsed 11m 30s (remain 2m 55s) Loss: 0.3330(0.5297) Grad: 176698.4219  LR: 0.00001159  \n","Epoch: [2][2800/3386] Elapsed 11m 55s (remain 2m 29s) Loss: 0.3758(0.5295) Grad: 64629.4141  LR: 0.00001136  \n","Epoch: [2][2900/3386] Elapsed 12m 21s (remain 2m 3s) Loss: 0.4195(0.5295) Grad: 5947.8643  LR: 0.00001113  \n","Epoch: [2][3000/3386] Elapsed 12m 46s (remain 1m 38s) Loss: 0.4510(0.5295) Grad: 13302.7725  LR: 0.00001090  \n","Epoch: [2][3100/3386] Elapsed 13m 11s (remain 1m 12s) Loss: 0.6405(0.5292) Grad: 10549.6963  LR: 0.00001066  \n","Epoch: [2][3200/3386] Elapsed 13m 37s (remain 0m 47s) Loss: 0.5352(0.5294) Grad: 31294.4082  LR: 0.00001043  \n","Epoch: [2][3300/3386] Elapsed 14m 2s (remain 0m 21s) Loss: 0.4871(0.5289) Grad: 31689.4336  LR: 0.00001020  \n","Epoch: [2][3385/3386] Elapsed 14m 24s (remain 0m 0s) Loss: 0.6354(0.5290) Grad: 8157.4888  LR: 0.00001000  \n","EVAL: [0/1173] Elapsed 0m 0s (remain 13m 44s) Loss: 0.8538(0.8538) \n","EVAL: [100/1173] Elapsed 0m 9s (remain 1m 43s) Loss: 0.5464(0.5196) \n","EVAL: [200/1173] Elapsed 0m 18s (remain 1m 30s) Loss: 0.5086(0.5378) \n","EVAL: [300/1173] Elapsed 0m 27s (remain 1m 20s) Loss: 0.5001(0.5455) \n","EVAL: [400/1173] Elapsed 0m 36s (remain 1m 11s) Loss: 0.4223(0.5556) \n","EVAL: [500/1173] Elapsed 0m 46s (remain 1m 1s) Loss: 0.6391(0.5560) \n","EVAL: [600/1173] Elapsed 0m 55s (remain 0m 52s) Loss: 0.6588(0.5573) \n","EVAL: [700/1173] Elapsed 1m 4s (remain 0m 43s) Loss: 0.5077(0.5555) \n","EVAL: [800/1173] Elapsed 1m 13s (remain 0m 34s) Loss: 0.3529(0.5584) \n","EVAL: [900/1173] Elapsed 1m 22s (remain 0m 24s) Loss: 0.5880(0.5581) \n","EVAL: [1000/1173] Elapsed 1m 31s (remain 0m 15s) Loss: 0.6474(0.5621) \n","EVAL: [1100/1173] Elapsed 1m 40s (remain 0m 6s) Loss: 0.3645(0.5599) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5290  avg_val_loss: 0.5605  time: 972s\n","Epoch 2 - Score: 0.8241\n","Epoch 2 - Save Best Score: 0.8241 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1172/1173] Elapsed 1m 47s (remain 0m 0s) Loss: 0.6764(0.5605) \n","Epoch: [3][0/3386] Elapsed 0m 0s (remain 49m 47s) Loss: 0.6549(0.6549) Grad: 20563.6816  LR: 0.00001000  \n","Epoch: [3][100/3386] Elapsed 0m 27s (remain 14m 54s) Loss: 0.5139(0.5160) Grad: 22079.3965  LR: 0.00000977  \n","Epoch: [3][200/3386] Elapsed 0m 54s (remain 14m 19s) Loss: 0.5555(0.5162) Grad: 12513.6709  LR: 0.00000954  \n","Epoch: [3][300/3386] Elapsed 1m 20s (remain 13m 43s) Loss: 0.5261(0.5130) Grad: 24430.4043  LR: 0.00000931  \n","Epoch: [3][400/3386] Elapsed 1m 46s (remain 13m 11s) Loss: 0.6376(0.5124) Grad: 19373.2461  LR: 0.00000907  \n","Epoch: [3][500/3386] Elapsed 2m 12s (remain 12m 40s) Loss: 0.6751(0.5153) Grad: 19383.2305  LR: 0.00000884  \n","Epoch: [3][600/3386] Elapsed 2m 37s (remain 12m 10s) Loss: 0.5449(0.5136) Grad: 23076.8047  LR: 0.00000861  \n","Epoch: [3][700/3386] Elapsed 3m 3s (remain 11m 42s) Loss: 0.5422(0.5139) Grad: 49945.4180  LR: 0.00000838  \n","Epoch: [3][800/3386] Elapsed 3m 29s (remain 11m 15s) Loss: 0.6601(0.5133) Grad: 22406.4629  LR: 0.00000816  \n","Epoch: [3][900/3386] Elapsed 3m 55s (remain 10m 48s) Loss: 0.3672(0.5123) Grad: 27162.3633  LR: 0.00000793  \n","Epoch: [3][1000/3386] Elapsed 4m 20s (remain 10m 21s) Loss: 0.4746(0.5117) Grad: 13916.5244  LR: 0.00000770  \n","Epoch: [3][1100/3386] Elapsed 4m 46s (remain 9m 54s) Loss: 0.2315(0.5103) Grad: 9845.5391  LR: 0.00000748  \n","Epoch: [3][1200/3386] Elapsed 5m 11s (remain 9m 27s) Loss: 0.4529(0.5108) Grad: 46720.9141  LR: 0.00000725  \n","Epoch: [3][1300/3386] Elapsed 5m 37s (remain 9m 0s) Loss: 0.5728(0.5099) Grad: 24796.2031  LR: 0.00000703  \n","Epoch: [3][1400/3386] Elapsed 6m 2s (remain 8m 33s) Loss: 0.5357(0.5101) Grad: 26608.1855  LR: 0.00000681  \n","Epoch: [3][1500/3386] Elapsed 6m 28s (remain 8m 7s) Loss: 0.5143(0.5097) Grad: 15128.5840  LR: 0.00000659  \n","Epoch: [3][1600/3386] Elapsed 6m 53s (remain 7m 41s) Loss: 0.5268(0.5084) Grad: 31557.5781  LR: 0.00000638  \n","Epoch: [3][1700/3386] Elapsed 7m 19s (remain 7m 15s) Loss: 0.5161(0.5089) Grad: 216945.2344  LR: 0.00000616  \n","Epoch: [3][1800/3386] Elapsed 7m 44s (remain 6m 49s) Loss: 0.5433(0.5091) Grad: 6736.8276  LR: 0.00000595  \n","Epoch: [3][1900/3386] Elapsed 8m 10s (remain 6m 22s) Loss: 0.4455(0.5093) Grad: 11717.5215  LR: 0.00000574  \n","Epoch: [3][2000/3386] Elapsed 8m 35s (remain 5m 56s) Loss: 0.4521(0.5099) Grad: 75714.8516  LR: 0.00000553  \n","Epoch: [3][2100/3386] Elapsed 9m 0s (remain 5m 30s) Loss: 0.3932(0.5096) Grad: 17810.7207  LR: 0.00000532  \n","Epoch: [3][2200/3386] Elapsed 9m 25s (remain 5m 4s) Loss: 0.3163(0.5095) Grad: 149087.8125  LR: 0.00000512  \n","Epoch: [3][2300/3386] Elapsed 9m 50s (remain 4m 38s) Loss: 0.4742(0.5097) Grad: 4126.8496  LR: 0.00000492  \n","Epoch: [3][2400/3386] Elapsed 10m 15s (remain 4m 12s) Loss: 0.6915(0.5098) Grad: 108916.6562  LR: 0.00000472  \n","Epoch: [3][2500/3386] Elapsed 10m 40s (remain 3m 46s) Loss: 0.4060(0.5096) Grad: 5676.8091  LR: 0.00000452  \n","Epoch: [3][2600/3386] Elapsed 11m 5s (remain 3m 20s) Loss: 0.4829(0.5086) Grad: 13557.1279  LR: 0.00000433  \n","Epoch: [3][2700/3386] Elapsed 11m 30s (remain 2m 55s) Loss: 0.4710(0.5085) Grad: 7185.2104  LR: 0.00000414  \n","Epoch: [3][2800/3386] Elapsed 11m 55s (remain 2m 29s) Loss: 0.4738(0.5086) Grad: 7667.1665  LR: 0.00000395  \n","Epoch: [3][2900/3386] Elapsed 12m 21s (remain 2m 3s) Loss: 0.4751(0.5083) Grad: 5659.8677  LR: 0.00000377  \n","Epoch: [3][3000/3386] Elapsed 12m 46s (remain 1m 38s) Loss: 0.5816(0.5087) Grad: 9225.3955  LR: 0.00000359  \n","Epoch: [3][3100/3386] Elapsed 13m 11s (remain 1m 12s) Loss: 0.5533(0.5082) Grad: 13787.0449  LR: 0.00000342  \n","Epoch: [3][3200/3386] Elapsed 13m 36s (remain 0m 47s) Loss: 0.6840(0.5080) Grad: 188784.3750  LR: 0.00000324  \n","Epoch: [3][3300/3386] Elapsed 14m 1s (remain 0m 21s) Loss: 0.5449(0.5079) Grad: 110119.8281  LR: 0.00000307  \n","Epoch: [3][3385/3386] Elapsed 14m 22s (remain 0m 0s) Loss: 0.3156(0.5077) Grad: 9856.0469  LR: 0.00000293  \n","EVAL: [0/1173] Elapsed 0m 0s (remain 13m 11s) Loss: 0.9464(0.9464) \n","EVAL: [100/1173] Elapsed 0m 9s (remain 1m 43s) Loss: 0.5726(0.5368) \n","EVAL: [200/1173] Elapsed 0m 18s (remain 1m 30s) Loss: 0.6092(0.5529) \n","EVAL: [300/1173] Elapsed 0m 27s (remain 1m 20s) Loss: 0.5281(0.5542) \n","EVAL: [400/1173] Elapsed 0m 36s (remain 1m 10s) Loss: 0.4338(0.5639) \n","EVAL: [500/1173] Elapsed 0m 45s (remain 1m 1s) Loss: 0.6773(0.5620) \n","EVAL: [600/1173] Elapsed 0m 54s (remain 0m 52s) Loss: 0.6897(0.5624) \n","EVAL: [700/1173] Elapsed 1m 3s (remain 0m 43s) Loss: 0.5354(0.5613) \n","EVAL: [800/1173] Elapsed 1m 12s (remain 0m 33s) Loss: 0.3619(0.5648) \n","EVAL: [900/1173] Elapsed 1m 22s (remain 0m 24s) Loss: 0.5807(0.5671) \n","EVAL: [1000/1173] Elapsed 1m 31s (remain 0m 15s) Loss: 0.6330(0.5691) \n","EVAL: [1100/1173] Elapsed 1m 40s (remain 0m 6s) Loss: 0.3605(0.5659) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5077  avg_val_loss: 0.5667  time: 969s\n","Epoch 3 - Score: 0.8269\n","Epoch 3 - Save Best Score: 0.8269 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1172/1173] Elapsed 1m 46s (remain 0m 0s) Loss: 0.6763(0.5667) \n","Epoch: [4][0/3386] Elapsed 0m 0s (remain 48m 27s) Loss: 0.3823(0.3823) Grad: 8326.8779  LR: 0.00000293  \n","Epoch: [4][100/3386] Elapsed 0m 26s (remain 14m 26s) Loss: 0.5600(0.4894) Grad: 2204.6509  LR: 0.00000277  \n","Epoch: [4][200/3386] Elapsed 0m 52s (remain 13m 59s) Loss: 0.4743(0.4845) Grad: 5966.4951  LR: 0.00000261  \n","Epoch: [4][300/3386] Elapsed 1m 19s (remain 13m 32s) Loss: 0.4954(0.4881) Grad: 57353.8867  LR: 0.00000246  \n","Epoch: [4][400/3386] Elapsed 1m 44s (remain 12m 58s) Loss: 0.4059(0.4893) Grad: 56136.8906  LR: 0.00000231  \n","Epoch: [4][500/3386] Elapsed 2m 9s (remain 12m 27s) Loss: 0.5449(0.4917) Grad: 8970.4424  LR: 0.00000216  \n","Epoch: [4][600/3386] Elapsed 2m 35s (remain 11m 58s) Loss: 0.6143(0.4939) Grad: 82176.8750  LR: 0.00000202  \n","Epoch: [4][700/3386] Elapsed 3m 0s (remain 11m 30s) Loss: 0.6917(0.4944) Grad: 130914.3516  LR: 0.00000188  \n","Epoch: [4][800/3386] Elapsed 3m 25s (remain 11m 3s) Loss: 0.5876(0.4924) Grad: 1828973.3750  LR: 0.00000175  \n","Epoch: [4][900/3386] Elapsed 3m 50s (remain 10m 37s) Loss: 0.5792(0.4947) Grad: 7821.8389  LR: 0.00000162  \n","Epoch: [4][1000/3386] Elapsed 4m 16s (remain 10m 10s) Loss: 0.5527(0.4971) Grad: 9661.4248  LR: 0.00000149  \n","Epoch: [4][1100/3386] Elapsed 4m 41s (remain 9m 44s) Loss: 0.3782(0.4975) Grad: 10284.7529  LR: 0.00000137  \n","Epoch: [4][1200/3386] Elapsed 5m 6s (remain 9m 17s) Loss: 0.5136(0.4972) Grad: 8456.0088  LR: 0.00000126  \n","Epoch: [4][1300/3386] Elapsed 5m 31s (remain 8m 51s) Loss: 0.5406(0.4977) Grad: 10068.3809  LR: 0.00000115  \n","Epoch: [4][1400/3386] Elapsed 5m 56s (remain 8m 25s) Loss: 0.6490(0.4971) Grad: 21714.4180  LR: 0.00000104  \n","Epoch: [4][1500/3386] Elapsed 6m 21s (remain 7m 59s) Loss: 0.5557(0.4965) Grad: 7617.6040  LR: 0.00000094  \n","Epoch: [4][1600/3386] Elapsed 6m 46s (remain 7m 33s) Loss: 0.4368(0.4968) Grad: 4951.2578  LR: 0.00000085  \n","Epoch: [4][1700/3386] Elapsed 7m 11s (remain 7m 7s) Loss: 0.5229(0.4961) Grad: 9568.4912  LR: 0.00000076  \n","Epoch: [4][1800/3386] Elapsed 7m 37s (remain 6m 42s) Loss: 0.6599(0.4959) Grad: 102122.1406  LR: 0.00000067  \n","Epoch: [4][1900/3386] Elapsed 8m 2s (remain 6m 16s) Loss: 0.6165(0.4971) Grad: 6333.0156  LR: 0.00000059  \n","Epoch: [4][2000/3386] Elapsed 8m 27s (remain 5m 51s) Loss: 0.5445(0.4965) Grad: 5047.6055  LR: 0.00000051  \n","Epoch: [4][2100/3386] Elapsed 8m 52s (remain 5m 25s) Loss: 0.4599(0.4953) Grad: 9340.2363  LR: 0.00000044  \n","Epoch: [4][2200/3386] Elapsed 9m 18s (remain 5m 0s) Loss: 0.6304(0.4945) Grad: 17784.0898  LR: 0.00000038  \n","Epoch: [4][2300/3386] Elapsed 9m 43s (remain 4m 35s) Loss: 0.6254(0.4949) Grad: 7786.8564  LR: 0.00000032  \n","Epoch: [4][2400/3386] Elapsed 10m 8s (remain 4m 9s) Loss: 0.4560(0.4954) Grad: 1695.5892  LR: 0.00000026  \n","Epoch: [4][2500/3386] Elapsed 10m 33s (remain 3m 44s) Loss: 0.5581(0.4950) Grad: 67898.5156  LR: 0.00000021  \n","Epoch: [4][2600/3386] Elapsed 10m 59s (remain 3m 18s) Loss: 0.3837(0.4954) Grad: 8218.5752  LR: 0.00000017  \n","Epoch: [4][2700/3386] Elapsed 11m 24s (remain 2m 53s) Loss: 0.2528(0.4959) Grad: 25658.5098  LR: 0.00000013  \n","Epoch: [4][2800/3386] Elapsed 11m 49s (remain 2m 28s) Loss: 0.6640(0.4967) Grad: 34177.8594  LR: 0.00000009  \n","Epoch: [4][2900/3386] Elapsed 12m 14s (remain 2m 2s) Loss: 0.4909(0.4963) Grad: 266633.4062  LR: 0.00000006  \n","Epoch: [4][3000/3386] Elapsed 12m 40s (remain 1m 37s) Loss: 0.4573(0.4965) Grad: 11666.1816  LR: 0.00000004  \n","Epoch: [4][3100/3386] Elapsed 13m 5s (remain 1m 12s) Loss: 0.4379(0.4965) Grad: 30301.6660  LR: 0.00000002  \n","Epoch: [4][3200/3386] Elapsed 13m 30s (remain 0m 46s) Loss: 0.5595(0.4969) Grad: 12758.0176  LR: 0.00000001  \n","Epoch: [4][3300/3386] Elapsed 13m 55s (remain 0m 21s) Loss: 0.4414(0.4969) Grad: 9173.5830  LR: 0.00000000  \n","Epoch: [4][3385/3386] Elapsed 14m 17s (remain 0m 0s) Loss: 0.3721(0.4971) Grad: 14570.4258  LR: 0.00000000  \n","EVAL: [0/1173] Elapsed 0m 0s (remain 13m 23s) Loss: 0.9544(0.9544) \n","EVAL: [100/1173] Elapsed 0m 9s (remain 1m 43s) Loss: 0.6170(0.5389) \n","EVAL: [200/1173] Elapsed 0m 18s (remain 1m 30s) Loss: 0.6160(0.5560) \n","EVAL: [300/1173] Elapsed 0m 27s (remain 1m 20s) Loss: 0.5307(0.5605) \n","EVAL: [400/1173] Elapsed 0m 36s (remain 1m 11s) Loss: 0.4205(0.5698) \n","EVAL: [500/1173] Elapsed 0m 45s (remain 1m 1s) Loss: 0.6646(0.5678) \n","EVAL: [600/1173] Elapsed 0m 54s (remain 0m 52s) Loss: 0.6978(0.5681) \n","EVAL: [700/1173] Elapsed 1m 4s (remain 0m 43s) Loss: 0.5249(0.5666) \n","EVAL: [800/1173] Elapsed 1m 13s (remain 0m 33s) Loss: 0.3661(0.5702) \n","EVAL: [900/1173] Elapsed 1m 22s (remain 0m 24s) Loss: 0.5813(0.5723) \n","EVAL: [1000/1173] Elapsed 1m 31s (remain 0m 15s) Loss: 0.6328(0.5743) \n","EVAL: [1100/1173] Elapsed 1m 40s (remain 0m 6s) Loss: 0.3679(0.5711) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4971  avg_val_loss: 0.5720  time: 965s\n","Epoch 4 - Score: 0.8264\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1172/1173] Elapsed 1m 46s (remain 0m 0s) Loss: 0.6770(0.5720) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","Score: 0.8269\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at ../input/deberta-v3-large/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3451] Elapsed 0m 0s (remain 55m 38s) Loss: 0.6949(0.6949) Grad: 84479.7344  LR: 0.00002000  \n","Epoch: [1][100/3451] Elapsed 0m 26s (remain 14m 28s) Loss: 0.6485(0.6629) Grad: 113836.0078  LR: 0.00002000  \n","Epoch: [1][200/3451] Elapsed 0m 51s (remain 13m 52s) Loss: 0.6955(0.6586) Grad: 201591.4375  LR: 0.00001999  \n","Epoch: [1][300/3451] Elapsed 1m 16s (remain 13m 21s) Loss: 0.6003(0.6489) Grad: 59379.1211  LR: 0.00001998  \n","Epoch: [1][400/3451] Elapsed 1m 41s (remain 12m 53s) Loss: 0.5648(0.6382) Grad: 39161.4453  LR: 0.00001996  \n","Epoch: [1][500/3451] Elapsed 2m 6s (remain 12m 25s) Loss: 0.5260(0.6313) Grad: 28963.8359  LR: 0.00001994  \n","Epoch: [1][600/3451] Elapsed 2m 31s (remain 11m 59s) Loss: 0.6705(0.6253) Grad: 36959.4336  LR: 0.00001991  \n","Epoch: [1][700/3451] Elapsed 2m 57s (remain 11m 35s) Loss: 0.5432(0.6199) Grad: 42294.8945  LR: 0.00001987  \n","Epoch: [1][800/3451] Elapsed 3m 22s (remain 11m 10s) Loss: 0.5775(0.6127) Grad: 77275.6406  LR: 0.00001983  \n","Epoch: [1][900/3451] Elapsed 3m 47s (remain 10m 44s) Loss: 0.7310(0.6068) Grad: 88315.8594  LR: 0.00001979  \n","Epoch: [1][1000/3451] Elapsed 4m 13s (remain 10m 19s) Loss: 0.6952(0.6024) Grad: 81616.8750  LR: 0.00001974  \n","Epoch: [1][1100/3451] Elapsed 4m 38s (remain 9m 54s) Loss: 0.5123(0.5989) Grad: 29653.4238  LR: 0.00001969  \n","Epoch: [1][1200/3451] Elapsed 5m 3s (remain 9m 29s) Loss: 0.6023(0.5959) Grad: 27182.8867  LR: 0.00001963  \n","Epoch: [1][1300/3451] Elapsed 5m 29s (remain 9m 4s) Loss: 0.4792(0.5931) Grad: 33594.2031  LR: 0.00001956  \n","Epoch: [1][1400/3451] Elapsed 5m 54s (remain 8m 39s) Loss: 0.7024(0.5901) Grad: 89078.2734  LR: 0.00001950  \n","Epoch: [1][1500/3451] Elapsed 6m 20s (remain 8m 13s) Loss: 0.4764(0.5885) Grad: 12996.5576  LR: 0.00001942  \n","Epoch: [1][1600/3451] Elapsed 6m 45s (remain 7m 48s) Loss: 0.7515(0.5874) Grad: 97297.1016  LR: 0.00001934  \n","Epoch: [1][1700/3451] Elapsed 7m 10s (remain 7m 23s) Loss: 0.4545(0.5858) Grad: 29981.4844  LR: 0.00001926  \n","Epoch: [1][1800/3451] Elapsed 7m 36s (remain 6m 58s) Loss: 0.3732(0.5843) Grad: 38489.5547  LR: 0.00001917  \n","Epoch: [1][1900/3451] Elapsed 8m 1s (remain 6m 32s) Loss: 0.5958(0.5827) Grad: 71575.0234  LR: 0.00001908  \n","Epoch: [1][2000/3451] Elapsed 8m 27s (remain 6m 7s) Loss: 0.6673(0.5813) Grad: 24490.2012  LR: 0.00001898  \n","Epoch: [1][2100/3451] Elapsed 8m 53s (remain 5m 42s) Loss: 0.5355(0.5797) Grad: 33921.8398  LR: 0.00001888  \n","Epoch: [1][2200/3451] Elapsed 9m 18s (remain 5m 17s) Loss: 0.6697(0.5796) Grad: 29908.2871  LR: 0.00001877  \n","Epoch: [1][2300/3451] Elapsed 9m 43s (remain 4m 51s) Loss: 0.4751(0.5784) Grad: 13711.9170  LR: 0.00001866  \n","Epoch: [1][2400/3451] Elapsed 10m 9s (remain 4m 26s) Loss: 0.6259(0.5771) Grad: 30726.9570  LR: 0.00001854  \n","Epoch: [1][2500/3451] Elapsed 10m 35s (remain 4m 1s) Loss: 0.4966(0.5753) Grad: 74944.7656  LR: 0.00001842  \n","Epoch: [1][2600/3451] Elapsed 11m 0s (remain 3m 35s) Loss: 0.6500(0.5744) Grad: 98790.5547  LR: 0.00001830  \n","Epoch: [1][2700/3451] Elapsed 11m 26s (remain 3m 10s) Loss: 0.5550(0.5737) Grad: 10419.8525  LR: 0.00001817  \n","Epoch: [1][2800/3451] Elapsed 11m 51s (remain 2m 45s) Loss: 0.5242(0.5725) Grad: 21834.7168  LR: 0.00001804  \n","Epoch: [1][2900/3451] Elapsed 12m 16s (remain 2m 19s) Loss: 0.4663(0.5722) Grad: 21385.4629  LR: 0.00001790  \n","Epoch: [1][3000/3451] Elapsed 12m 41s (remain 1m 54s) Loss: 0.5501(0.5716) Grad: 48894.9102  LR: 0.00001776  \n","Epoch: [1][3100/3451] Elapsed 13m 7s (remain 1m 28s) Loss: 0.4771(0.5713) Grad: 102700.7500  LR: 0.00001761  \n","Epoch: [1][3200/3451] Elapsed 13m 32s (remain 1m 3s) Loss: 0.5107(0.5703) Grad: 31466.8438  LR: 0.00001746  \n","Epoch: [1][3300/3451] Elapsed 13m 57s (remain 0m 38s) Loss: 0.5254(0.5705) Grad: 9255.9189  LR: 0.00001731  \n","Epoch: [1][3400/3451] Elapsed 14m 22s (remain 0m 12s) Loss: 0.5531(0.5699) Grad: 79033.7422  LR: 0.00001715  \n","Epoch: [1][3450/3451] Elapsed 14m 35s (remain 0m 0s) Loss: 0.6407(0.5697) Grad: 153359.8594  LR: 0.00001707  \n","EVAL: [0/1108] Elapsed 0m 0s (remain 13m 12s) Loss: 0.6325(0.6325) \n","EVAL: [100/1108] Elapsed 0m 9s (remain 1m 37s) Loss: 0.5920(0.5507) \n","EVAL: [200/1108] Elapsed 0m 18s (remain 1m 24s) Loss: 0.6752(0.5521) \n","EVAL: [300/1108] Elapsed 0m 27s (remain 1m 14s) Loss: 0.4568(0.5672) \n","EVAL: [400/1108] Elapsed 0m 36s (remain 1m 5s) Loss: 0.6508(0.5561) \n","EVAL: [500/1108] Elapsed 0m 45s (remain 0m 55s) Loss: 0.2004(0.5529) \n","EVAL: [600/1108] Elapsed 0m 54s (remain 0m 46s) Loss: 0.6128(0.5546) \n","EVAL: [700/1108] Elapsed 1m 3s (remain 0m 37s) Loss: 0.4670(0.5585) \n","EVAL: [800/1108] Elapsed 1m 13s (remain 0m 27s) Loss: 0.6630(0.5581) \n","EVAL: [900/1108] Elapsed 1m 22s (remain 0m 18s) Loss: 0.7553(0.5588) \n","EVAL: [1000/1108] Elapsed 1m 31s (remain 0m 9s) Loss: 0.8313(0.5580) \n","EVAL: [1100/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.3860(0.5584) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5697  avg_val_loss: 0.5584  time: 976s\n","Epoch 1 - Score: 0.7949\n","Epoch 1 - Save Best Score: 0.7949 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1107/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.6723(0.5584) \n","Epoch: [2][0/3451] Elapsed 0m 0s (remain 53m 49s) Loss: 0.5327(0.5327) Grad: 7888.2588  LR: 0.00001707  \n","Epoch: [2][100/3451] Elapsed 0m 27s (remain 15m 23s) Loss: 0.4224(0.5496) Grad: 12574.6650  LR: 0.00001691  \n","Epoch: [2][200/3451] Elapsed 0m 54s (remain 14m 47s) Loss: 0.5230(0.5363) Grad: 13826.1670  LR: 0.00001674  \n","Epoch: [2][300/3451] Elapsed 1m 20s (remain 14m 4s) Loss: 0.3247(0.5323) Grad: 4502.3491  LR: 0.00001657  \n","Epoch: [2][400/3451] Elapsed 1m 46s (remain 13m 28s) Loss: 0.4979(0.5334) Grad: 5336.2603  LR: 0.00001640  \n","Epoch: [2][500/3451] Elapsed 2m 12s (remain 12m 57s) Loss: 0.6789(0.5359) Grad: 40968.8398  LR: 0.00001622  \n","Epoch: [2][600/3451] Elapsed 2m 37s (remain 12m 28s) Loss: 0.4048(0.5339) Grad: 5929.8223  LR: 0.00001604  \n","Epoch: [2][700/3451] Elapsed 3m 3s (remain 11m 58s) Loss: 0.5808(0.5330) Grad: 19986.6719  LR: 0.00001586  \n","Epoch: [2][800/3451] Elapsed 3m 28s (remain 11m 28s) Loss: 0.6278(0.5341) Grad: 10057.8887  LR: 0.00001567  \n","Epoch: [2][900/3451] Elapsed 3m 53s (remain 11m 0s) Loss: 0.4150(0.5343) Grad: 3812.6763  LR: 0.00001548  \n","Epoch: [2][1000/3451] Elapsed 4m 18s (remain 10m 32s) Loss: 0.5013(0.5339) Grad: 6338.7983  LR: 0.00001529  \n","Epoch: [2][1100/3451] Elapsed 4m 44s (remain 10m 6s) Loss: 0.3615(0.5323) Grad: 12306.4014  LR: 0.00001510  \n","Epoch: [2][1200/3451] Elapsed 5m 9s (remain 9m 39s) Loss: 0.4447(0.5337) Grad: 6084.4077  LR: 0.00001490  \n","Epoch: [2][1300/3451] Elapsed 5m 35s (remain 9m 13s) Loss: 0.4531(0.5330) Grad: 69978.1094  LR: 0.00001470  \n","Epoch: [2][1400/3451] Elapsed 6m 0s (remain 8m 47s) Loss: 0.4990(0.5340) Grad: 6388.7578  LR: 0.00001450  \n","Epoch: [2][1500/3451] Elapsed 6m 25s (remain 8m 20s) Loss: 0.5577(0.5339) Grad: 37606.9883  LR: 0.00001430  \n","Epoch: [2][1600/3451] Elapsed 6m 50s (remain 7m 54s) Loss: 0.4653(0.5342) Grad: 23306.6836  LR: 0.00001409  \n","Epoch: [2][1700/3451] Elapsed 7m 15s (remain 7m 28s) Loss: 0.4208(0.5333) Grad: 28551.1934  LR: 0.00001388  \n","Epoch: [2][1800/3451] Elapsed 7m 40s (remain 7m 2s) Loss: 0.4361(0.5333) Grad: 43070.4023  LR: 0.00001367  \n","Epoch: [2][1900/3451] Elapsed 8m 5s (remain 6m 36s) Loss: 0.4212(0.5325) Grad: 32015.5625  LR: 0.00001346  \n","Epoch: [2][2000/3451] Elapsed 8m 30s (remain 6m 10s) Loss: 0.5065(0.5324) Grad: 18311.2266  LR: 0.00001324  \n","Epoch: [2][2100/3451] Elapsed 8m 55s (remain 5m 44s) Loss: 0.9238(0.5321) Grad: 621140.2500  LR: 0.00001303  \n","Epoch: [2][2200/3451] Elapsed 9m 20s (remain 5m 18s) Loss: 0.5444(0.5320) Grad: 12469.9502  LR: 0.00001281  \n","Epoch: [2][2300/3451] Elapsed 9m 46s (remain 4m 53s) Loss: 0.6524(0.5321) Grad: 21401.0293  LR: 0.00001259  \n","Epoch: [2][2400/3451] Elapsed 10m 11s (remain 4m 27s) Loss: 0.3738(0.5320) Grad: 21567.0918  LR: 0.00001237  \n","Epoch: [2][2500/3451] Elapsed 10m 36s (remain 4m 1s) Loss: 0.4027(0.5313) Grad: 35259.7305  LR: 0.00001215  \n","Epoch: [2][2600/3451] Elapsed 11m 1s (remain 3m 36s) Loss: 0.5379(0.5314) Grad: 7741.8071  LR: 0.00001192  \n","Epoch: [2][2700/3451] Elapsed 11m 26s (remain 3m 10s) Loss: 0.4778(0.5317) Grad: 34970.8086  LR: 0.00001170  \n","Epoch: [2][2800/3451] Elapsed 11m 52s (remain 2m 45s) Loss: 0.5694(0.5319) Grad: 6686.4985  LR: 0.00001148  \n","Epoch: [2][2900/3451] Elapsed 12m 17s (remain 2m 19s) Loss: 0.6281(0.5319) Grad: 16877.2773  LR: 0.00001125  \n","Epoch: [2][3000/3451] Elapsed 12m 42s (remain 1m 54s) Loss: 0.4799(0.5317) Grad: 9239.1562  LR: 0.00001102  \n","Epoch: [2][3100/3451] Elapsed 13m 7s (remain 1m 28s) Loss: 0.4465(0.5317) Grad: 54176.5352  LR: 0.00001080  \n","Epoch: [2][3200/3451] Elapsed 13m 32s (remain 1m 3s) Loss: 0.4322(0.5312) Grad: 10642.4600  LR: 0.00001057  \n","Epoch: [2][3300/3451] Elapsed 13m 57s (remain 0m 38s) Loss: 0.6166(0.5314) Grad: 146721.8281  LR: 0.00001034  \n","Epoch: [2][3400/3451] Elapsed 14m 22s (remain 0m 12s) Loss: 0.4098(0.5312) Grad: 17515.5547  LR: 0.00001012  \n","Epoch: [2][3450/3451] Elapsed 14m 34s (remain 0m 0s) Loss: 0.5176(0.5309) Grad: 18004.2266  LR: 0.00001000  \n","EVAL: [0/1108] Elapsed 0m 0s (remain 13m 34s) Loss: 0.8567(0.8567) \n","EVAL: [100/1108] Elapsed 0m 9s (remain 1m 37s) Loss: 0.5783(0.5582) \n","EVAL: [200/1108] Elapsed 0m 18s (remain 1m 24s) Loss: 0.5235(0.5595) \n","EVAL: [300/1108] Elapsed 0m 27s (remain 1m 14s) Loss: 0.4709(0.5743) \n","EVAL: [400/1108] Elapsed 0m 36s (remain 1m 5s) Loss: 0.6231(0.5625) \n","EVAL: [500/1108] Elapsed 0m 45s (remain 0m 55s) Loss: 0.1743(0.5588) \n","EVAL: [600/1108] Elapsed 0m 55s (remain 0m 46s) Loss: 0.5986(0.5586) \n","EVAL: [700/1108] Elapsed 1m 4s (remain 0m 37s) Loss: 0.4585(0.5609) \n","EVAL: [800/1108] Elapsed 1m 13s (remain 0m 28s) Loss: 0.6642(0.5592) \n","EVAL: [900/1108] Elapsed 1m 22s (remain 0m 18s) Loss: 0.6853(0.5589) \n","EVAL: [1000/1108] Elapsed 1m 31s (remain 0m 9s) Loss: 0.8926(0.5592) \n","EVAL: [1100/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.3745(0.5620) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5309  avg_val_loss: 0.5618  time: 976s\n","Epoch 2 - Score: 0.8156\n","Epoch 2 - Save Best Score: 0.8156 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1107/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.6679(0.5618) \n","Epoch: [3][0/3451] Elapsed 0m 0s (remain 53m 58s) Loss: 0.5402(0.5402) Grad: 37384.1641  LR: 0.00001000  \n","Epoch: [3][100/3451] Elapsed 0m 27s (remain 15m 14s) Loss: 0.5060(0.5205) Grad: 18559.7285  LR: 0.00000977  \n","Epoch: [3][200/3451] Elapsed 0m 54s (remain 14m 43s) Loss: 0.3155(0.5213) Grad: 3001.5710  LR: 0.00000955  \n","Epoch: [3][300/3451] Elapsed 1m 20s (remain 14m 3s) Loss: 0.4710(0.5146) Grad: 7944.2114  LR: 0.00000932  \n","Epoch: [3][400/3451] Elapsed 1m 45s (remain 13m 25s) Loss: 0.4587(0.5113) Grad: 9959.9297  LR: 0.00000909  \n","Epoch: [3][500/3451] Elapsed 2m 11s (remain 12m 54s) Loss: 0.4610(0.5109) Grad: 38707.5508  LR: 0.00000886  \n","Epoch: [3][600/3451] Elapsed 2m 36s (remain 12m 23s) Loss: 0.5643(0.5096) Grad: 54015.2422  LR: 0.00000864  \n","Epoch: [3][700/3451] Elapsed 3m 2s (remain 11m 54s) Loss: 0.5397(0.5082) Grad: 6741.9316  LR: 0.00000841  \n","Epoch: [3][800/3451] Elapsed 3m 27s (remain 11m 26s) Loss: 0.5676(0.5065) Grad: 11441.0635  LR: 0.00000819  \n","Epoch: [3][900/3451] Elapsed 3m 52s (remain 10m 59s) Loss: 0.5828(0.5048) Grad: 8173.2676  LR: 0.00000797  \n","Epoch: [3][1000/3451] Elapsed 4m 18s (remain 10m 32s) Loss: 0.4015(0.5035) Grad: 15279.6387  LR: 0.00000774  \n","Epoch: [3][1100/3451] Elapsed 4m 43s (remain 10m 5s) Loss: 0.3614(0.5027) Grad: 17077.9355  LR: 0.00000752  \n","Epoch: [3][1200/3451] Elapsed 5m 9s (remain 9m 39s) Loss: 0.5527(0.5042) Grad: 11663.3711  LR: 0.00000730  \n","Epoch: [3][1300/3451] Elapsed 5m 34s (remain 9m 12s) Loss: 0.3098(0.5046) Grad: 8621.8301  LR: 0.00000708  \n","Epoch: [3][1400/3451] Elapsed 5m 59s (remain 8m 46s) Loss: 0.5959(0.5040) Grad: 11214.9697  LR: 0.00000687  \n","Epoch: [3][1500/3451] Elapsed 6m 25s (remain 8m 20s) Loss: 0.5869(0.5036) Grad: 33150.6953  LR: 0.00000665  \n","Epoch: [3][1600/3451] Elapsed 6m 51s (remain 7m 55s) Loss: 0.4764(0.5045) Grad: 4704.3965  LR: 0.00000644  \n","Epoch: [3][1700/3451] Elapsed 7m 16s (remain 7m 29s) Loss: 0.5467(0.5049) Grad: 9819.2852  LR: 0.00000623  \n","Epoch: [3][1800/3451] Elapsed 7m 41s (remain 7m 2s) Loss: 0.4864(0.5047) Grad: 8917.2510  LR: 0.00000602  \n","Epoch: [3][1900/3451] Elapsed 8m 6s (remain 6m 36s) Loss: 0.5286(0.5048) Grad: 6447.6338  LR: 0.00000581  \n","Epoch: [3][2000/3451] Elapsed 8m 31s (remain 6m 10s) Loss: 0.6422(0.5056) Grad: 14511.3994  LR: 0.00000560  \n","Epoch: [3][2100/3451] Elapsed 8m 56s (remain 5m 44s) Loss: 0.4931(0.5054) Grad: 32724.9375  LR: 0.00000540  \n","Epoch: [3][2200/3451] Elapsed 9m 21s (remain 5m 19s) Loss: 0.3651(0.5054) Grad: 27357.3281  LR: 0.00000520  \n","Epoch: [3][2300/3451] Elapsed 9m 46s (remain 4m 53s) Loss: 0.3164(0.5052) Grad: 5494.9854  LR: 0.00000500  \n","Epoch: [3][2400/3451] Elapsed 10m 11s (remain 4m 27s) Loss: 0.4943(0.5051) Grad: 15198.4785  LR: 0.00000481  \n","Epoch: [3][2500/3451] Elapsed 10m 36s (remain 4m 1s) Loss: 0.5571(0.5051) Grad: 9359.1914  LR: 0.00000461  \n","Epoch: [3][2600/3451] Elapsed 11m 2s (remain 3m 36s) Loss: 0.4598(0.5049) Grad: 6717.6753  LR: 0.00000442  \n","Epoch: [3][2700/3451] Elapsed 11m 27s (remain 3m 10s) Loss: 0.4786(0.5047) Grad: 19370.2285  LR: 0.00000424  \n","Epoch: [3][2800/3451] Elapsed 11m 52s (remain 2m 45s) Loss: 0.4605(0.5050) Grad: 33417.4961  LR: 0.00000405  \n","Epoch: [3][2900/3451] Elapsed 12m 18s (remain 2m 19s) Loss: 0.3408(0.5052) Grad: 13903.3428  LR: 0.00000387  \n","Epoch: [3][3000/3451] Elapsed 12m 43s (remain 1m 54s) Loss: 0.4879(0.5055) Grad: 109863.3906  LR: 0.00000369  \n","Epoch: [3][3100/3451] Elapsed 13m 9s (remain 1m 29s) Loss: 0.6165(0.5054) Grad: 45252.1484  LR: 0.00000352  \n","Epoch: [3][3200/3451] Elapsed 13m 34s (remain 1m 3s) Loss: 0.4731(0.5052) Grad: 2236.6091  LR: 0.00000334  \n","Epoch: [3][3300/3451] Elapsed 14m 0s (remain 0m 38s) Loss: 0.5157(0.5058) Grad: 9028.7510  LR: 0.00000318  \n","Epoch: [3][3400/3451] Elapsed 14m 25s (remain 0m 12s) Loss: 0.5965(0.5062) Grad: 6006.6006  LR: 0.00000301  \n","Epoch: [3][3450/3451] Elapsed 14m 38s (remain 0m 0s) Loss: 0.4942(0.5066) Grad: 13801.6699  LR: 0.00000293  \n","EVAL: [0/1108] Elapsed 0m 0s (remain 13m 25s) Loss: 0.9337(0.9337) \n","EVAL: [100/1108] Elapsed 0m 9s (remain 1m 37s) Loss: 0.5692(0.5618) \n","EVAL: [200/1108] Elapsed 0m 18s (remain 1m 24s) Loss: 0.5329(0.5624) \n","EVAL: [300/1108] Elapsed 0m 27s (remain 1m 14s) Loss: 0.4353(0.5732) \n","EVAL: [400/1108] Elapsed 0m 36s (remain 1m 5s) Loss: 0.7101(0.5627) \n","EVAL: [500/1108] Elapsed 0m 45s (remain 0m 55s) Loss: 0.1748(0.5583) \n","EVAL: [600/1108] Elapsed 0m 54s (remain 0m 46s) Loss: 0.5896(0.5588) \n","EVAL: [700/1108] Elapsed 1m 3s (remain 0m 37s) Loss: 0.4381(0.5615) \n","EVAL: [800/1108] Elapsed 1m 12s (remain 0m 27s) Loss: 0.6657(0.5604) \n","EVAL: [900/1108] Elapsed 1m 22s (remain 0m 18s) Loss: 0.7027(0.5605) \n","EVAL: [1000/1108] Elapsed 1m 31s (remain 0m 9s) Loss: 1.0156(0.5615) \n","EVAL: [1100/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.3693(0.5638) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5066  avg_val_loss: 0.5639  time: 979s\n","Epoch 3 - Score: 0.8198\n","Epoch 3 - Save Best Score: 0.8198 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1107/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.6683(0.5639) \n","Epoch: [4][0/3451] Elapsed 0m 0s (remain 53m 11s) Loss: 0.5794(0.5794) Grad: 5844.8281  LR: 0.00000293  \n","Epoch: [4][100/3451] Elapsed 0m 27s (remain 15m 4s) Loss: 0.5440(0.5019) Grad: 4744.1426  LR: 0.00000277  \n","Epoch: [4][200/3451] Elapsed 0m 53s (remain 14m 25s) Loss: 0.4580(0.5014) Grad: 3420.3059  LR: 0.00000262  \n","Epoch: [4][300/3451] Elapsed 1m 19s (remain 13m 51s) Loss: 0.4901(0.4983) Grad: 36499.3633  LR: 0.00000246  \n","Epoch: [4][400/3451] Elapsed 1m 44s (remain 13m 15s) Loss: 0.5648(0.4983) Grad: 8480.3838  LR: 0.00000232  \n","Epoch: [4][500/3451] Elapsed 2m 9s (remain 12m 44s) Loss: 0.3848(0.4997) Grad: 10890.5225  LR: 0.00000217  \n","Epoch: [4][600/3451] Elapsed 2m 35s (remain 12m 16s) Loss: 0.4791(0.4988) Grad: 15926.1719  LR: 0.00000203  \n","Epoch: [4][700/3451] Elapsed 3m 0s (remain 11m 47s) Loss: 0.6764(0.4983) Grad: 19369.4316  LR: 0.00000190  \n","Epoch: [4][800/3451] Elapsed 3m 25s (remain 11m 19s) Loss: 0.5262(0.4999) Grad: 14526.1152  LR: 0.00000177  \n","Epoch: [4][900/3451] Elapsed 3m 50s (remain 10m 53s) Loss: 0.6242(0.5005) Grad: 10976.8213  LR: 0.00000164  \n","Epoch: [4][1000/3451] Elapsed 4m 15s (remain 10m 26s) Loss: 0.6531(0.5001) Grad: 8860.4619  LR: 0.00000152  \n","Epoch: [4][1100/3451] Elapsed 4m 41s (remain 9m 59s) Loss: 0.5676(0.4989) Grad: 10401.2090  LR: 0.00000140  \n","Epoch: [4][1200/3451] Elapsed 5m 6s (remain 9m 34s) Loss: 0.6460(0.4984) Grad: 74573.3750  LR: 0.00000128  \n","Epoch: [4][1300/3451] Elapsed 5m 31s (remain 9m 8s) Loss: 0.4361(0.4973) Grad: 3165.4248  LR: 0.00000118  \n","Epoch: [4][1400/3451] Elapsed 5m 57s (remain 8m 43s) Loss: 0.6473(0.4970) Grad: 5618.8271  LR: 0.00000107  \n","Epoch: [4][1500/3451] Elapsed 6m 22s (remain 8m 17s) Loss: 0.4935(0.4966) Grad: 11025.9639  LR: 0.00000097  \n","Epoch: [4][1600/3451] Elapsed 6m 48s (remain 7m 51s) Loss: 0.4036(0.4950) Grad: 9288.1982  LR: 0.00000087  \n","Epoch: [4][1700/3451] Elapsed 7m 13s (remain 7m 26s) Loss: 0.5610(0.4961) Grad: 9999.1504  LR: 0.00000078  \n","Epoch: [4][1800/3451] Elapsed 7m 39s (remain 7m 0s) Loss: 0.5533(0.4969) Grad: 22497.1465  LR: 0.00000070  \n","Epoch: [4][1900/3451] Elapsed 8m 4s (remain 6m 35s) Loss: 0.5935(0.4974) Grad: 36301.4375  LR: 0.00000062  \n","Epoch: [4][2000/3451] Elapsed 8m 29s (remain 6m 9s) Loss: 0.3855(0.4975) Grad: 10719.1230  LR: 0.00000054  \n","Epoch: [4][2100/3451] Elapsed 8m 55s (remain 5m 43s) Loss: 0.4568(0.4973) Grad: 7003.4287  LR: 0.00000047  \n","Epoch: [4][2200/3451] Elapsed 9m 20s (remain 5m 18s) Loss: 0.6834(0.4981) Grad: 58953.6875  LR: 0.00000040  \n","Epoch: [4][2300/3451] Elapsed 9m 45s (remain 4m 52s) Loss: 0.4324(0.4982) Grad: 164384.3281  LR: 0.00000034  \n","Epoch: [4][2400/3451] Elapsed 10m 11s (remain 4m 27s) Loss: 0.5146(0.4982) Grad: 15937.1514  LR: 0.00000029  \n","Epoch: [4][2500/3451] Elapsed 10m 36s (remain 4m 1s) Loss: 0.3263(0.4978) Grad: 14826.8096  LR: 0.00000023  \n","Epoch: [4][2600/3451] Elapsed 11m 1s (remain 3m 36s) Loss: 0.2459(0.4980) Grad: 10938.0498  LR: 0.00000019  \n","Epoch: [4][2700/3451] Elapsed 11m 27s (remain 3m 10s) Loss: 0.3865(0.4974) Grad: 28803.4258  LR: 0.00000015  \n","Epoch: [4][2800/3451] Elapsed 11m 52s (remain 2m 45s) Loss: 0.5090(0.4975) Grad: 16415.0547  LR: 0.00000011  \n","Epoch: [4][2900/3451] Elapsed 12m 17s (remain 2m 19s) Loss: 0.4905(0.4972) Grad: 6182.8672  LR: 0.00000008  \n","Epoch: [4][3000/3451] Elapsed 12m 43s (remain 1m 54s) Loss: 0.6029(0.4969) Grad: 60749.9180  LR: 0.00000005  \n","Epoch: [4][3100/3451] Elapsed 13m 8s (remain 1m 29s) Loss: 0.5309(0.4968) Grad: 5773.0752  LR: 0.00000003  \n","Epoch: [4][3200/3451] Elapsed 13m 34s (remain 1m 3s) Loss: 0.6502(0.4965) Grad: 259196.1250  LR: 0.00000002  \n","Epoch: [4][3300/3451] Elapsed 13m 59s (remain 0m 38s) Loss: 0.5478(0.4972) Grad: 9308.7480  LR: 0.00000001  \n","Epoch: [4][3400/3451] Elapsed 14m 25s (remain 0m 12s) Loss: 0.4003(0.4974) Grad: 153865.3594  LR: 0.00000000  \n","Epoch: [4][3450/3451] Elapsed 14m 37s (remain 0m 0s) Loss: 0.5132(0.4970) Grad: 18537.6367  LR: 0.00000000  \n","EVAL: [0/1108] Elapsed 0m 0s (remain 13m 44s) Loss: 1.0029(1.0029) \n","EVAL: [100/1108] Elapsed 0m 9s (remain 1m 37s) Loss: 0.5763(0.5725) \n","EVAL: [200/1108] Elapsed 0m 18s (remain 1m 25s) Loss: 0.5244(0.5750) \n","EVAL: [300/1108] Elapsed 0m 27s (remain 1m 14s) Loss: 0.4353(0.5863) \n","EVAL: [400/1108] Elapsed 0m 36s (remain 1m 5s) Loss: 0.7358(0.5765) \n","EVAL: [500/1108] Elapsed 0m 45s (remain 0m 55s) Loss: 0.1736(0.5723) \n","EVAL: [600/1108] Elapsed 0m 55s (remain 0m 46s) Loss: 0.5896(0.5728) \n","EVAL: [700/1108] Elapsed 1m 4s (remain 0m 37s) Loss: 0.4398(0.5757) \n","EVAL: [800/1108] Elapsed 1m 13s (remain 0m 28s) Loss: 0.6677(0.5748) \n","EVAL: [900/1108] Elapsed 1m 22s (remain 0m 18s) Loss: 0.7087(0.5752) \n","EVAL: [1000/1108] Elapsed 1m 31s (remain 0m 9s) Loss: 1.0176(0.5764) \n","EVAL: [1100/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.3700(0.5789) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4970  avg_val_loss: 0.5791  time: 979s\n","Epoch 4 - Score: 0.8159\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1107/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.6670(0.5791) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 1 result ==========\n","Score: 0.8198\n","========== fold: 2 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at ../input/deberta-v3-large/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3482] Elapsed 0m 0s (remain 54m 23s) Loss: 0.7071(0.7071) Grad: 62826.7227  LR: 0.00002000  \n","Epoch: [1][100/3482] Elapsed 0m 26s (remain 14m 38s) Loss: 0.5722(0.6675) Grad: 103178.0234  LR: 0.00002000  \n","Epoch: [1][200/3482] Elapsed 0m 51s (remain 14m 4s) Loss: 0.6714(0.6508) Grad: 70930.9297  LR: 0.00001999  \n","Epoch: [1][300/3482] Elapsed 1m 16s (remain 13m 33s) Loss: 0.5981(0.6386) Grad: 82965.3672  LR: 0.00001998  \n","Epoch: [1][400/3482] Elapsed 1m 42s (remain 13m 5s) Loss: 0.5873(0.6294) Grad: 114442.3984  LR: 0.00001996  \n","Epoch: [1][500/3482] Elapsed 2m 7s (remain 12m 39s) Loss: 0.5712(0.6230) Grad: 80167.3047  LR: 0.00001994  \n","Epoch: [1][600/3482] Elapsed 2m 33s (remain 12m 13s) Loss: 0.6168(0.6169) Grad: 40334.3516  LR: 0.00001991  \n","Epoch: [1][700/3482] Elapsed 2m 58s (remain 11m 47s) Loss: 0.5951(0.6133) Grad: 48683.7188  LR: 0.00001988  \n","Epoch: [1][800/3482] Elapsed 3m 23s (remain 11m 21s) Loss: 0.6747(0.6078) Grad: 572489.6875  LR: 0.00001984  \n","Epoch: [1][900/3482] Elapsed 3m 48s (remain 10m 55s) Loss: 0.4364(0.6034) Grad: 42466.4609  LR: 0.00001979  \n","Epoch: [1][1000/3482] Elapsed 4m 14s (remain 10m 29s) Loss: 0.4864(0.5994) Grad: 20303.9883  LR: 0.00001975  \n","Epoch: [1][1100/3482] Elapsed 4m 39s (remain 10m 4s) Loss: 0.5241(0.5969) Grad: 35775.3555  LR: 0.00001969  \n","Epoch: [1][1200/3482] Elapsed 5m 4s (remain 9m 38s) Loss: 0.5693(0.5952) Grad: 58789.2305  LR: 0.00001964  \n","Epoch: [1][1300/3482] Elapsed 5m 29s (remain 9m 13s) Loss: 0.6140(0.5924) Grad: 48432.6094  LR: 0.00001957  \n","Epoch: [1][1400/3482] Elapsed 5m 55s (remain 8m 48s) Loss: 0.4111(0.5909) Grad: 25745.0391  LR: 0.00001950  \n","Epoch: [1][1500/3482] Elapsed 6m 21s (remain 8m 23s) Loss: 0.4775(0.5910) Grad: 16995.0801  LR: 0.00001943  \n","Epoch: [1][1600/3482] Elapsed 6m 47s (remain 7m 58s) Loss: 0.4708(0.5891) Grad: 39825.4453  LR: 0.00001936  \n","Epoch: [1][1700/3482] Elapsed 7m 12s (remain 7m 33s) Loss: 0.6437(0.5875) Grad: 6891.3872  LR: 0.00001927  \n","Epoch: [1][1800/3482] Elapsed 7m 38s (remain 7m 7s) Loss: 0.5660(0.5867) Grad: 5756.3164  LR: 0.00001919  \n","Epoch: [1][1900/3482] Elapsed 8m 3s (remain 6m 42s) Loss: 0.6529(0.5864) Grad: 4679.7979  LR: 0.00001909  \n","Epoch: [1][2000/3482] Elapsed 8m 28s (remain 6m 16s) Loss: 0.4677(0.5849) Grad: 23646.4551  LR: 0.00001900  \n","Epoch: [1][2100/3482] Elapsed 8m 53s (remain 5m 51s) Loss: 0.6834(0.5832) Grad: 10007.0830  LR: 0.00001890  \n","Epoch: [1][2200/3482] Elapsed 9m 19s (remain 5m 25s) Loss: 0.6760(0.5829) Grad: 7481.3667  LR: 0.00001879  \n","Epoch: [1][2300/3482] Elapsed 9m 44s (remain 5m 0s) Loss: 0.6454(0.5866) Grad: 9664.7705  LR: 0.00001868  \n","Epoch: [1][2400/3482] Elapsed 10m 10s (remain 4m 34s) Loss: 0.6726(0.5896) Grad: 9576.7529  LR: 0.00001857  \n","Epoch: [1][2500/3482] Elapsed 10m 35s (remain 4m 9s) Loss: 0.6631(0.5924) Grad: 13482.1152  LR: 0.00001845  \n","Epoch: [1][2600/3482] Elapsed 11m 1s (remain 3m 43s) Loss: 0.5125(0.5946) Grad: 13153.8936  LR: 0.00001833  \n","Epoch: [1][2700/3482] Elapsed 11m 26s (remain 3m 18s) Loss: 0.6359(0.5937) Grad: 47933.2188  LR: 0.00001820  \n","Epoch: [1][2800/3482] Elapsed 11m 51s (remain 2m 53s) Loss: 0.6765(0.5924) Grad: 9953.9443  LR: 0.00001807  \n","Epoch: [1][2900/3482] Elapsed 12m 17s (remain 2m 27s) Loss: 0.6013(0.5920) Grad: 13731.8115  LR: 0.00001794  \n","Epoch: [1][3000/3482] Elapsed 12m 42s (remain 2m 2s) Loss: 0.5967(0.5907) Grad: 21417.5352  LR: 0.00001780  \n","Epoch: [1][3100/3482] Elapsed 13m 7s (remain 1m 36s) Loss: 0.4532(0.5898) Grad: 10868.6025  LR: 0.00001765  \n","Epoch: [1][3200/3482] Elapsed 13m 32s (remain 1m 11s) Loss: 0.7010(0.5890) Grad: 90807.2969  LR: 0.00001751  \n","Epoch: [1][3300/3482] Elapsed 13m 57s (remain 0m 45s) Loss: 0.5990(0.5885) Grad: 5649.7734  LR: 0.00001735  \n","Epoch: [1][3400/3482] Elapsed 14m 23s (remain 0m 20s) Loss: 0.5625(0.5876) Grad: 9162.6221  LR: 0.00001720  \n","Epoch: [1][3481/3482] Elapsed 14m 43s (remain 0m 0s) Loss: 0.5024(0.5864) Grad: 56748.6602  LR: 0.00001707  \n","EVAL: [0/1077] Elapsed 0m 0s (remain 12m 59s) Loss: 0.5581(0.5581) \n","EVAL: [100/1077] Elapsed 0m 9s (remain 1m 34s) Loss: 0.3952(0.5508) \n","EVAL: [200/1077] Elapsed 0m 18s (remain 1m 22s) Loss: 0.4610(0.5420) \n","EVAL: [300/1077] Elapsed 0m 27s (remain 1m 12s) Loss: 0.5543(0.5434) \n","EVAL: [400/1077] Elapsed 0m 37s (remain 1m 2s) Loss: 0.6327(0.5451) \n","EVAL: [500/1077] Elapsed 0m 46s (remain 0m 52s) Loss: 0.7163(0.5480) \n","EVAL: [600/1077] Elapsed 0m 55s (remain 0m 43s) Loss: 0.4691(0.5469) \n","EVAL: [700/1077] Elapsed 1m 4s (remain 0m 34s) Loss: 0.6434(0.5448) \n","EVAL: [800/1077] Elapsed 1m 13s (remain 0m 25s) Loss: 0.6287(0.5454) \n","EVAL: [900/1077] Elapsed 1m 22s (remain 0m 16s) Loss: 0.4936(0.5440) \n","EVAL: [1000/1077] Elapsed 1m 31s (remain 0m 6s) Loss: 0.2457(0.5439) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5864  avg_val_loss: 0.5441  time: 982s\n","Epoch 1 - Score: 0.8141\n","Epoch 1 - Save Best Score: 0.8141 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1076/1077] Elapsed 1m 38s (remain 0m 0s) Loss: 0.4310(0.5441) \n","Epoch: [2][0/3482] Elapsed 0m 0s (remain 50m 9s) Loss: 0.5119(0.5119) Grad: 33850.9844  LR: 0.00001707  \n","Epoch: [2][100/3482] Elapsed 0m 27s (remain 15m 18s) Loss: 0.3680(0.5318) Grad: 24128.1992  LR: 0.00001691  \n","Epoch: [2][200/3482] Elapsed 0m 53s (remain 14m 35s) Loss: 0.5675(0.5368) Grad: 15790.8711  LR: 0.00001674  \n","Epoch: [2][300/3482] Elapsed 1m 19s (remain 14m 4s) Loss: 0.5236(0.5384) Grad: 29887.0488  LR: 0.00001658  \n","Epoch: [2][400/3482] Elapsed 1m 45s (remain 13m 30s) Loss: 0.3684(0.5358) Grad: 15636.7031  LR: 0.00001640  \n","Epoch: [2][500/3482] Elapsed 2m 11s (remain 12m 59s) Loss: 0.4551(0.5355) Grad: 20913.6406  LR: 0.00001623  \n","Epoch: [2][600/3482] Elapsed 2m 36s (remain 12m 30s) Loss: 0.5651(0.5372) Grad: 14150.7412  LR: 0.00001605  \n","Epoch: [2][700/3482] Elapsed 3m 2s (remain 12m 2s) Loss: 0.5685(0.5374) Grad: 44825.4492  LR: 0.00001587  \n","Epoch: [2][800/3482] Elapsed 3m 27s (remain 11m 34s) Loss: 0.4143(0.5367) Grad: 10273.7168  LR: 0.00001569  \n","Epoch: [2][900/3482] Elapsed 3m 53s (remain 11m 7s) Loss: 0.5741(0.5374) Grad: 27101.1914  LR: 0.00001550  \n","Epoch: [2][1000/3482] Elapsed 4m 18s (remain 10m 40s) Loss: 0.3853(0.5364) Grad: 47338.3516  LR: 0.00001531  \n","Epoch: [2][1100/3482] Elapsed 4m 44s (remain 10m 14s) Loss: 0.4928(0.5379) Grad: 13771.0176  LR: 0.00001512  \n","Epoch: [2][1200/3482] Elapsed 5m 10s (remain 9m 48s) Loss: 0.5732(0.5394) Grad: 4920.7012  LR: 0.00001492  \n","Epoch: [2][1300/3482] Elapsed 5m 36s (remain 9m 23s) Loss: 0.5572(0.5400) Grad: 29509.3301  LR: 0.00001472  \n","Epoch: [2][1400/3482] Elapsed 6m 2s (remain 8m 57s) Loss: 0.5658(0.5399) Grad: 28772.6250  LR: 0.00001452  \n","Epoch: [2][1500/3482] Elapsed 6m 27s (remain 8m 31s) Loss: 0.4562(0.5409) Grad: 9557.9580  LR: 0.00001432  \n","Epoch: [2][1600/3482] Elapsed 6m 52s (remain 8m 5s) Loss: 0.5203(0.5405) Grad: 10213.3682  LR: 0.00001412  \n","Epoch: [2][1700/3482] Elapsed 7m 18s (remain 7m 39s) Loss: 0.5363(0.5401) Grad: 5972.7095  LR: 0.00001391  \n","Epoch: [2][1800/3482] Elapsed 7m 44s (remain 7m 13s) Loss: 0.6501(0.5402) Grad: 7582.2310  LR: 0.00001370  \n","Epoch: [2][1900/3482] Elapsed 8m 9s (remain 6m 47s) Loss: 0.6011(0.5400) Grad: 5238.5864  LR: 0.00001349  \n","Epoch: [2][2000/3482] Elapsed 8m 35s (remain 6m 21s) Loss: 0.4616(0.5396) Grad: 4826.1040  LR: 0.00001328  \n","Epoch: [2][2100/3482] Elapsed 9m 1s (remain 5m 55s) Loss: 0.6528(0.5407) Grad: 8970.7344  LR: 0.00001307  \n","Epoch: [2][2200/3482] Elapsed 9m 27s (remain 5m 30s) Loss: 0.4529(0.5407) Grad: 4624.5269  LR: 0.00001285  \n","Epoch: [2][2300/3482] Elapsed 9m 53s (remain 5m 4s) Loss: 0.6715(0.5409) Grad: 2768.3748  LR: 0.00001263  \n","Epoch: [2][2400/3482] Elapsed 10m 19s (remain 4m 38s) Loss: 0.4089(0.5413) Grad: 30670.3223  LR: 0.00001242  \n","Epoch: [2][2500/3482] Elapsed 10m 45s (remain 4m 13s) Loss: 0.4823(0.5414) Grad: 5348.2188  LR: 0.00001220  \n","Epoch: [2][2600/3482] Elapsed 11m 10s (remain 3m 47s) Loss: 0.4952(0.5413) Grad: 8458.2930  LR: 0.00001198  \n","Epoch: [2][2700/3482] Elapsed 11m 36s (remain 3m 21s) Loss: 0.2384(0.5410) Grad: 5885.0229  LR: 0.00001175  \n","Epoch: [2][2800/3482] Elapsed 12m 2s (remain 2m 55s) Loss: 0.4615(0.5404) Grad: 7995.7725  LR: 0.00001153  \n","Epoch: [2][2900/3482] Elapsed 12m 27s (remain 2m 29s) Loss: 0.5753(0.5407) Grad: 9085.4053  LR: 0.00001131  \n","Epoch: [2][3000/3482] Elapsed 12m 53s (remain 2m 3s) Loss: 0.5965(0.5409) Grad: 61240.7734  LR: 0.00001108  \n","Epoch: [2][3100/3482] Elapsed 13m 18s (remain 1m 38s) Loss: 0.5320(0.5410) Grad: 7468.9722  LR: 0.00001086  \n","Epoch: [2][3200/3482] Elapsed 13m 44s (remain 1m 12s) Loss: 0.5098(0.5405) Grad: 40050.4297  LR: 0.00001064  \n","Epoch: [2][3300/3482] Elapsed 14m 9s (remain 0m 46s) Loss: 0.5621(0.5410) Grad: 2880.3242  LR: 0.00001041  \n","Epoch: [2][3400/3482] Elapsed 14m 34s (remain 0m 20s) Loss: 0.4797(0.5410) Grad: 6673.8047  LR: 0.00001018  \n","Epoch: [2][3481/3482] Elapsed 14m 55s (remain 0m 0s) Loss: 0.4311(0.5414) Grad: 5472.7329  LR: 0.00001000  \n","EVAL: [0/1077] Elapsed 0m 0s (remain 11m 30s) Loss: 0.6520(0.6520) \n","EVAL: [100/1077] Elapsed 0m 9s (remain 1m 34s) Loss: 0.4912(0.5740) \n","EVAL: [200/1077] Elapsed 0m 18s (remain 1m 22s) Loss: 0.4764(0.5638) \n","EVAL: [300/1077] Elapsed 0m 27s (remain 1m 12s) Loss: 0.6698(0.5614) \n","EVAL: [400/1077] Elapsed 0m 37s (remain 1m 2s) Loss: 0.6788(0.5689) \n","EVAL: [500/1077] Elapsed 0m 46s (remain 0m 52s) Loss: 0.7669(0.5698) \n","EVAL: [600/1077] Elapsed 0m 55s (remain 0m 43s) Loss: 0.4530(0.5709) \n","EVAL: [700/1077] Elapsed 1m 4s (remain 0m 34s) Loss: 0.6613(0.5679) \n","EVAL: [800/1077] Elapsed 1m 13s (remain 0m 25s) Loss: 0.6357(0.5703) \n","EVAL: [900/1077] Elapsed 1m 22s (remain 0m 16s) Loss: 0.4930(0.5704) \n","EVAL: [1000/1077] Elapsed 1m 31s (remain 0m 6s) Loss: 0.2305(0.5702) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5414  avg_val_loss: 0.5715  time: 994s\n","Epoch 2 - Score: 0.7764\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1076/1077] Elapsed 1m 38s (remain 0m 0s) Loss: 0.3740(0.5715) \n","Epoch: [3][0/3482] Elapsed 0m 0s (remain 48m 34s) Loss: 0.7672(0.7672) Grad: 107530.7812  LR: 0.00001000  \n","Epoch: [3][100/3482] Elapsed 0m 26s (remain 14m 42s) Loss: 0.6201(0.5322) Grad: 2914.1418  LR: 0.00000977  \n","Epoch: [3][200/3482] Elapsed 0m 51s (remain 14m 4s) Loss: 0.5818(0.5289) Grad: 4664.9512  LR: 0.00000955  \n","Epoch: [3][300/3482] Elapsed 1m 17s (remain 13m 37s) Loss: 0.5345(0.5322) Grad: 3855.7310  LR: 0.00000932  \n","Epoch: [3][400/3482] Elapsed 1m 43s (remain 13m 13s) Loss: 0.5631(0.5285) Grad: 5631.7041  LR: 0.00000910  \n","Epoch: [3][500/3482] Elapsed 2m 8s (remain 12m 46s) Loss: 0.2443(0.5262) Grad: 2287.0291  LR: 0.00000887  \n","Epoch: [3][600/3482] Elapsed 2m 34s (remain 12m 21s) Loss: 0.6611(0.5250) Grad: 25970.8613  LR: 0.00000865  \n","Epoch: [3][700/3482] Elapsed 3m 0s (remain 11m 55s) Loss: 0.5681(0.5228) Grad: 1428.8335  LR: 0.00000843  \n","Epoch: [3][800/3482] Elapsed 3m 26s (remain 11m 30s) Loss: 0.4513(0.5206) Grad: 3235.8828  LR: 0.00000821  \n","Epoch: [3][900/3482] Elapsed 3m 51s (remain 11m 4s) Loss: 0.6724(0.5210) Grad: 3409.8643  LR: 0.00000798  \n","Epoch: [3][1000/3482] Elapsed 4m 17s (remain 10m 38s) Loss: 0.5774(0.5225) Grad: 2448.6519  LR: 0.00000776  \n","Epoch: [3][1100/3482] Elapsed 4m 42s (remain 10m 11s) Loss: 0.6082(0.5219) Grad: 28426.4727  LR: 0.00000754  \n","Epoch: [3][1200/3482] Elapsed 5m 8s (remain 9m 45s) Loss: 0.5351(0.5221) Grad: 29487.1621  LR: 0.00000733  \n","Epoch: [3][1300/3482] Elapsed 5m 34s (remain 9m 20s) Loss: 0.6171(0.5235) Grad: 2236.4785  LR: 0.00000711  \n","Epoch: [3][1400/3482] Elapsed 5m 59s (remain 8m 54s) Loss: 0.4909(0.5223) Grad: 3432.9441  LR: 0.00000689  \n","Epoch: [3][1500/3482] Elapsed 6m 25s (remain 8m 28s) Loss: 0.5325(0.5232) Grad: 2646.6592  LR: 0.00000668  \n","Epoch: [3][1600/3482] Elapsed 6m 50s (remain 8m 2s) Loss: 0.7755(0.5228) Grad: 13392.3799  LR: 0.00000647  \n","Epoch: [3][1700/3482] Elapsed 7m 16s (remain 7m 37s) Loss: 0.4540(0.5229) Grad: 922.3318  LR: 0.00000626  \n","Epoch: [3][1800/3482] Elapsed 7m 42s (remain 7m 11s) Loss: 0.4700(0.5226) Grad: 1348.2227  LR: 0.00000605  \n","Epoch: [3][1900/3482] Elapsed 8m 7s (remain 6m 45s) Loss: 0.4191(0.5233) Grad: 405.8866  LR: 0.00000584  \n","Epoch: [3][2000/3482] Elapsed 8m 33s (remain 6m 19s) Loss: 0.4726(0.5228) Grad: 2126.3633  LR: 0.00000564  \n","Epoch: [3][2100/3482] Elapsed 8m 58s (remain 5m 54s) Loss: 0.5160(0.5223) Grad: 10075.9277  LR: 0.00000544  \n","Epoch: [3][2200/3482] Elapsed 9m 24s (remain 5m 28s) Loss: 0.5001(0.5221) Grad: 6537.7256  LR: 0.00000524  \n","Epoch: [3][2300/3482] Elapsed 9m 50s (remain 5m 2s) Loss: 0.5456(0.5215) Grad: 1425.7448  LR: 0.00000504  \n","Epoch: [3][2400/3482] Elapsed 10m 15s (remain 4m 37s) Loss: 0.3021(0.5210) Grad: 721.2744  LR: 0.00000485  \n","Epoch: [3][2500/3482] Elapsed 10m 40s (remain 4m 11s) Loss: 0.5429(0.5208) Grad: 4993.5806  LR: 0.00000466  \n","Epoch: [3][2600/3482] Elapsed 11m 6s (remain 3m 45s) Loss: 0.6420(0.5206) Grad: 1103.8344  LR: 0.00000447  \n","Epoch: [3][2700/3482] Elapsed 11m 32s (remain 3m 20s) Loss: 0.5172(0.5205) Grad: 5841.2905  LR: 0.00000428  \n","Epoch: [3][2800/3482] Elapsed 11m 58s (remain 2m 54s) Loss: 0.5053(0.5204) Grad: 2371.8994  LR: 0.00000410  \n","Epoch: [3][2900/3482] Elapsed 12m 24s (remain 2m 29s) Loss: 0.5425(0.5200) Grad: 1914.8802  LR: 0.00000392  \n","Epoch: [3][3000/3482] Elapsed 12m 49s (remain 2m 3s) Loss: 0.4966(0.5202) Grad: 2003.9515  LR: 0.00000374  \n","Epoch: [3][3100/3482] Elapsed 13m 15s (remain 1m 37s) Loss: 0.5888(0.5199) Grad: 3121.8123  LR: 0.00000356  \n","Epoch: [3][3200/3482] Elapsed 13m 41s (remain 1m 12s) Loss: 0.4919(0.5196) Grad: 3901.6230  LR: 0.00000339  \n","Epoch: [3][3300/3482] Elapsed 14m 7s (remain 0m 46s) Loss: 0.5708(0.5194) Grad: 1772.0916  LR: 0.00000323  \n","Epoch: [3][3400/3482] Elapsed 14m 33s (remain 0m 20s) Loss: 0.4069(0.5189) Grad: 1518.3909  LR: 0.00000306  \n","Epoch: [3][3481/3482] Elapsed 14m 54s (remain 0m 0s) Loss: 0.5118(0.5192) Grad: 5167.9766  LR: 0.00000293  \n","EVAL: [0/1077] Elapsed 0m 0s (remain 11m 38s) Loss: 0.5641(0.5641) \n","EVAL: [100/1077] Elapsed 0m 9s (remain 1m 34s) Loss: 0.3725(0.5544) \n","EVAL: [200/1077] Elapsed 0m 18s (remain 1m 22s) Loss: 0.4746(0.5440) \n","EVAL: [300/1077] Elapsed 0m 27s (remain 1m 12s) Loss: 0.6639(0.5418) \n","EVAL: [400/1077] Elapsed 0m 37s (remain 1m 2s) Loss: 0.6653(0.5489) \n","EVAL: [500/1077] Elapsed 0m 46s (remain 0m 53s) Loss: 0.7196(0.5520) \n","EVAL: [600/1077] Elapsed 0m 55s (remain 0m 43s) Loss: 0.4572(0.5514) \n","EVAL: [700/1077] Elapsed 1m 4s (remain 0m 34s) Loss: 0.6600(0.5490) \n","EVAL: [800/1077] Elapsed 1m 13s (remain 0m 25s) Loss: 0.6081(0.5484) \n","EVAL: [900/1077] Elapsed 1m 22s (remain 0m 16s) Loss: 0.5081(0.5476) \n","EVAL: [1000/1077] Elapsed 1m 31s (remain 0m 6s) Loss: 0.2311(0.5490) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5192  avg_val_loss: 0.5498  time: 994s\n","Epoch 3 - Score: 0.8292\n","Epoch 3 - Save Best Score: 0.8292 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1076/1077] Elapsed 1m 38s (remain 0m 0s) Loss: 0.3432(0.5498) \n","Epoch: [4][0/3482] Elapsed 0m 0s (remain 50m 41s) Loss: 0.5437(0.5437) Grad: 2075.0483  LR: 0.00000293  \n","Epoch: [4][100/3482] Elapsed 0m 27s (remain 15m 12s) Loss: 0.5797(0.4864) Grad: 2925.5408  LR: 0.00000277  \n","Epoch: [4][200/3482] Elapsed 0m 54s (remain 14m 46s) Loss: 0.3861(0.4945) Grad: 678.4516  LR: 0.00000262  \n","Epoch: [4][300/3482] Elapsed 1m 21s (remain 14m 16s) Loss: 0.4060(0.5006) Grad: 1933.0299  LR: 0.00000247  \n","Epoch: [4][400/3482] Elapsed 1m 46s (remain 13m 42s) Loss: 0.4739(0.4955) Grad: 4062.9375  LR: 0.00000232  \n","Epoch: [4][500/3482] Elapsed 2m 12s (remain 13m 8s) Loss: 0.5407(0.4963) Grad: 2906.7341  LR: 0.00000218  \n","Epoch: [4][600/3482] Elapsed 2m 38s (remain 12m 38s) Loss: 0.5464(0.4972) Grad: 1491.4507  LR: 0.00000204  \n","Epoch: [4][700/3482] Elapsed 3m 3s (remain 12m 9s) Loss: 0.4564(0.4982) Grad: 81020.8203  LR: 0.00000191  \n","Epoch: [4][800/3482] Elapsed 3m 29s (remain 11m 41s) Loss: 0.1558(0.4982) Grad: 2401.7144  LR: 0.00000178  \n","Epoch: [4][900/3482] Elapsed 3m 55s (remain 11m 13s) Loss: 0.6104(0.4991) Grad: 6766.6260  LR: 0.00000165  \n","Epoch: [4][1000/3482] Elapsed 4m 20s (remain 10m 46s) Loss: 0.6157(0.4999) Grad: 3362.8311  LR: 0.00000153  \n","Epoch: [4][1100/3482] Elapsed 4m 46s (remain 10m 19s) Loss: 0.4683(0.4997) Grad: 1962.1151  LR: 0.00000141  \n","Epoch: [4][1200/3482] Elapsed 5m 12s (remain 9m 53s) Loss: 0.4746(0.4999) Grad: 1656.5406  LR: 0.00000130  \n","Epoch: [4][1300/3482] Elapsed 5m 38s (remain 9m 26s) Loss: 0.4788(0.4995) Grad: 2549.1572  LR: 0.00000119  \n","Epoch: [4][1400/3482] Elapsed 6m 3s (remain 9m 0s) Loss: 0.4522(0.4994) Grad: 2135.5000  LR: 0.00000108  \n","Epoch: [4][1500/3482] Elapsed 6m 29s (remain 8m 34s) Loss: 0.6195(0.4985) Grad: 2763.8135  LR: 0.00000098  \n","Epoch: [4][1600/3482] Elapsed 6m 55s (remain 8m 7s) Loss: 0.4990(0.4989) Grad: 4002.0635  LR: 0.00000089  \n","Epoch: [4][1700/3482] Elapsed 7m 20s (remain 7m 41s) Loss: 0.3743(0.4984) Grad: 210212.0625  LR: 0.00000080  \n","Epoch: [4][1800/3482] Elapsed 7m 46s (remain 7m 15s) Loss: 0.4749(0.4997) Grad: 2611.2454  LR: 0.00000071  \n","Epoch: [4][1900/3482] Elapsed 8m 12s (remain 6m 49s) Loss: 0.6032(0.4998) Grad: 29623.3184  LR: 0.00000063  \n","Epoch: [4][2000/3482] Elapsed 8m 37s (remain 6m 23s) Loss: 0.6712(0.4997) Grad: 4411.6890  LR: 0.00000055  \n","Epoch: [4][2100/3482] Elapsed 9m 2s (remain 5m 56s) Loss: 0.3882(0.5004) Grad: 3392.9177  LR: 0.00000048  \n","Epoch: [4][2200/3482] Elapsed 9m 28s (remain 5m 30s) Loss: 0.4424(0.5013) Grad: 3269.8247  LR: 0.00000042  \n","Epoch: [4][2300/3482] Elapsed 9m 54s (remain 5m 5s) Loss: 0.6037(0.5020) Grad: 8553.6250  LR: 0.00000035  \n","Epoch: [4][2400/3482] Elapsed 10m 19s (remain 4m 39s) Loss: 0.3075(0.5015) Grad: 2866.2036  LR: 0.00000030  \n","Epoch: [4][2500/3482] Elapsed 10m 45s (remain 4m 13s) Loss: 0.5037(0.5015) Grad: 5648.7681  LR: 0.00000024  \n","Epoch: [4][2600/3482] Elapsed 11m 11s (remain 3m 47s) Loss: 0.4550(0.5013) Grad: 550.3377  LR: 0.00000020  \n","Epoch: [4][2700/3482] Elapsed 11m 36s (remain 3m 21s) Loss: 0.4797(0.5016) Grad: 17218.1465  LR: 0.00000016  \n","Epoch: [4][2800/3482] Elapsed 12m 2s (remain 2m 55s) Loss: 0.4835(0.5019) Grad: 4184.5884  LR: 0.00000012  \n","Epoch: [4][2900/3482] Elapsed 12m 27s (remain 2m 29s) Loss: 0.5354(0.5019) Grad: 4817.0991  LR: 0.00000009  \n","Epoch: [4][3000/3482] Elapsed 12m 53s (remain 2m 3s) Loss: 0.6060(0.5019) Grad: 4532.9136  LR: 0.00000006  \n","Epoch: [4][3100/3482] Elapsed 13m 18s (remain 1m 38s) Loss: 0.4932(0.5017) Grad: 15941.9951  LR: 0.00000004  \n","Epoch: [4][3200/3482] Elapsed 13m 44s (remain 1m 12s) Loss: 0.6321(0.5014) Grad: 4471.2944  LR: 0.00000002  \n","Epoch: [4][3300/3482] Elapsed 14m 9s (remain 0m 46s) Loss: 0.4859(0.5013) Grad: 2155.4221  LR: 0.00000001  \n","Epoch: [4][3400/3482] Elapsed 14m 35s (remain 0m 20s) Loss: 0.6028(0.5015) Grad: 2900.6304  LR: 0.00000000  \n","Epoch: [4][3481/3482] Elapsed 14m 56s (remain 0m 0s) Loss: 0.5756(0.5016) Grad: 1128.2605  LR: 0.00000000  \n","EVAL: [0/1077] Elapsed 0m 0s (remain 11m 53s) Loss: 0.5586(0.5586) \n","EVAL: [100/1077] Elapsed 0m 9s (remain 1m 34s) Loss: 0.3756(0.5649) \n","EVAL: [200/1077] Elapsed 0m 18s (remain 1m 22s) Loss: 0.4668(0.5567) \n","EVAL: [300/1077] Elapsed 0m 27s (remain 1m 11s) Loss: 0.5576(0.5565) \n","EVAL: [400/1077] Elapsed 0m 36s (remain 1m 2s) Loss: 0.6558(0.5609) \n","EVAL: [500/1077] Elapsed 0m 46s (remain 0m 52s) Loss: 0.7196(0.5642) \n","EVAL: [600/1077] Elapsed 0m 55s (remain 0m 43s) Loss: 0.4523(0.5627) \n","EVAL: [700/1077] Elapsed 1m 4s (remain 0m 34s) Loss: 0.6564(0.5608) \n","EVAL: [800/1077] Elapsed 1m 13s (remain 0m 25s) Loss: 0.6051(0.5598) \n","EVAL: [900/1077] Elapsed 1m 22s (remain 0m 16s) Loss: 0.5046(0.5587) \n","EVAL: [1000/1077] Elapsed 1m 31s (remain 0m 6s) Loss: 0.2297(0.5600) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.5016  avg_val_loss: 0.5618  time: 995s\n","Epoch 4 - Score: 0.8308\n","Epoch 4 - Save Best Score: 0.8308 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1076/1077] Elapsed 1m 38s (remain 0m 0s) Loss: 0.3408(0.5618) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 2 result ==========\n","Score: 0.8308\n","========== fold: 3 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifier.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifer.weight', 'mask_predictions.classifer.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'deberta.embeddings.position_embeddings.weight', 'mask_predictions.dense.weight', 'mask_predictions.dense.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at ../input/deberta-v3-large/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3356] Elapsed 0m 0s (remain 53m 2s) Loss: 0.7251(0.7251) Grad: 171513.5938  LR: 0.00002000  \n","Epoch: [1][100/3356] Elapsed 0m 27s (remain 14m 48s) Loss: 0.6466(0.6595) Grad: 74536.5000  LR: 0.00002000  \n","Epoch: [1][200/3356] Elapsed 0m 54s (remain 14m 11s) Loss: 0.6205(0.6486) Grad: 51472.2656  LR: 0.00001999  \n","Epoch: [1][300/3356] Elapsed 1m 20s (remain 13m 37s) Loss: 0.4963(0.6385) Grad: 56297.9336  LR: 0.00001998  \n","Epoch: [1][400/3356] Elapsed 1m 46s (remain 13m 2s) Loss: 0.5343(0.6301) Grad: 32639.0332  LR: 0.00001996  \n","Epoch: [1][500/3356] Elapsed 2m 11s (remain 12m 30s) Loss: 0.6835(0.6219) Grad: 64261.6328  LR: 0.00001993  \n","Epoch: [1][600/3356] Elapsed 2m 37s (remain 12m 2s) Loss: 0.6082(0.6162) Grad: 58460.2031  LR: 0.00001990  \n","Epoch: [1][700/3356] Elapsed 3m 3s (remain 11m 33s) Loss: 0.5243(0.6103) Grad: 48725.3867  LR: 0.00001987  \n","Epoch: [1][800/3356] Elapsed 3m 28s (remain 11m 4s) Loss: 0.6925(0.6059) Grad: 38313.2734  LR: 0.00001982  \n","Epoch: [1][900/3356] Elapsed 3m 54s (remain 10m 37s) Loss: 0.5310(0.6006) Grad: 37318.9922  LR: 0.00001978  \n","Epoch: [1][1000/3356] Elapsed 4m 19s (remain 10m 10s) Loss: 0.5616(0.5980) Grad: 18515.3516  LR: 0.00001973  \n","Epoch: [1][1100/3356] Elapsed 4m 45s (remain 9m 44s) Loss: 0.5852(0.5943) Grad: 14521.6875  LR: 0.00001967  \n","Epoch: [1][1200/3356] Elapsed 5m 10s (remain 9m 17s) Loss: 0.5993(0.5923) Grad: 40189.3555  LR: 0.00001961  \n","Epoch: [1][1300/3356] Elapsed 5m 36s (remain 8m 51s) Loss: 0.5995(0.5904) Grad: 43107.8594  LR: 0.00001954  \n","Epoch: [1][1400/3356] Elapsed 6m 2s (remain 8m 25s) Loss: 0.6291(0.5894) Grad: 41683.7773  LR: 0.00001947  \n","Epoch: [1][1500/3356] Elapsed 6m 27s (remain 7m 59s) Loss: 0.2834(0.5878) Grad: 81961.3984  LR: 0.00001939  \n","Epoch: [1][1600/3356] Elapsed 6m 53s (remain 7m 33s) Loss: 0.5342(0.5848) Grad: 23599.7344  LR: 0.00001931  \n","Epoch: [1][1700/3356] Elapsed 7m 19s (remain 7m 7s) Loss: 0.7556(0.5834) Grad: 68188.5312  LR: 0.00001922  \n","Epoch: [1][1800/3356] Elapsed 7m 45s (remain 6m 41s) Loss: 0.6469(0.5813) Grad: 19774.9531  LR: 0.00001912  \n","Epoch: [1][1900/3356] Elapsed 8m 11s (remain 6m 15s) Loss: 0.4482(0.5793) Grad: 36195.1211  LR: 0.00001903  \n","Epoch: [1][2000/3356] Elapsed 8m 36s (remain 5m 49s) Loss: 0.5289(0.5785) Grad: 16925.4766  LR: 0.00001892  \n","Epoch: [1][2100/3356] Elapsed 9m 2s (remain 5m 23s) Loss: 0.5040(0.5777) Grad: 23786.2324  LR: 0.00001882  \n","Epoch: [1][2200/3356] Elapsed 9m 27s (remain 4m 58s) Loss: 0.5453(0.5768) Grad: 34755.8477  LR: 0.00001870  \n","Epoch: [1][2300/3356] Elapsed 9m 53s (remain 4m 32s) Loss: 0.4890(0.5752) Grad: 43198.1523  LR: 0.00001859  \n","Epoch: [1][2400/3356] Elapsed 10m 19s (remain 4m 6s) Loss: 0.6686(0.5743) Grad: 85471.5469  LR: 0.00001846  \n","Epoch: [1][2500/3356] Elapsed 10m 44s (remain 3m 40s) Loss: 0.5787(0.5736) Grad: 19542.9355  LR: 0.00001834  \n","Epoch: [1][2600/3356] Elapsed 11m 10s (remain 3m 14s) Loss: 0.5167(0.5733) Grad: 10078.9414  LR: 0.00001820  \n","Epoch: [1][2700/3356] Elapsed 11m 35s (remain 2m 48s) Loss: 0.6034(0.5726) Grad: 6938.7446  LR: 0.00001807  \n","Epoch: [1][2800/3356] Elapsed 12m 1s (remain 2m 23s) Loss: 0.5659(0.5724) Grad: 8318.2549  LR: 0.00001793  \n","Epoch: [1][2900/3356] Elapsed 12m 27s (remain 1m 57s) Loss: 0.7227(0.5715) Grad: 72048.2656  LR: 0.00001778  \n","Epoch: [1][3000/3356] Elapsed 12m 53s (remain 1m 31s) Loss: 0.4234(0.5712) Grad: 15684.4570  LR: 0.00001763  \n","Epoch: [1][3100/3356] Elapsed 13m 19s (remain 1m 5s) Loss: 0.5221(0.5704) Grad: 76794.1562  LR: 0.00001748  \n","Epoch: [1][3200/3356] Elapsed 13m 44s (remain 0m 39s) Loss: 0.5412(0.5704) Grad: 39344.8867  LR: 0.00001732  \n","Epoch: [1][3300/3356] Elapsed 14m 10s (remain 0m 14s) Loss: 0.5560(0.5694) Grad: 126015.3281  LR: 0.00001716  \n","Epoch: [1][3355/3356] Elapsed 14m 24s (remain 0m 0s) Loss: 0.4007(0.5690) Grad: 18015.9922  LR: 0.00001707  \n","EVAL: [0/1203] Elapsed 0m 0s (remain 15m 5s) Loss: 0.5552(0.5552) \n","EVAL: [100/1203] Elapsed 0m 9s (remain 1m 47s) Loss: 0.5871(0.5402) \n","EVAL: [200/1203] Elapsed 0m 18s (remain 1m 34s) Loss: 0.6211(0.5506) \n","EVAL: [300/1203] Elapsed 0m 28s (remain 1m 24s) Loss: 0.6340(0.5647) \n","EVAL: [400/1203] Elapsed 0m 37s (remain 1m 14s) Loss: 0.4721(0.5688) \n","EVAL: [500/1203] Elapsed 0m 46s (remain 1m 4s) Loss: 0.5435(0.5709) \n","EVAL: [600/1203] Elapsed 0m 55s (remain 0m 55s) Loss: 0.5621(0.5689) \n","EVAL: [700/1203] Elapsed 1m 4s (remain 0m 46s) Loss: 0.5124(0.5682) \n","EVAL: [800/1203] Elapsed 1m 13s (remain 0m 36s) Loss: 0.2383(0.5684) \n","EVAL: [900/1203] Elapsed 1m 22s (remain 0m 27s) Loss: 0.3910(0.5681) \n","EVAL: [1000/1203] Elapsed 1m 31s (remain 0m 18s) Loss: 0.4037(0.5675) \n","EVAL: [1100/1203] Elapsed 1m 40s (remain 0m 9s) Loss: 0.6756(0.5655) \n","EVAL: [1200/1203] Elapsed 1m 49s (remain 0m 0s) Loss: 0.5439(0.5654) \n","EVAL: [1202/1203] Elapsed 1m 49s (remain 0m 0s) Loss: 0.5095(0.5653) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5690  avg_val_loss: 0.5653  time: 975s\n","Epoch 1 - Score: 0.7733\n","Epoch 1 - Save Best Score: 0.7733 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [2][0/3356] Elapsed 0m 0s (remain 48m 30s) Loss: 0.5730(0.5730) Grad: 14198.5801  LR: 0.00001707  \n","Epoch: [2][100/3356] Elapsed 0m 27s (remain 14m 54s) Loss: 0.6044(0.5361) Grad: 35648.1602  LR: 0.00001690  \n","Epoch: [2][200/3356] Elapsed 0m 55s (remain 14m 28s) Loss: 0.5068(0.5377) Grad: 9146.3584  LR: 0.00001673  \n","Epoch: [2][300/3356] Elapsed 1m 22s (remain 13m 52s) Loss: 0.5209(0.5387) Grad: 7388.4468  LR: 0.00001656  \n","Epoch: [2][400/3356] Elapsed 1m 48s (remain 13m 16s) Loss: 0.5292(0.5374) Grad: 13261.2930  LR: 0.00001638  \n","Epoch: [2][500/3356] Elapsed 2m 14s (remain 12m 45s) Loss: 0.3451(0.5335) Grad: 6470.2271  LR: 0.00001620  \n","Epoch: [2][600/3356] Elapsed 2m 40s (remain 12m 15s) Loss: 0.5813(0.5365) Grad: 7166.7944  LR: 0.00001601  \n","Epoch: [2][700/3356] Elapsed 3m 6s (remain 11m 46s) Loss: 0.6318(0.5345) Grad: 13962.9512  LR: 0.00001582  \n","Epoch: [2][800/3356] Elapsed 3m 32s (remain 11m 18s) Loss: 0.5302(0.5360) Grad: 3689.9785  LR: 0.00001563  \n","Epoch: [2][900/3356] Elapsed 3m 58s (remain 10m 50s) Loss: 0.7042(0.5372) Grad: 32600.3164  LR: 0.00001544  \n","Epoch: [2][1000/3356] Elapsed 4m 24s (remain 10m 22s) Loss: 0.6589(0.5350) Grad: 4984.2671  LR: 0.00001524  \n","Epoch: [2][1100/3356] Elapsed 4m 50s (remain 9m 55s) Loss: 0.5024(0.5341) Grad: 12008.3223  LR: 0.00001504  \n","Epoch: [2][1200/3356] Elapsed 5m 17s (remain 9m 29s) Loss: 0.4515(0.5329) Grad: 14985.4824  LR: 0.00001483  \n","Epoch: [2][1300/3356] Elapsed 5m 43s (remain 9m 2s) Loss: 0.5046(0.5323) Grad: 41546.6875  LR: 0.00001463  \n","Epoch: [2][1400/3356] Elapsed 6m 9s (remain 8m 35s) Loss: 0.6723(0.5317) Grad: 52939.7031  LR: 0.00001442  \n","Epoch: [2][1500/3356] Elapsed 6m 35s (remain 8m 8s) Loss: 0.4376(0.5339) Grad: 32780.8203  LR: 0.00001421  \n","Epoch: [2][1600/3356] Elapsed 7m 0s (remain 7m 41s) Loss: 0.4828(0.5343) Grad: 27672.8711  LR: 0.00001399  \n","Epoch: [2][1700/3356] Elapsed 7m 26s (remain 7m 14s) Loss: 0.3845(0.5335) Grad: 9514.6387  LR: 0.00001378  \n","Epoch: [2][1800/3356] Elapsed 7m 52s (remain 6m 47s) Loss: 0.5989(0.5316) Grad: 45790.7930  LR: 0.00001356  \n","Epoch: [2][1900/3356] Elapsed 8m 18s (remain 6m 21s) Loss: 0.3946(0.5297) Grad: 10568.4482  LR: 0.00001334  \n","Epoch: [2][2000/3356] Elapsed 8m 44s (remain 5m 54s) Loss: 0.5814(0.5291) Grad: 13132.7051  LR: 0.00001312  \n","Epoch: [2][2100/3356] Elapsed 9m 9s (remain 5m 28s) Loss: 0.5609(0.5302) Grad: 34004.6797  LR: 0.00001290  \n","Epoch: [2][2200/3356] Elapsed 9m 36s (remain 5m 2s) Loss: 0.6042(0.5295) Grad: 15557.5264  LR: 0.00001267  \n","Epoch: [2][2300/3356] Elapsed 10m 2s (remain 4m 36s) Loss: 0.6807(0.5293) Grad: 13114.5107  LR: 0.00001244  \n","Epoch: [2][2400/3356] Elapsed 10m 28s (remain 4m 9s) Loss: 0.5799(0.5295) Grad: 4960.4673  LR: 0.00001222  \n","Epoch: [2][2500/3356] Elapsed 10m 54s (remain 3m 43s) Loss: 0.6001(0.5292) Grad: 29350.3242  LR: 0.00001199  \n","Epoch: [2][2600/3356] Elapsed 11m 19s (remain 3m 17s) Loss: 0.5549(0.5301) Grad: 11864.4297  LR: 0.00001176  \n","Epoch: [2][2700/3356] Elapsed 11m 45s (remain 2m 51s) Loss: 0.4930(0.5303) Grad: 22688.8379  LR: 0.00001153  \n","Epoch: [2][2800/3356] Elapsed 12m 11s (remain 2m 25s) Loss: 0.5841(0.5298) Grad: 32806.1250  LR: 0.00001130  \n","Epoch: [2][2900/3356] Elapsed 12m 37s (remain 1m 58s) Loss: 0.6050(0.5294) Grad: 75524.5547  LR: 0.00001106  \n","Epoch: [2][3000/3356] Elapsed 13m 3s (remain 1m 32s) Loss: 0.5708(0.5294) Grad: 25667.3633  LR: 0.00001083  \n","Epoch: [2][3100/3356] Elapsed 13m 28s (remain 1m 6s) Loss: 0.5651(0.5296) Grad: 30449.2207  LR: 0.00001060  \n","Epoch: [2][3200/3356] Elapsed 13m 54s (remain 0m 40s) Loss: 0.5505(0.5294) Grad: 28399.8516  LR: 0.00001036  \n","Epoch: [2][3300/3356] Elapsed 14m 20s (remain 0m 14s) Loss: 0.6351(0.5294) Grad: 18653.5801  LR: 0.00001013  \n","Epoch: [2][3355/3356] Elapsed 14m 34s (remain 0m 0s) Loss: 0.5704(0.5293) Grad: 19217.4062  LR: 0.00001000  \n","EVAL: [0/1203] Elapsed 0m 0s (remain 13m 43s) Loss: 0.5346(0.5346) \n","EVAL: [100/1203] Elapsed 0m 9s (remain 1m 46s) Loss: 0.5280(0.5508) \n","EVAL: [200/1203] Elapsed 0m 18s (remain 1m 33s) Loss: 0.7598(0.5643) \n","EVAL: [300/1203] Elapsed 0m 27s (remain 1m 23s) Loss: 0.6182(0.5759) \n","EVAL: [400/1203] Elapsed 0m 36s (remain 1m 13s) Loss: 0.4554(0.5785) \n","EVAL: [500/1203] Elapsed 0m 45s (remain 1m 4s) Loss: 0.5332(0.5800) \n","EVAL: [600/1203] Elapsed 0m 55s (remain 0m 55s) Loss: 0.5402(0.5783) \n","EVAL: [700/1203] Elapsed 1m 4s (remain 0m 45s) Loss: 0.4754(0.5785) \n","EVAL: [800/1203] Elapsed 1m 13s (remain 0m 36s) Loss: 0.1796(0.5816) \n","EVAL: [900/1203] Elapsed 1m 22s (remain 0m 27s) Loss: 0.3794(0.5823) \n","EVAL: [1000/1203] Elapsed 1m 31s (remain 0m 18s) Loss: 0.4648(0.5802) \n","EVAL: [1100/1203] Elapsed 1m 40s (remain 0m 9s) Loss: 0.6620(0.5764) \n","EVAL: [1200/1203] Elapsed 1m 49s (remain 0m 0s) Loss: 0.5512(0.5747) \n","EVAL: [1202/1203] Elapsed 1m 49s (remain 0m 0s) Loss: 0.4311(0.5745) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5293  avg_val_loss: 0.5745  time: 985s\n","Epoch 2 - Score: 0.7972\n","Epoch 2 - Save Best Score: 0.7972 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [3][0/3356] Elapsed 0m 0s (remain 53m 19s) Loss: 0.6066(0.6066) Grad: 10023.5254  LR: 0.00001000  \n","Epoch: [3][100/3356] Elapsed 0m 27s (remain 14m 48s) Loss: 0.4860(0.4967) Grad: 10248.4229  LR: 0.00000976  \n","Epoch: [3][200/3356] Elapsed 0m 54s (remain 14m 14s) Loss: 0.5303(0.4987) Grad: 5624.6206  LR: 0.00000953  \n","Epoch: [3][300/3356] Elapsed 1m 20s (remain 13m 39s) Loss: 0.4674(0.5127) Grad: 12298.7861  LR: 0.00000930  \n","Epoch: [3][400/3356] Elapsed 1m 46s (remain 13m 3s) Loss: 0.2536(0.5134) Grad: 9088.9863  LR: 0.00000906  \n","Epoch: [3][500/3356] Elapsed 2m 11s (remain 12m 31s) Loss: 0.5455(0.5119) Grad: 5723.8672  LR: 0.00000883  \n","Epoch: [3][600/3356] Elapsed 2m 37s (remain 12m 3s) Loss: 0.3932(0.5108) Grad: 4316.3999  LR: 0.00000860  \n","Epoch: [3][700/3356] Elapsed 3m 3s (remain 11m 35s) Loss: 0.5171(0.5122) Grad: 5410.2715  LR: 0.00000837  \n","Epoch: [3][800/3356] Elapsed 3m 29s (remain 11m 9s) Loss: 0.4775(0.5126) Grad: 5590.0171  LR: 0.00000814  \n","Epoch: [3][900/3356] Elapsed 3m 55s (remain 10m 41s) Loss: 0.8590(0.5115) Grad: 94001.7500  LR: 0.00000791  \n","Epoch: [3][1000/3356] Elapsed 4m 21s (remain 10m 14s) Loss: 0.5346(0.5122) Grad: 14644.3447  LR: 0.00000768  \n","Epoch: [3][1100/3356] Elapsed 4m 46s (remain 9m 47s) Loss: 0.6866(0.5108) Grad: 111046.4844  LR: 0.00000745  \n","Epoch: [3][1200/3356] Elapsed 5m 13s (remain 9m 22s) Loss: 0.4073(0.5107) Grad: 33559.1758  LR: 0.00000723  \n","Epoch: [3][1300/3356] Elapsed 5m 39s (remain 8m 55s) Loss: 0.6376(0.5119) Grad: 14245.4502  LR: 0.00000700  \n","Epoch: [3][1400/3356] Elapsed 6m 4s (remain 8m 29s) Loss: 0.5187(0.5114) Grad: 10837.5879  LR: 0.00000678  \n","Epoch: [3][1500/3356] Elapsed 6m 30s (remain 8m 2s) Loss: 0.6514(0.5103) Grad: 5935.2285  LR: 0.00000656  \n","Epoch: [3][1600/3356] Elapsed 6m 56s (remain 7m 36s) Loss: 0.5087(0.5102) Grad: 13026.2510  LR: 0.00000634  \n","Epoch: [3][1700/3356] Elapsed 7m 22s (remain 7m 10s) Loss: 0.6149(0.5102) Grad: 64370.8828  LR: 0.00000612  \n","Epoch: [3][1800/3356] Elapsed 7m 48s (remain 6m 44s) Loss: 0.4740(0.5103) Grad: 1980.6050  LR: 0.00000591  \n","Epoch: [3][1900/3356] Elapsed 8m 14s (remain 6m 18s) Loss: 0.5000(0.5107) Grad: 7084.4746  LR: 0.00000570  \n","Epoch: [3][2000/3356] Elapsed 8m 39s (remain 5m 52s) Loss: 0.6379(0.5102) Grad: 57432.2539  LR: 0.00000549  \n","Epoch: [3][2100/3356] Elapsed 9m 5s (remain 5m 25s) Loss: 0.7785(0.5112) Grad: 24387.0273  LR: 0.00000528  \n","Epoch: [3][2200/3356] Elapsed 9m 31s (remain 4m 59s) Loss: 0.5498(0.5113) Grad: 3599.8799  LR: 0.00000508  \n","Epoch: [3][2300/3356] Elapsed 9m 57s (remain 4m 33s) Loss: 0.4842(0.5112) Grad: 24459.7754  LR: 0.00000487  \n","Epoch: [3][2400/3356] Elapsed 10m 22s (remain 4m 7s) Loss: 0.5947(0.5103) Grad: 2444.8225  LR: 0.00000467  \n","Epoch: [3][2500/3356] Elapsed 10m 48s (remain 3m 41s) Loss: 0.2882(0.5104) Grad: 4998.5508  LR: 0.00000448  \n","Epoch: [3][2600/3356] Elapsed 11m 13s (remain 3m 15s) Loss: 0.5461(0.5103) Grad: 7596.7935  LR: 0.00000428  \n","Epoch: [3][2700/3356] Elapsed 11m 39s (remain 2m 49s) Loss: 0.5992(0.5103) Grad: 43638.6016  LR: 0.00000409  \n","Epoch: [3][2800/3356] Elapsed 12m 5s (remain 2m 23s) Loss: 0.4375(0.5100) Grad: 32125.1855  LR: 0.00000391  \n","Epoch: [3][2900/3356] Elapsed 12m 31s (remain 1m 57s) Loss: 0.5125(0.5098) Grad: 12625.5361  LR: 0.00000372  \n","Epoch: [3][3000/3356] Elapsed 12m 57s (remain 1m 31s) Loss: 0.4671(0.5103) Grad: 4478.5879  LR: 0.00000354  \n","Epoch: [3][3100/3356] Elapsed 13m 23s (remain 1m 6s) Loss: 0.4651(0.5104) Grad: 25500.6348  LR: 0.00000336  \n","Epoch: [3][3200/3356] Elapsed 13m 49s (remain 0m 40s) Loss: 0.5002(0.5102) Grad: 8106.2769  LR: 0.00000319  \n","Epoch: [3][3300/3356] Elapsed 14m 14s (remain 0m 14s) Loss: 0.5417(0.5102) Grad: 4478.0327  LR: 0.00000302  \n","Epoch: [3][3355/3356] Elapsed 14m 29s (remain 0m 0s) Loss: 0.4887(0.5100) Grad: 8341.0166  LR: 0.00000293  \n","EVAL: [0/1203] Elapsed 0m 0s (remain 14m 17s) Loss: 0.5310(0.5310) \n","EVAL: [100/1203] Elapsed 0m 9s (remain 1m 46s) Loss: 0.5282(0.5469) \n","EVAL: [200/1203] Elapsed 0m 18s (remain 1m 33s) Loss: 0.8184(0.5721) \n","EVAL: [300/1203] Elapsed 0m 27s (remain 1m 23s) Loss: 0.6143(0.5824) \n","EVAL: [400/1203] Elapsed 0m 37s (remain 1m 14s) Loss: 0.4864(0.5843) \n","EVAL: [500/1203] Elapsed 0m 46s (remain 1m 4s) Loss: 0.5321(0.5827) \n","EVAL: [600/1203] Elapsed 0m 55s (remain 0m 55s) Loss: 0.5442(0.5800) \n","EVAL: [700/1203] Elapsed 1m 4s (remain 0m 45s) Loss: 0.4830(0.5778) \n","EVAL: [800/1203] Elapsed 1m 13s (remain 0m 36s) Loss: 0.1961(0.5809) \n","EVAL: [900/1203] Elapsed 1m 22s (remain 0m 27s) Loss: 0.3843(0.5804) \n","EVAL: [1000/1203] Elapsed 1m 31s (remain 0m 18s) Loss: 0.4812(0.5796) \n","EVAL: [1100/1203] Elapsed 1m 40s (remain 0m 9s) Loss: 0.6671(0.5763) \n","EVAL: [1200/1203] Elapsed 1m 49s (remain 0m 0s) Loss: 0.5444(0.5742) \n","EVAL: [1202/1203] Elapsed 1m 49s (remain 0m 0s) Loss: 0.4330(0.5740) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5100  avg_val_loss: 0.5740  time: 979s\n","Epoch 3 - Score: 0.8002\n","Epoch 3 - Save Best Score: 0.8002 Model\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [4][0/3356] Elapsed 0m 0s (remain 51m 12s) Loss: 0.6036(0.6036) Grad: 4270.8921  LR: 0.00000293  \n","Epoch: [4][100/3356] Elapsed 0m 27s (remain 14m 53s) Loss: 0.4582(0.4865) Grad: 3906.2839  LR: 0.00000277  \n","Epoch: [4][200/3356] Elapsed 0m 54s (remain 14m 18s) Loss: 0.3063(0.4923) Grad: 8066.2764  LR: 0.00000261  \n","Epoch: [4][300/3356] Elapsed 1m 21s (remain 13m 43s) Loss: 0.4389(0.4907) Grad: 868.1865  LR: 0.00000245  \n","Epoch: [4][400/3356] Elapsed 1m 46s (remain 13m 5s) Loss: 0.6981(0.4936) Grad: 191786.7656  LR: 0.00000230  \n","Epoch: [4][500/3356] Elapsed 2m 12s (remain 12m 32s) Loss: 0.4192(0.4903) Grad: 4240.1494  LR: 0.00000215  \n","Epoch: [4][600/3356] Elapsed 2m 37s (remain 12m 2s) Loss: 0.4557(0.4917) Grad: 4032.6394  LR: 0.00000201  \n","Epoch: [4][700/3356] Elapsed 3m 3s (remain 11m 33s) Loss: 0.6070(0.4942) Grad: 1082.1162  LR: 0.00000187  \n","Epoch: [4][800/3356] Elapsed 3m 28s (remain 11m 5s) Loss: 0.5756(0.4947) Grad: 7675.8296  LR: 0.00000174  \n","Epoch: [4][900/3356] Elapsed 3m 54s (remain 10m 37s) Loss: 0.5709(0.4965) Grad: 3464.3655  LR: 0.00000161  \n","Epoch: [4][1000/3356] Elapsed 4m 19s (remain 10m 11s) Loss: 0.4175(0.4963) Grad: 6418.6646  LR: 0.00000148  \n","Epoch: [4][1100/3356] Elapsed 4m 45s (remain 9m 44s) Loss: 0.4603(0.4949) Grad: 4112.6875  LR: 0.00000136  \n","Epoch: [4][1200/3356] Elapsed 5m 10s (remain 9m 17s) Loss: 0.4672(0.4956) Grad: 3728.9927  LR: 0.00000125  \n","Epoch: [4][1300/3356] Elapsed 5m 36s (remain 8m 51s) Loss: 0.3406(0.4959) Grad: 4561.4229  LR: 0.00000114  \n","Epoch: [4][1400/3356] Elapsed 6m 1s (remain 8m 24s) Loss: 0.4914(0.4961) Grad: 3087.9912  LR: 0.00000103  \n","Epoch: [4][1500/3356] Elapsed 6m 27s (remain 7m 58s) Loss: 0.5440(0.4971) Grad: 2050.6890  LR: 0.00000093  \n","Epoch: [4][1600/3356] Elapsed 6m 53s (remain 7m 33s) Loss: 0.3191(0.4959) Grad: 9274.9883  LR: 0.00000083  \n","Epoch: [4][1700/3356] Elapsed 7m 18s (remain 7m 7s) Loss: 0.5745(0.4963) Grad: 4205.0698  LR: 0.00000074  \n","Epoch: [4][1800/3356] Elapsed 7m 44s (remain 6m 41s) Loss: 0.5417(0.4968) Grad: 54800.8398  LR: 0.00000066  \n","Epoch: [4][1900/3356] Elapsed 8m 10s (remain 6m 15s) Loss: 0.4599(0.4960) Grad: 4671.7363  LR: 0.00000057  \n","Epoch: [4][2000/3356] Elapsed 8m 35s (remain 5m 49s) Loss: 0.4402(0.4965) Grad: 7537.2905  LR: 0.00000050  \n","Epoch: [4][2100/3356] Elapsed 9m 1s (remain 5m 23s) Loss: 0.5058(0.4971) Grad: 3308.2654  LR: 0.00000043  \n","Epoch: [4][2200/3356] Elapsed 9m 27s (remain 4m 57s) Loss: 0.5635(0.4973) Grad: 49767.2422  LR: 0.00000036  \n","Epoch: [4][2300/3356] Elapsed 9m 52s (remain 4m 31s) Loss: 0.4558(0.4971) Grad: 2123.5132  LR: 0.00000030  \n","Epoch: [4][2400/3356] Elapsed 10m 18s (remain 4m 6s) Loss: 0.5535(0.4977) Grad: 8492.9990  LR: 0.00000025  \n","Epoch: [4][2500/3356] Elapsed 10m 44s (remain 3m 40s) Loss: 0.6028(0.4977) Grad: 3779.4678  LR: 0.00000020  \n","Epoch: [4][2600/3356] Elapsed 11m 10s (remain 3m 14s) Loss: 0.5377(0.4981) Grad: 3709.1125  LR: 0.00000016  \n","Epoch: [4][2700/3356] Elapsed 11m 35s (remain 2m 48s) Loss: 0.6133(0.4977) Grad: 5071.0117  LR: 0.00000012  \n","Epoch: [4][2800/3356] Elapsed 12m 1s (remain 2m 22s) Loss: 0.5873(0.4978) Grad: 20722.9453  LR: 0.00000008  \n","Epoch: [4][2900/3356] Elapsed 12m 27s (remain 1m 57s) Loss: 0.4575(0.4981) Grad: 3461.1665  LR: 0.00000006  \n","Epoch: [4][3000/3356] Elapsed 12m 52s (remain 1m 31s) Loss: 0.4454(0.4980) Grad: 23799.2461  LR: 0.00000003  \n","Epoch: [4][3100/3356] Elapsed 13m 18s (remain 1m 5s) Loss: 0.4929(0.4979) Grad: 14206.8252  LR: 0.00000002  \n","Epoch: [4][3200/3356] Elapsed 13m 43s (remain 0m 39s) Loss: 0.4446(0.4978) Grad: 3666.3748  LR: 0.00000001  \n","Epoch: [4][3300/3356] Elapsed 14m 9s (remain 0m 14s) Loss: 0.4906(0.4979) Grad: 7622.5474  LR: 0.00000000  \n","Epoch: [4][3355/3356] Elapsed 14m 23s (remain 0m 0s) Loss: 0.5675(0.4981) Grad: 31405.9414  LR: 0.00000000  \n","EVAL: [0/1203] Elapsed 0m 0s (remain 14m 18s) Loss: 0.5297(0.5297) \n","EVAL: [100/1203] Elapsed 0m 9s (remain 1m 46s) Loss: 0.5286(0.5569) \n","EVAL: [200/1203] Elapsed 0m 18s (remain 1m 33s) Loss: 0.8549(0.5826) \n","EVAL: [300/1203] Elapsed 0m 27s (remain 1m 23s) Loss: 0.6148(0.5936) \n","EVAL: [400/1203] Elapsed 0m 36s (remain 1m 13s) Loss: 0.4791(0.5940) \n","EVAL: [500/1203] Elapsed 0m 46s (remain 1m 4s) Loss: 0.5324(0.5928) \n","EVAL: [600/1203] Elapsed 0m 55s (remain 0m 55s) Loss: 0.5461(0.5899) \n","EVAL: [700/1203] Elapsed 1m 4s (remain 0m 45s) Loss: 0.4824(0.5874) \n","EVAL: [800/1203] Elapsed 1m 13s (remain 0m 36s) Loss: 0.1933(0.5921) \n","EVAL: [900/1203] Elapsed 1m 22s (remain 0m 27s) Loss: 0.3825(0.5913) \n","EVAL: [1000/1203] Elapsed 1m 31s (remain 0m 18s) Loss: 0.5245(0.5897) \n","EVAL: [1100/1203] Elapsed 1m 40s (remain 0m 9s) Loss: 0.6783(0.5858) \n","EVAL: [1200/1203] Elapsed 1m 49s (remain 0m 0s) Loss: 0.5567(0.5836) \n","EVAL: [1202/1203] Elapsed 1m 49s (remain 0m 0s) Loss: 0.4297(0.5833) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4981  avg_val_loss: 0.5833  time: 974s\n","Epoch 4 - Score: 0.7975\n","========== fold: 3 result ==========\n","Score: 0.8002\n","========== CV ==========\n","Score: 0.8192\n"]},{"data":{"text/html":["Waiting for W\u0026B process to finish... \u003cstrong style=\"color:green\"\u003e(success).\u003c/strong\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"52ae2d94f77542d7b77dddbfc88d1201","version_major":2,"version_minor":0},"text/plain":["VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\u003cstyle\u003e\n","    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n","    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n","    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n","    \u003c/style\u003e\n","\u003cdiv class=\"wandb-row\"\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun history:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▄▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e█▇▆█▄█▅▅▄▃▂▆▃▆▅▅▆▆▅▆█▅▅▅▄▅█▄▅▁▆▂▅▆▄▅▃▄▅▅\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▆▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e▁▆██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▂▃█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e▇▆▇▄▇▇▄▄▄▅▆▆▇▅▇▆▁▄▂▂▅▃▃▅▆▄▆▅▄▃▁▃▄▆▄▄▅█▅▂\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e▁▇█▇\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁█▂▆\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e▅▅▃▃▄▅▄▅▄▄▄▄▄▃▄▄▅▅▁▃▁▄▃▃▅▃▃▃▂█▄▄▂▂▃▃▃▄▃▄\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▆▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e▆▁██\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e█▄▂▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e▁▅▄█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e▁▃▆█\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e▇█▇▄▄█▇▄▅▇█▆▆▇▅▃▇█▄▅▇▅▁▇▇▆▄▁▇▇▇▅▇▇▇█▄▆▄▆\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e███████▇▇▇▇▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▂▂▂▂▂▁▁▁▁▁▁▁\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e▁▇█▇\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003cdiv class=\"wandb-col\"\u003e\u003ch3\u003eRun summary:\u003c/h3\u003e\u003cbr/\u003e\u003ctable class=\"wandb\"\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49708\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.572\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] loss\u003c/td\u003e\u003ctd\u003e0.37213\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold0] score\u003c/td\u003e\u003ctd\u003e0.82642\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49703\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.57913\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] loss\u003c/td\u003e\u003ctd\u003e0.51323\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold1] score\u003c/td\u003e\u003ctd\u003e0.81595\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.50163\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.56179\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] loss\u003c/td\u003e\u003ctd\u003e0.57562\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold2] score\u003c/td\u003e\u003ctd\u003e0.83083\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_train_loss\u003c/td\u003e\u003ctd\u003e0.49811\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] avg_val_loss\u003c/td\u003e\u003ctd\u003e0.58332\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] epoch\u003c/td\u003e\u003ctd\u003e4\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] loss\u003c/td\u003e\u003ctd\u003e0.56753\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] lr\u003c/td\u003e\u003ctd\u003e0.0\u003c/td\u003e\u003c/tr\u003e\u003ctr\u003e\u003ctd\u003e[fold3] score\u003c/td\u003e\u003ctd\u003e0.7975\u003c/td\u003e\u003c/tr\u003e\u003c/table\u003e\u003cbr/\u003e\u003c/div\u003e\u003c/div\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Synced \u003cstrong style=\"color:#cdcd00\"\u003eexp004\u003c/strong\u003e: \u003ca href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching/runs/26oy5db1\" target=\"_blank\"\u003ehttps://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching/runs/26oy5db1\u003c/a\u003e\u003cbr/\u003eSynced 5 W\u0026B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Find logs at: \u003ccode\u003e../input/nb005t-deberta-v3-large/wandb/run-20220614_065707-26oy5db1/logs\u003c/code\u003e"],"text/plain":["\u003cIPython.core.display.HTML object\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:\u003c.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()\n","\n","\n","\n","\n","    # Push to LINE\n","    import requests\n","\n","    def send_line_notification(message):\n","        import json\n","        f = open(\"../../line.json\", \"r\")\n","        json_data = json.load(f)\n","        line_token = json_data[\"kagglePush\"]\n","        endpoint = 'https://notify-api.line.me/api/notify'\n","        message = \"\\n{}\".format(message)\n","        payload = {'message': message}\n","        headers = {'Authorization': 'Bearer {}'.format(line_token)}\n","        requests.post(endpoint, data=payload, headers=headers)\n","\n","    if CFG.wandb:\n","        send_line_notification(f\"Training of {CFG.wandbproject+'/'+CFG.wandbgroup+'/'+CFG.wandbname} has been done. See {run.url}\")\n","    else:\n","        send_line_notification(f\"Training of {CFG.wandbproject+'/'+CFG.wandbgroup+'/'+CFG.wandbname} has been done.\")"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"nb005t-deberta-v3-large.ipynb","toc_visible":true,"version":""},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"11d3e97f89c54e6f9dbe8a535d0ce5ee":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"120b181517d644c5b909664bf0fb2dd2":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"13b3631b5d034d25ab161233b8741ab5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cd6bd30ec8948408a6f4c92bae06d50","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_72af327064d746648de3f2bb2254bdfd","value":36473}},"1f9f3c80200d4da7b53a880c7c692531":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25f81c3f554d4d57a1d4375bf863920a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c3aa9831e13241acafede3dd484aa2b3","placeholder":"​","style":"IPY_MODEL_724308e0d3954f50844b0a1b159597c1","value":" 36473/36473 [00:03\u0026lt;00:00, 11838.98it/s]"}},"3c35a253bddf40649585cd9f524fc247":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e48e0724f1a43cbbbb33b03dcd92632":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"471003dfb2524fdcb956a9d1429520de":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"484fd3df25aa443994c36118e1c349dc":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e61d943a9ff5492590f28fb9fa6d5bea","IPY_MODEL_f6f4695fd75d475f996dfe1f18c77349","IPY_MODEL_25f81c3f554d4d57a1d4375bf863920a"],"layout":"IPY_MODEL_471003dfb2524fdcb956a9d1429520de"}},"4cee18793e904c1296032a725b643984":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b6a32dca7fee4e34902c47304bde4d5e","placeholder":"​","style":"IPY_MODEL_52bbb2460b6d4e5f9471ea8ba90e9604","value":" 136/136 [00:00\u0026lt;00:00, 2251.42it/s]"}},"52bbb2460b6d4e5f9471ea8ba90e9604":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cd6bd30ec8948408a6f4c92bae06d50":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6270a96df168445eb16caee74945b3c2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6aece71288b44130a24eb3cabc4a64dd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f2d7ded15faa4336a8b0580ccc412b10","IPY_MODEL_b289aa98e84442d0b4b27dd30b392758","IPY_MODEL_4cee18793e904c1296032a725b643984"],"layout":"IPY_MODEL_d5b8c38b95834a39a65a1fb6a5781933"}},"724308e0d3954f50844b0a1b159597c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72af327064d746648de3f2bb2254bdfd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7def557405244be3b9fa4a7178fa2ebd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8d55bf5d6cd44fecb7224f533374fa48":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a20fe48e9a564703b4f3209247b09880":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8088f8894a24e1480ff28f0fe60e2d9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b289aa98e84442d0b4b27dd30b392758":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f9f3c80200d4da7b53a880c7c692531","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3e48e0724f1a43cbbbb33b03dcd92632","value":136}},"b6a32dca7fee4e34902c47304bde4d5e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bb369a573f3543729fc90b07e66d1109":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bdc9f1c1a6c0451c8c2be96132b90bf1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_db324cba939349f2ab897cf659a316b6","IPY_MODEL_13b3631b5d034d25ab161233b8741ab5","IPY_MODEL_fd9e372fc2e74fa08c0daeec78a812e3"],"layout":"IPY_MODEL_3c35a253bddf40649585cd9f524fc247"}},"c3aa9831e13241acafede3dd484aa2b3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d5b8c38b95834a39a65a1fb6a5781933":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db324cba939349f2ab897cf659a316b6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7def557405244be3b9fa4a7178fa2ebd","placeholder":"​","style":"IPY_MODEL_bb369a573f3543729fc90b07e66d1109","value":"100%"}},"e34cf73152e04dbb93cc438f5feb89da":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e61d943a9ff5492590f28fb9fa6d5bea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_120b181517d644c5b909664bf0fb2dd2","placeholder":"​","style":"IPY_MODEL_6270a96df168445eb16caee74945b3c2","value":"100%"}},"f2d7ded15faa4336a8b0580ccc412b10":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d55bf5d6cd44fecb7224f533374fa48","placeholder":"​","style":"IPY_MODEL_11d3e97f89c54e6f9dbe8a535d0ce5ee","value":"100%"}},"f6f4695fd75d475f996dfe1f18c77349":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcdddaafb96c4942951398d4a738f7b5","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e34cf73152e04dbb93cc438f5feb89da","value":36473}},"fcdddaafb96c4942951398d4a738f7b5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd9e372fc2e74fa08c0daeec78a812e3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8088f8894a24e1480ff28f0fe60e2d9","placeholder":"​","style":"IPY_MODEL_a20fe48e9a564703b4f3209247b09880","value":" 36473/36473 [00:03\u0026lt;00:00, 12416.53it/s]"}}}}},"nbformat":4,"nbformat_minor":0}