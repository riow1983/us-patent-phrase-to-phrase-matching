{"cells":[{"cell_type":"markdown","metadata":{"id":"e460cbb5"},"source":["# About this notebook\n","- tokenizer(anchor[SEP]target | CPC)\n","- Deberta-v3-large starter code\n","- pip wheels is [here](https://www.kaggle.com/code/yasufuminakama/pppm-pip-wheels)\n","- Inference notebook is [here](https://www.kaggle.com/code/yasufuminakama/pppm-deberta-v3-large-baseline-inference)\n","\n","If this notebook is helpful, feel free to upvote :)"]},{"cell_type":"markdown","metadata":{"id":"xONchFYMvMMf"},"source":["# Directory settings"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2248,"status":"ok","timestamp":1655272430692,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"fa3b873b","outputId":"e7a9d409-97c8-4323-aa72-60151b9a7797"},"outputs":[{"name":"stdout","output_type":"stream","text":["3.7.13 (default, Apr 24 2022, 01:04:09) \n","[GCC 7.5.0]\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","/content/drive/MyDrive/colab_notebooks/kaggle/us-patent-phrase-to-phrase-matching/notebooks\n"]}],"source":["# ====================================================\n","# Directory settings\n","# ====================================================\n","comp_name = 'us-patent-phrase-to-phrase-matching'\n","nb_name = 'nb005t-deberta-v3-large'\n","\n","import sys\n","print(sys.version)\n","if \"google.colab\" in sys.modules:\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")\n","    base = f\"/content/drive/MyDrive/colab_notebooks/kaggle/{comp_name}/notebooks\"\n","    %cd {base}\n","\n","\n","import os\n","INPUT_DIR = f'../input/{comp_name}/'\n","if 'kaggle_web_client' in sys.modules:\n","    OUTPUT_DIR = './'\n","else:\n","    OUTPUT_DIR = f'../input/{nb_name}/'\n","    if not os.path.exists(OUTPUT_DIR):\n","        os.makedirs(OUTPUT_DIR)"]},{"cell_type":"markdown","metadata":{"id":"1d0c4430"},"source":["# CFG"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"48dd82bb"},"outputs":[],"source":["# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    wandb=True\n","    wandbproject=comp_name\n","    wandbgroup=nb_name\n","    wandbname='late_exp001'\n","    _wandb_kernel='riow1983'\n","    apex=True\n","    print_freq=100\n","    num_workers=8\n","    model=\"microsoft/deberta-v3-large\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=8\n","    fc_dropout=0.2\n","    target_size=1\n","    max_len=512\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    #### AWP\n","    adv_lr=1e-6\n","    adv_eps=1e-3\n","    #### AWPAWP\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","    train=True\n","    \n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0]\n","    CFG.wandb = False"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":590},"executionInfo":{"elapsed":11270,"status":"ok","timestamp":1655272441954,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"b88c983e","outputId":"0eb958cc-afac-449d-ef3e-37b3da55dd82"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: wandb in /usr/local/lib/python3.7/dist-packages (0.12.18)\n","Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n","Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (6.0)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n","Requirement already satisfied: setproctitle in /usr/local/lib/python3.7/dist-packages (from wandb) (1.2.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n","Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.1.27)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n","Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (0.4.0)\n","Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.5.12)\n","Requirement already satisfied: protobuf<4.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n","Requirement already satisfied: pathtools in /usr/local/lib/python3.7/dist-packages (from wandb) (0.1.2)\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n","Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.0.9)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.0.9)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.7/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb) (5.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mriow1983\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"data":{"text/html":["Tracking run with wandb version 0.12.18"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>../input/nb005t-deberta-v3-large/wandb/run-20220615_055356-7np6v3i4</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching/runs/7np6v3i4\" target=\"_blank\">exp005</a></strong> to <a href=\"https://wandb.ai/riow1983/us-patent-phrase-to-phrase-matching\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["wandb run id: 7np6v3i4\n"]}],"source":["# ====================================================\n","# wandb\n","# ====================================================\n","if CFG.wandb:\n","    if 'google.colab' in sys.modules:\n","        !pip install wandb\n","    import wandb\n","\n","    try:\n","        if 'kaggle_web_client' in sys.modules:\n","            from kaggle_secrets import UserSecretsClient\n","            user_secrets = UserSecretsClient()\n","            secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n","        else:\n","            import json\n","            f = open(\"../../wandb.json\", \"r\")\n","            json_data = json.load(f)\n","            secret_value_0 = json_data[\"wandb_api\"]\n","        wandb.login(key=secret_value_0)\n","        anony = None\n","    except:\n","        anony = \"must\"\n","        print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","\n","\n","    def class2dict(f):\n","        return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n","    \n","    run = wandb.init(\n","        dir=OUTPUT_DIR,\n","        project=CFG.wandbproject,\n","        group=CFG.wandbgroup,\n","        name=CFG.wandbname, \n","        config=class2dict(CFG),\n","        job_type=\"train\",\n","        anonymous=anony)\n","    print(f\"wandb run id: {run.id}\")"]},{"cell_type":"markdown","metadata":{"id":"f2ed8ef2"},"source":["# Library"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17061,"status":"ok","timestamp":1655272459009,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"35916341","outputId":"7a0f1c26-11e8-48a4-ae8d-60055b450f06"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.__version__: 1.11.0+cu113\n","tokenizers.__version__: 0.12.1\n","transformers.__version__: 4.18.0\n","env: TOKENIZERS_PARALLELISM=true\n"]}],"source":["# ====================================================\n","# Library\n","# ====================================================\n","import os\n","import gc\n","import re\n","import ast\n","import sys\n","import copy\n","import json\n","import time\n","import math\n","import shutil\n","import string\n","import pickle\n","import random\n","import joblib\n","import itertools\n","from pathlib import Path\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","import scipy as sp\n","import numpy as np\n","import pandas as pd\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n","\n","\n","# # PyTorchのバージョンを1.10.1に下げる (Google Colabなのでpipでやる)\n","# os.system('pip uninstall -y torch torchvision torchaudio')\n","# os.system('pip install torch==1.10.1+cu111 torchvision==0.11.2+cu111 torchaudio==0.10.1 -f https://download.pytorch.org/whl/torch_stable.html')\n","\n","\n","import torch\n","print(f\"torch.__version__: {torch.__version__}\")\n","import torch.nn as nn\n","from torch.nn import Parameter\n","import torch.nn.functional as F\n","from torch.optim import Adam, SGD, AdamW\n","from torch.utils.data import DataLoader, Dataset\n","\n","os.system('pip uninstall -y transformers')\n","os.system('pip uninstall -y tokenizers')\n","os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels transformers')\n","os.system('python -m pip install --no-index --find-links=../input/pppm-pip-wheels tokenizers')\n","# os.system('python -m pip install transformers')\n","# os.system('python -m pip install tokenizers')\n","os.system('pip install sentencepiece')\n","import tokenizers\n","import transformers\n","print(f\"tokenizers.__version__: {tokenizers.__version__}\")\n","print(f\"transformers.__version__: {transformers.__version__}\")\n","from transformers import AutoTokenizer, AutoModel, AutoConfig\n","#### TFH\n","from transformers import AutoModelForTokenClassification\n","#### TFHTFH\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","%env TOKENIZERS_PARALLELISM=true\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"markdown","metadata":{"id":"fd586614"},"source":["# Utils"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5c0ccc6"},"outputs":[],"source":["# ====================================================\n","# Utils\n","# ====================================================\n","def get_score(y_true, y_pred):\n","    score = sp.stats.pearsonr(y_true, y_pred)[0]\n","    return score\n","\n","\n","def get_logger(filename=OUTPUT_DIR+'train'):\n","    from logging import getLogger, INFO, StreamHandler, FileHandler, Formatter\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=42):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    \n","seed_everything(seed=42)"]},{"cell_type":"markdown","metadata":{"id":"cb3d8e1e"},"source":["# Data Loading"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":638},"executionInfo":{"elapsed":37,"status":"ok","timestamp":1655272459011,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"bef012d3","outputId":"13c9bd83-923d-4d00-f82e-bf2097228421"},"outputs":[{"name":"stdout","output_type":"stream","text":["train.shape: (36473, 5)\n","test.shape: (36, 4)\n","submission.shape: (36, 2)\n"]},{"data":{"text/html":["\n","  <div id=\"df-bd5afb05-1925-4b84-935a-d124103f06fc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd5afb05-1925-4b84-935a-d124103f06fc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bd5afb05-1925-4b84-935a-d124103f06fc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bd5afb05-1925-4b84-935a-d124103f06fc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-c38e36ad-1bf2-482a-af08-a2aa13e99110\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c38e36ad-1bf2-482a-af08-a2aa13e99110')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c38e36ad-1bf2-482a-af08-a2aa13e99110 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c38e36ad-1bf2-482a-af08-a2aa13e99110');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id              anchor                         target context\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23\n","2  36baf228038e314b      lower trunnion                 lower locating     B60\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-4581d88f-42fc-4666-92e2-f78ef5f0552a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4581d88f-42fc-4666-92e2-f78ef5f0552a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4581d88f-42fc-4666-92e2-f78ef5f0552a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4581d88f-42fc-4666-92e2-f78ef5f0552a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id  score\n","0  4112d61851461f60      0\n","1  09e418c93a776564      0\n","2  36baf228038e314b      0\n","3  1f37ead645e7f0c8      0\n","4  71a5b6ad068d531f      0"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# Data Loading\n","# ====================================================\n","train = pd.read_csv(INPUT_DIR+'train.csv')\n","test = pd.read_csv(INPUT_DIR+'test.csv')\n","submission = pd.read_csv(INPUT_DIR+'sample_submission.csv')\n","print(f\"train.shape: {train.shape}\")\n","print(f\"test.shape: {test.shape}\")\n","print(f\"submission.shape: {submission.shape}\")\n","display(train.head())\n","display(test.head())\n","display(submission.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":613},"executionInfo":{"elapsed":467,"status":"ok","timestamp":1655272459465,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"UCsnldv5vMMq","outputId":"ffe04e63-5e6d-4869-a56c-c1141f855076"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-94ee6286-4956-48af-8c31-a092dad56735\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-94ee6286-4956-48af-8c31-a092dad56735')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-94ee6286-4956-48af-8c31-a092dad56735 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-94ee6286-4956-48af-8c31-a092dad56735');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-02adbfb5-160c-4657-8d39-3ffcbe065537\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>context_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","      <td>PHYSICS. OPTICS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02adbfb5-160c-4657-8d39-3ffcbe065537')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-02adbfb5-160c-4657-8d39-3ffcbe065537 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-02adbfb5-160c-4657-8d39-3ffcbe065537');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# ====================================================\n","# CPC Data\n","# ====================================================\n","def get_cpc_texts():\n","    contexts = []\n","    pattern = '[A-Z]\\d+'\n","    for file_name in os.listdir('../input/cpc-data/CPCSchemeXML202105'):\n","        result = re.findall(pattern, file_name)\n","        if result:\n","            contexts.append(result)\n","    contexts = sorted(set(sum(contexts, [])))\n","    results = {}\n","    for cpc in ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'Y']:\n","        with open(f'../input/cpc-data/CPCTitleList202202/cpc-section-{cpc}_20220201.txt') as f:\n","            s = f.read()\n","        pattern = f'{cpc}\\t\\t.+'\n","        result = re.findall(pattern, s)\n","        cpc_result = result[0].lstrip(pattern)\n","        for context in [c for c in contexts if c[0] == cpc]:\n","            pattern = f'{context}\\t\\t.+'\n","            result = re.findall(pattern, s)\n","            results[context] = cpc_result + \". \" + result[0].lstrip(pattern)\n","    return results\n","\n","\n","cpc_texts = get_cpc_texts()\n","torch.save(cpc_texts, OUTPUT_DIR+\"cpc_texts.pth\")\n","train['context_text'] = train['context'].map(cpc_texts)\n","test['context_text'] = test['context'].map(cpc_texts)\n","display(train.head())\n","display(test.head())"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":646,"status":"ok","timestamp":1655272460099,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"PJvUJQujvMMr","outputId":"e98e7d35-dcd6-42bb-f687-5f9ae99f04ae"},"outputs":[{"data":{"text/html":["\n","  <div id=\"df-bfbd42e3-44d1-4f28-883b-7957bf41d6ef\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>score</th>\n","      <th>context_text</th>\n","      <th>text</th>\n","      <th>text2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>37d61fd2272659b1</td>\n","      <td>abatement</td>\n","      <td>abatement of pollution</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]abatement of pollution</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>7b9652b17b68b7a4</td>\n","      <td>abatement</td>\n","      <td>act of abating</td>\n","      <td>A47</td>\n","      <td>0.75</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]act of abating</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36d72442aefd8232</td>\n","      <td>abatement</td>\n","      <td>active catalyst</td>\n","      <td>A47</td>\n","      <td>0.25</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]active catalyst</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5296b0c19e1ce60e</td>\n","      <td>abatement</td>\n","      <td>eliminating process</td>\n","      <td>A47</td>\n","      <td>0.50</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]eliminating process</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>54c1e3b9184cb5b6</td>\n","      <td>abatement</td>\n","      <td>forest region</td>\n","      <td>A47</td>\n","      <td>0.00</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","      <td>abatement[SEP]forest region</td>\n","      <td>HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bfbd42e3-44d1-4f28-883b-7957bf41d6ef')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-bfbd42e3-44d1-4f28-883b-7957bf41d6ef button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-bfbd42e3-44d1-4f28-883b-7957bf41d6ef');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id     anchor                  target context  score                                       context_text                                  text                                              text2\n","0  37d61fd2272659b1  abatement  abatement of pollution     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...  abatement[SEP]abatement of pollution  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","1  7b9652b17b68b7a4  abatement          act of abating     A47   0.75  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...          abatement[SEP]act of abating  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","2  36d72442aefd8232  abatement         active catalyst     A47   0.25  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...         abatement[SEP]active catalyst  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","3  5296b0c19e1ce60e  abatement     eliminating process     A47   0.50  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...     abatement[SEP]eliminating process  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...\n","4  54c1e3b9184cb5b6  abatement           forest region     A47   0.00  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE...           abatement[SEP]forest region  HUMAN NECESSITIES. FURNITURE; DOMESTIC ARTICLE..."]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","  <div id=\"df-6ed2ed20-dc9e-4f1a-8196-c0960280ae4d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>anchor</th>\n","      <th>target</th>\n","      <th>context</th>\n","      <th>context_text</th>\n","      <th>text</th>\n","      <th>text2</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4112d61851461f60</td>\n","      <td>opc drum</td>\n","      <td>inorganic photoconductor drum</td>\n","      <td>G02</td>\n","      <td>PHYSICS. OPTICS</td>\n","      <td>opc drum[SEP]inorganic photoconductor drum</td>\n","      <td>PHYSICS. OPTICS</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>09e418c93a776564</td>\n","      <td>adjust gas flow</td>\n","      <td>altering gas flow</td>\n","      <td>F23</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","      <td>adjust gas flow[SEP]altering gas flow</td>\n","      <td>MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>36baf228038e314b</td>\n","      <td>lower trunnion</td>\n","      <td>lower locating</td>\n","      <td>B60</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","      <td>lower trunnion[SEP]lower locating</td>\n","      <td>PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1f37ead645e7f0c8</td>\n","      <td>cap component</td>\n","      <td>upper portion</td>\n","      <td>D06</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","      <td>cap component[SEP]upper portion</td>\n","      <td>TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>71a5b6ad068d531f</td>\n","      <td>neural stimulation</td>\n","      <td>artificial neural network</td>\n","      <td>H04</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","      <td>neural stimulation[SEP]artificial neural network</td>\n","      <td>ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6ed2ed20-dc9e-4f1a-8196-c0960280ae4d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-6ed2ed20-dc9e-4f1a-8196-c0960280ae4d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-6ed2ed20-dc9e-4f1a-8196-c0960280ae4d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "],"text/plain":["                 id              anchor                         target context                                       context_text                                              text                                              text2\n","0  4112d61851461f60            opc drum  inorganic photoconductor drum     G02                                    PHYSICS. OPTICS        opc drum[SEP]inorganic photoconductor drum                                    PHYSICS. OPTICS\n","1  09e418c93a776564     adjust gas flow              altering gas flow     F23  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...             adjust gas flow[SEP]altering gas flow  MECHANICAL ENGINEERING; LIGHTING; HEATING; WEA...\n","2  36baf228038e314b      lower trunnion                 lower locating     B60  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...                 lower trunnion[SEP]lower locating  PERFORMING OPERATIONS; TRANSPORTING. VEHICLES ...\n","3  1f37ead645e7f0c8       cap component                  upper portion     D06  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...                   cap component[SEP]upper portion  TEXTILES; PAPER. TREATMENT OF TEXTILES OR THE ...\n","4  71a5b6ad068d531f  neural stimulation      artificial neural network     H04      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE  neural stimulation[SEP]artificial neural network      ELECTRICITY. ELECTRIC COMMUNICATION TECHNIQUE"]},"metadata":{},"output_type":"display_data"}],"source":["# train['text'] = train['anchor'] + '[SEP]' + train['target'] + '[SEP]'  + train['context_text']\n","# test['text'] = test['anchor'] + '[SEP]' + test['target'] + '[SEP]'  + test['context_text']\n","\n","train['text'] = train['anchor'] + '[SEP]' + train['target']\n","test['text'] = test['anchor'] + '[SEP]' + test['target']\n","\n","train['text2'] = train['context_text']\n","test['text2'] = test['context_text']\n","\n","\n","display(train.head())\n","display(test.head())"]},{"cell_type":"markdown","metadata":{"id":"zuhGVmnivMMs"},"source":["# EDA"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":283},"executionInfo":{"elapsed":141,"status":"ok","timestamp":1655272460105,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"CdwSw4u5vMMs","outputId":"96944a6e-f0b9-4c89-83b5-1aaf5949ab08"},"outputs":[{"data":{"text/plain":["<matplotlib.axes._subplots.AxesSubplot at 0x7f6e7db61250>"]},"execution_count":9,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["train['score'].hist()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":178},"executionInfo":{"elapsed":118,"status":"ok","timestamp":1655272460106,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"GJBRJnjevMMs","outputId":"ff962946-f1da-424d-a77e-7e4901d481f0"},"outputs":[{"data":{"text/plain":["B    8019\n","H    6195\n","G    6013\n","C    5288\n","A    4094\n","F    4054\n","E    1531\n","D    1279\n","Name: context, dtype: int64"]},"metadata":{},"output_type":"display_data"}],"source":["display(train['context'].apply(lambda x: x[0]).value_counts())"]},{"cell_type":"markdown","metadata":{"id":"62MFTSvavMMt"},"source":["- Y is not in training data, but may be in test data?"]},{"cell_type":"markdown","metadata":{"id":"9e05b6c4"},"source":["# CV split"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2866,"status":"ok","timestamp":1655272462856,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"3ba287c4","outputId":"4c1f6c58-4dda-4a5a-9cbd-ca6deb58f6d0"},"outputs":[{"name":"stdout","output_type":"stream","text":["550 183\n","549 184\n","550 183\n","550 183\n","3    9622\n","0    9379\n","1    8860\n","2    8612\n","Name: fold, dtype: int64\n"]}],"source":["# ====================================================\n","# CV split\n","# ====================================================\n","# train['score_map'] = train['score'].map({0.00: 0, 0.25: 1, 0.50: 2, 0.75: 3, 1.00: 4})\n","# Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n","# for n, (train_index, val_index) in enumerate(Fold.split(train, train['score_map'])):\n","#     train.loc[val_index, 'fold'] = int(n)\n","# train['fold'] = train['fold'].astype(int)\n","# display(train.groupby('fold').size())\n","\n","\n","\n","# Credits to https://www.kaggle.com/code/hannes82/pppm-deberta-v3-large-closing-the-cv-lb-gap/notebook#CV-split\n","#credits to: https://www.kaggle.com/code/abhishek/creating-folds-properly-hopefully-p\n","\n","!pip install -q iterative-stratification\n","from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n","\n","dfx = pd.get_dummies(train, columns=[\"score\"]).groupby([\"anchor\"], as_index=False).sum()\n","cols = [c for c in dfx.columns if c.startswith(\"score_\") or c == \"anchor\"]\n","dfx = dfx[cols]\n","\n","mskf = MultilabelStratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=42)\n","labels = [c for c in dfx.columns if c != \"anchor\"]\n","dfx_labels = dfx[labels]\n","dfx[\"fold\"] = -1\n","\n","for fold, (trn_, val_) in enumerate(mskf.split(dfx, dfx_labels)):\n","    print(len(trn_), len(val_))\n","    dfx.loc[val_, \"fold\"] = fold\n","\n","train = train.merge(dfx[[\"anchor\", \"fold\"]], on=\"anchor\", how=\"left\")\n","del dfx\n","print(train.fold.value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4c3ce877"},"outputs":[],"source":["if CFG.debug:\n","    display(train.groupby('fold').size())\n","    train = train.sample(n=1000, random_state=0).reset_index(drop=True)\n","    display(train.groupby('fold').size())"]},{"cell_type":"markdown","metadata":{"id":"918a28aa"},"source":["# tokenizer"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3403,"status":"ok","timestamp":1655272466231,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"H4pgQRxAvMMv","outputId":"c29cedfc-2dcb-43b5-bc84-10c382968797"},"outputs":[{"name":"stderr","output_type":"stream","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}],"source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"]},{"cell_type":"markdown","metadata":{"id":"14da40cf"},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":131,"referenced_widgets":["c3a7072463804d449dd65c10f8c38471","e4c02f2f68c64eaaa86d47c76a998923","0664323959e74973a71bd4e5c6a7b9bf","1461270e1a8d4b6db15e16b8612f5a15","5ae700b4aafa4e6dafd1022b7c8fb623","8612b69581f34e2ca6ba153fc344cf4c","e9baca19c0264328ba72115ff8febe6f","31842e9cd1f94c4399eb2b82965f5816","c7a1a618887b493583968a8fce9999ce","38fb69f67e494ffcb1ed2ece66bddd90","87cb45a776e44ae4beff93b4c2b44a6c","e56743c49fda4275ab5a671d99b5baea","82b8b44806f94c5cab21b1b4e47f9b3f","244d8ae2eb7e43b4afe0508aaebfb97c","14757135308f4a239f0f327aeb059b3e","2b9b22c5fbe946d19b10d499a679d06a","6cb99871c12c423c9eb64891d426da63","59e0b0e4c5fe4535ac52697054b721d5","c91fe2daf6544ccfba05ab04421af028","872654c1df654364b00ea58baa41dd48","159532d942514366a5833ec0983e2ab9","748958d52d60497e9274b0b8a79ac845","684d6b654b0447f182764ae68a1eaa83","fc83c5657bac4bae8fd8b244ffc1494e","1c9c568a17334463bfb60d6086954bce","436c77c6f8a74ec486d3732758f8e681","462ece558d6d4f7b936c34ee8c2f771a","207b385d10584c718a4f24784c3f6ce3","5f349d1148fe4f32ab2bacfce00b678f","7ad0cd49a0c24ed1a4e1c3c538e767ef","381ad162b8b646629146d2e31f5d8690","8d2af96c01bc44edb9922bd8b57c5963","39c8e741c9b34af28b7ecca908259684"]},"executionInfo":{"elapsed":6248,"status":"ok","timestamp":1655272472466,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"c00327b0","outputId":"4709f974-74bf-46f4-85d1-c3b33f9a85af"},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3a7072463804d449dd65c10f8c38471","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/136 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e56743c49fda4275ab5a671d99b5baea","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"684d6b654b0447f182764ae68a1eaa83","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/36473 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["max_len: 133\n"]}],"source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths_dict = {}\n","\n","lengths = []\n","tk0 = tqdm(cpc_texts.values(), total=len(cpc_texts))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","lengths_dict['context_text'] = lengths\n","\n","for text_col in ['anchor', 'target']:\n","    lengths = []\n","    tk0 = tqdm(train[text_col].fillna(\"\").values, total=len(train))\n","    for text in tk0:\n","        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","        lengths.append(length)\n","    lengths_dict[text_col] = lengths\n","    \n","CFG.max_len = max(lengths_dict['anchor']) + max(lengths_dict['target'])\\\n","                + max(lengths_dict['context_text']) + 4 # CLS + SEP + SEP + SEP\n","# CFG.max_len = max(max(lengths_dict['anchor'])+max(lengths_dict['target'])+3, max(lengths_dict['context_text'])+2)\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9f791a19"},"outputs":[],"source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text, text2):\n","    inputs = cfg.tokenizer(text, text2,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.texts = df['text'].values\n","        self.texts2 = df['text2'].values\n","        self.labels = df['score'].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.texts[item], self.texts2[item])\n","        #inputs2 = prepare_input(self.cfg, self.texts2[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        #return inputs, inputs2, label\n","        return inputs, label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1655272472468,"user":{"displayName":"Ryosuke Horiuchi","userId":"18359745667022839599"},"user_tz":-540},"id":"a200bd5b","outputId":"ff20ab4f-a3e6-4de5-8ab2-ef9054af6ab6"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'\\ntrain_dataset = TrainDataset(CFG, train)\\ninputs, label = train_dataset[0]\\nprint(inputs)\\nprint(label)\\n'"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","train_dataset = TrainDataset(CFG, train)\n","inputs, label = train_dataset[0]\n","print(inputs)\n","print(label)\n","\"\"\""]},{"cell_type":"markdown","metadata":{"id":"e04d6363"},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2zrMGZbdBI2i"},"outputs":[],"source":["#### TFH\n","class TransformerHead(nn.Module):\n","    def __init__(self, in_features, max_length, num_layers=1, nhead=8, num_targets=1):\n","        super().__init__()\n","\n","        self.transformer = nn.TransformerEncoder(encoder_layer=nn.TransformerEncoderLayer(d_model=in_features,\n","                                                                                          nhead=nhead),\n","                                                 num_layers=num_layers)\n","        \n","        #### exp005\n","        # self.row_fc = nn.Linear(in_features, 1)\n","        self.row_fc = nn.Linear(in_features, 512)\n","        self.tanh = nn.Tanh()\n","        self.fc = nn.Linear(512, 1)\n","        self.softmax = nn.Softmax(dim=1)\n","        #### exp005exp005\n","        self.out_features = max_length\n","\n","    def forward(self, x):\n","        out = self.transformer(x)\n","        #### exp005\n","        # out = self.row_fc(out).squeeze(-1)\n","        out = self.row_fc(out)\n","        out = self.tanh(out)\n","        out = self.fc(out)\n","        out = self.softmax(out)\n","        #### exp005exp005\n","        return out\n","#### TFHTFH"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4c5bab44"},"outputs":[],"source":["# ====================================================\n","# Model\n","# ====================================================\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel.from_config(self.config)\n","        \n","        #### TFH\n","        # self.attention = nn.Sequential(\n","        #     nn.Linear(self.config.hidden_size, 512),\n","        #     nn.Tanh(),\n","        #     nn.Linear(512, 1),\n","        #     nn.Softmax(dim=1)\n","        # )\n","        self.feature_extractor = AutoModelForTokenClassification.from_pretrained(\"../input/deberta-v3-large/deberta-v3-large\")\n","        in_features = self.feature_extractor.classifier.in_features\n","        self.attention = TransformerHead(in_features=in_features, max_length=CFG.max_len, num_layers=1, nhead=8, num_targets=1)\n","        #### TFHTFH\n","\n","        self.fc_dropout = nn.Dropout(cfg.fc_dropout)\n","        #### TFH\n","        #### exp005\n","        self.fc = nn.Linear(self.config.hidden_size, self.cfg.target_size)\n","        # self.fc = nn.Linear(self.attention.out_features, self.cfg.target_size)\n","        #### exp005exp005\n","        #### TFHTFH\n","        \n","        self._init_weights(self.fc)\n","        self._init_weights(self.attention)\n","        \n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    #### TFH\n","    #### exp005  \n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        \n","        # outputs2 = self.model(**inputs2)\n","        # last_hidden_states2 = outputs2[0]\n","        \n","        # feature = torch.mean(last_hidden_states, 1)\n","        weights = self.attention(last_hidden_states)\n","        feature = torch.sum(weights * last_hidden_states, dim=1)\n","        #feature2 = torch.mean(last_hidden_states2, dim=1)\n","        #feature += feature2\n","        return feature\n","    \n","    # def feature(self, inputs):\n","    #     outputs = self.model(**inputs)\n","    #     last_hidden_states = outputs[0]\n","    #     feature = self.attention(last_hidden_states)\n","    #     return feature\n","    #### exp005exp005\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        output = self.fc(self.fc_dropout(feature))\n","        return output\n","    #### TFHTFH"]},{"cell_type":"markdown","metadata":{"id":"deee9675"},"source":["# Helpler functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c8263b0c"},"outputs":[],"source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","#### AWP\n","#def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler, score, awp):\n","#### AWPAWP\n","    model.train()\n","    # AWP\n","    #scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    # AWPAWP\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs2.items():\n","        #     inputs2[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","\n","        #### AWP\n","        if score > 0.75:\n","            awp.attack_backward(inputs['input_ids'], labels, inputs['attention_mask'], step) \n","        #### AWPAWP\n","\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader), \n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] loss\": losses.val,\n","                       f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs2.items():\n","        #     inputs2[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        # for k, v in inputs[1].items():\n","        #     inputs[1][k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CI1gkNrPRgan"},"outputs":[],"source":["#### AWP\n","class AWP:\n","    def __init__(\n","        self,\n","        model,\n","        optimizer,\n","        adv_param=\"weight\",\n","        adv_lr=1,\n","        adv_eps=0.2,\n","        start_epoch=0,\n","        adv_step=1,\n","        scaler=None\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.adv_param = adv_param\n","        self.adv_lr = adv_lr\n","        self.adv_eps = adv_eps\n","        self.start_epoch = start_epoch\n","        self.adv_step = adv_step\n","        self.backup = {}\n","        self.backup_eps = {}\n","        self.scaler = scaler\n","\n","    def attack_backward(self, x, y, attention_mask,epoch):\n","        if (self.adv_lr == 0) or (epoch < self.start_epoch):\n","            return None\n","\n","        self._save() \n","        for i in range(self.adv_step):\n","            self._attack_step() \n","            with torch.cuda.amp.autocast():\n","                adv_loss, tr_logits = self.model(input_ids=x, attention_mask=attention_mask, labels=y)\n","                adv_loss = adv_loss.mean()\n","            self.optimizer.zero_grad()\n","            self.scaler.scale(adv_loss).backward()\n","            \n","        self._restore()\n","\n","    def _attack_step(self):\n","        e = 1e-6\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                norm1 = torch.norm(param.grad)\n","                norm2 = torch.norm(param.data.detach())\n","                if norm1 != 0 and not torch.isnan(norm1):\n","                    r_at = self.adv_lr * param.grad / (norm1 + e) * (norm2 + e)\n","                    param.data.add_(r_at)\n","                    param.data = torch.min(\n","                        torch.max(param.data, self.backup_eps[name][0]), self.backup_eps[name][1]\n","                    )\n","                # param.data.clamp_(*self.backup_eps[name])\n","\n","    def _save(self):\n","        for name, param in self.model.named_parameters():\n","            if param.requires_grad and param.grad is not None and self.adv_param in name:\n","                if name not in self.backup:\n","                    self.backup[name] = param.data.clone()\n","                    grad_eps = self.adv_eps * param.abs().detach()\n","                    self.backup_eps[name] = (\n","                        self.backup[name] - grad_eps,\n","                        self.backup[name] + grad_eps,\n","                    )\n","\n","    def _restore(self,):\n","        for name, param in self.model.named_parameters():\n","            if name in self.backup:\n","                param.data = self.backup[name]\n","        self.backup = {}\n","        self.backup_eps = {}\n","\n","#### AWPAWP"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bed940e1"},"outputs":[],"source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","    \n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['fold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['fold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds['score'].values\n","    \n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = TrainDataset(CFG, valid_folds)\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_DIR+'config.pth')\n","    model.to(device)\n","    \n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr, \n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","    \n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","    \n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss(reduction=\"mean\")\n","    \n","    best_score = 0.\n","    #### AWP\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    awp = AWP(model,\n","              optimizer,\n","              adv_lr=CFG.adv_lr,\n","              adv_eps=CFG.adv_eps,\n","              start_epoch=num_train_steps/CFG.epochs,\n","              scaler=scaler)\n","    score = 0.\n","    #### AWPAWP\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        #### AWP\n","        #avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device, scaler, score, awp)\n","        #### AWPAWP\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","        \n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","        if CFG.wandb:\n","            wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n","                       f\"[fold{fold}] avg_train_loss\": avg_loss, \n","                       f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n","                       f\"[fold{fold}] score\": score})\n","        \n","        if best_score < score:\n","            best_score = score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\", \n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","    \n","    return valid_folds"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"6cc76b1e","outputId":"1323e631-40ad-430c-ea99-73dd1298d1b0"},"outputs":[{"name":"stderr","output_type":"stream","text":["========== fold: 0 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifer.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifer.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at ../input/deberta-v3-large/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3386] Elapsed 0m 0s (remain 52m 1s) Loss: 0.6693(0.6693) Grad: inf  LR: 0.00002000  \n","Epoch: [1][100/3386] Elapsed 0m 26s (remain 14m 12s) Loss: 0.6451(0.6415) Grad: 20477.3477  LR: 0.00002000  \n","Epoch: [1][200/3386] Elapsed 0m 51s (remain 13m 34s) Loss: 0.6194(0.6283) Grad: 25761.9980  LR: 0.00001999  \n","Epoch: [1][300/3386] Elapsed 1m 16s (remain 13m 5s) Loss: 0.6004(0.6158) Grad: 15311.7588  LR: 0.00001998  \n","Epoch: [1][400/3386] Elapsed 1m 42s (remain 12m 39s) Loss: 0.6028(0.6089) Grad: 19572.7812  LR: 0.00001996  \n","Epoch: [1][500/3386] Elapsed 2m 7s (remain 12m 11s) Loss: 0.5227(0.6014) Grad: 24845.4453  LR: 0.00001993  \n","Epoch: [1][600/3386] Elapsed 2m 32s (remain 11m 46s) Loss: 0.7072(0.5937) Grad: 19399.0723  LR: 0.00001990  \n","Epoch: [1][700/3386] Elapsed 2m 57s (remain 11m 20s) Loss: 0.6152(0.5892) Grad: 31481.3242  LR: 0.00001987  \n","Epoch: [1][800/3386] Elapsed 3m 22s (remain 10m 55s) Loss: 0.6178(0.5866) Grad: 13783.1621  LR: 0.00001983  \n","Epoch: [1][900/3386] Elapsed 3m 48s (remain 10m 29s) Loss: 0.5658(0.5855) Grad: 10716.1523  LR: 0.00001978  \n","Epoch: [1][1000/3386] Elapsed 4m 13s (remain 10m 3s) Loss: 0.6169(0.5815) Grad: 16752.4062  LR: 0.00001973  \n","Epoch: [1][1100/3386] Elapsed 4m 38s (remain 9m 38s) Loss: 0.6864(0.5795) Grad: 18458.0352  LR: 0.00001968  \n","Epoch: [1][1200/3386] Elapsed 5m 4s (remain 9m 13s) Loss: 0.4290(0.5774) Grad: 18204.9453  LR: 0.00001961  \n","Epoch: [1][1300/3386] Elapsed 5m 29s (remain 8m 47s) Loss: 0.5250(0.5763) Grad: 21569.7891  LR: 0.00001955  \n","Epoch: [1][1400/3386] Elapsed 5m 54s (remain 8m 21s) Loss: 0.6090(0.5761) Grad: 32079.2422  LR: 0.00001948  \n","Epoch: [1][1500/3386] Elapsed 6m 19s (remain 7m 56s) Loss: 0.5037(0.5741) Grad: 21231.5898  LR: 0.00001940  \n","Epoch: [1][1600/3386] Elapsed 6m 45s (remain 7m 31s) Loss: 0.5160(0.5735) Grad: 8621.4502  LR: 0.00001932  \n","Epoch: [1][1700/3386] Elapsed 7m 10s (remain 7m 6s) Loss: 0.6329(0.5728) Grad: 47689.5273  LR: 0.00001923  \n","Epoch: [1][1800/3386] Elapsed 7m 35s (remain 6m 41s) Loss: 0.5562(0.5713) Grad: 21263.4902  LR: 0.00001914  \n","Epoch: [1][1900/3386] Elapsed 8m 0s (remain 6m 15s) Loss: 0.4984(0.5705) Grad: 5598.2661  LR: 0.00001904  \n","Epoch: [1][2000/3386] Elapsed 8m 25s (remain 5m 50s) Loss: 0.5218(0.5702) Grad: 23712.9785  LR: 0.00001894  \n","Epoch: [1][2100/3386] Elapsed 8m 51s (remain 5m 24s) Loss: 0.4789(0.5693) Grad: 6342.0796  LR: 0.00001884  \n","Epoch: [1][2200/3386] Elapsed 9m 16s (remain 4m 59s) Loss: 0.4912(0.5689) Grad: 40271.0625  LR: 0.00001873  \n","Epoch: [1][2300/3386] Elapsed 9m 41s (remain 4m 34s) Loss: 0.5995(0.5685) Grad: 34221.5820  LR: 0.00001861  \n","Epoch: [1][2400/3386] Elapsed 10m 6s (remain 4m 8s) Loss: 0.5402(0.5666) Grad: 15152.7842  LR: 0.00001849  \n","Epoch: [1][2500/3386] Elapsed 10m 31s (remain 3m 43s) Loss: 0.4844(0.5657) Grad: 20595.9609  LR: 0.00001836  \n","Epoch: [1][2600/3386] Elapsed 10m 56s (remain 3m 18s) Loss: 0.5341(0.5650) Grad: 7174.6533  LR: 0.00001824  \n","Epoch: [1][2700/3386] Elapsed 11m 21s (remain 2m 52s) Loss: 0.6185(0.5638) Grad: 62503.3984  LR: 0.00001810  \n","Epoch: [1][2800/3386] Elapsed 11m 45s (remain 2m 27s) Loss: 0.5951(0.5630) Grad: 29978.4453  LR: 0.00001796  \n","Epoch: [1][2900/3386] Elapsed 12m 10s (remain 2m 2s) Loss: 0.5582(0.5618) Grad: 52187.9922  LR: 0.00001782  \n","Epoch: [1][3000/3386] Elapsed 12m 35s (remain 1m 36s) Loss: 0.3782(0.5609) Grad: 72036.3281  LR: 0.00001767  \n","Epoch: [1][3100/3386] Elapsed 13m 0s (remain 1m 11s) Loss: 0.5117(0.5603) Grad: 27005.5996  LR: 0.00001752  \n","Epoch: [1][3200/3386] Elapsed 13m 25s (remain 0m 46s) Loss: 0.4616(0.5592) Grad: 87878.9922  LR: 0.00001737  \n","Epoch: [1][3300/3386] Elapsed 13m 50s (remain 0m 21s) Loss: 0.5962(0.5584) Grad: 132473.6250  LR: 0.00001721  \n","Epoch: [1][3385/3386] Elapsed 14m 11s (remain 0m 0s) Loss: 0.3672(0.5583) Grad: 22682.4414  LR: 0.00001707  \n","EVAL: [0/1173] Elapsed 0m 0s (remain 12m 47s) Loss: 0.7722(0.7722) \n","EVAL: [100/1173] Elapsed 0m 9s (remain 1m 43s) Loss: 0.4596(0.5155) \n","EVAL: [200/1173] Elapsed 0m 18s (remain 1m 31s) Loss: 0.4779(0.5323) \n","EVAL: [300/1173] Elapsed 0m 27s (remain 1m 20s) Loss: 0.4923(0.5356) \n","EVAL: [400/1173] Elapsed 0m 36s (remain 1m 11s) Loss: 0.3948(0.5434) \n","EVAL: [500/1173] Elapsed 0m 46s (remain 1m 1s) Loss: 0.6554(0.5444) \n","EVAL: [600/1173] Elapsed 0m 55s (remain 0m 52s) Loss: 0.6842(0.5458) \n","EVAL: [700/1173] Elapsed 1m 4s (remain 0m 43s) Loss: 0.5141(0.5451) \n","EVAL: [800/1173] Elapsed 1m 13s (remain 0m 34s) Loss: 0.3359(0.5475) \n","EVAL: [900/1173] Elapsed 1m 22s (remain 0m 24s) Loss: 0.5887(0.5486) \n","EVAL: [1000/1173] Elapsed 1m 31s (remain 0m 15s) Loss: 0.6347(0.5516) \n","EVAL: [1100/1173] Elapsed 1m 40s (remain 0m 6s) Loss: 0.4085(0.5501) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5583  avg_val_loss: 0.5511  time: 959s\n","Epoch 1 - Score: 0.8236\n","Epoch 1 - Save Best Score: 0.8236 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1172/1173] Elapsed 1m 47s (remain 0m 0s) Loss: 0.6783(0.5511) \n","Epoch: [2][0/3386] Elapsed 0m 0s (remain 49m 22s) Loss: 0.4874(0.4874) Grad: 20624.3340  LR: 0.00001707  \n","Epoch: [2][100/3386] Elapsed 0m 27s (remain 14m 41s) Loss: 0.6218(0.5299) Grad: 9849.6924  LR: 0.00001690  \n","Epoch: [2][200/3386] Elapsed 0m 53s (remain 14m 8s) Loss: 0.4391(0.5263) Grad: 11746.5742  LR: 0.00001674  \n","Epoch: [2][300/3386] Elapsed 1m 20s (remain 13m 40s) Loss: 0.4319(0.5324) Grad: 21443.5176  LR: 0.00001656  \n","Epoch: [2][400/3386] Elapsed 1m 45s (remain 13m 4s) Loss: 0.5684(0.5257) Grad: 49948.0000  LR: 0.00001639  \n","Epoch: [2][500/3386] Elapsed 2m 10s (remain 12m 30s) Loss: 0.3190(0.5251) Grad: 5144.2485  LR: 0.00001621  \n","Epoch: [2][600/3386] Elapsed 2m 35s (remain 12m 1s) Loss: 0.4611(0.5223) Grad: 7480.0796  LR: 0.00001602  \n","Epoch: [2][700/3386] Elapsed 3m 0s (remain 11m 32s) Loss: 0.6805(0.5216) Grad: 74691.0859  LR: 0.00001583  \n","Epoch: [2][800/3386] Elapsed 3m 25s (remain 11m 4s) Loss: 0.5374(0.5215) Grad: 18286.2188  LR: 0.00001564  \n","Epoch: [2][900/3386] Elapsed 3m 51s (remain 10m 37s) Loss: 0.6151(0.5220) Grad: 48710.4453  LR: 0.00001545  \n","Epoch: [2][1000/3386] Elapsed 4m 16s (remain 10m 10s) Loss: 0.6642(0.5222) Grad: 36846.6641  LR: 0.00001526  \n","Epoch: [2][1100/3386] Elapsed 4m 41s (remain 9m 43s) Loss: 0.5771(0.5190) Grad: 16852.7344  LR: 0.00001506  \n","Epoch: [2][1200/3386] Elapsed 5m 6s (remain 9m 17s) Loss: 0.6297(0.5199) Grad: 20169.2363  LR: 0.00001486  \n","Epoch: [2][1300/3386] Elapsed 5m 31s (remain 8m 51s) Loss: 0.6310(0.5196) Grad: 23740.8066  LR: 0.00001465  \n","Epoch: [2][1400/3386] Elapsed 5m 56s (remain 8m 25s) Loss: 0.5650(0.5210) Grad: 37230.7812  LR: 0.00001445  \n","Epoch: [2][1500/3386] Elapsed 6m 21s (remain 7m 58s) Loss: 0.5073(0.5209) Grad: 111590.2188  LR: 0.00001424  \n","Epoch: [2][1600/3386] Elapsed 6m 46s (remain 7m 32s) Loss: 0.3184(0.5221) Grad: 28508.6895  LR: 0.00001403  \n","Epoch: [2][1700/3386] Elapsed 7m 10s (remain 7m 6s) Loss: 0.4612(0.5224) Grad: 47672.4570  LR: 0.00001381  \n","Epoch: [2][1800/3386] Elapsed 7m 35s (remain 6m 41s) Loss: 0.4829(0.5213) Grad: 18898.6035  LR: 0.00001360  \n","Epoch: [2][1900/3386] Elapsed 8m 0s (remain 6m 15s) Loss: 0.3613(0.5221) Grad: 37164.1094  LR: 0.00001338  \n","Epoch: [2][2000/3386] Elapsed 8m 26s (remain 5m 50s) Loss: 0.5288(0.5215) Grad: 46330.3164  LR: 0.00001316  \n","Epoch: [2][2100/3386] Elapsed 8m 51s (remain 5m 24s) Loss: 0.5310(0.5208) Grad: 235156.4531  LR: 0.00001294  \n","Epoch: [2][2200/3386] Elapsed 9m 16s (remain 4m 59s) Loss: 0.5995(0.5208) Grad: 45633.2422  LR: 0.00001272  \n","Epoch: [2][2300/3386] Elapsed 9m 41s (remain 4m 34s) Loss: 0.5554(0.5203) Grad: 44524.2812  LR: 0.00001249  \n","Epoch: [2][2400/3386] Elapsed 10m 6s (remain 4m 8s) Loss: 0.6105(0.5196) Grad: 37195.1953  LR: 0.00001227  \n","Epoch: [2][2500/3386] Elapsed 10m 31s (remain 3m 43s) Loss: 0.5096(0.5200) Grad: 304663.8438  LR: 0.00001204  \n","Epoch: [2][2600/3386] Elapsed 10m 56s (remain 3m 18s) Loss: 0.4020(0.5202) Grad: 37615.4570  LR: 0.00001181  \n","Epoch: [2][2700/3386] Elapsed 11m 21s (remain 2m 52s) Loss: 0.4892(0.5200) Grad: 48117.1250  LR: 0.00001159  \n","Epoch: [2][2800/3386] Elapsed 11m 46s (remain 2m 27s) Loss: 0.5192(0.5195) Grad: 84149.6562  LR: 0.00001136  \n","Epoch: [2][2900/3386] Elapsed 12m 11s (remain 2m 2s) Loss: 0.4560(0.5189) Grad: 16404.5645  LR: 0.00001113  \n","Epoch: [2][3000/3386] Elapsed 12m 36s (remain 1m 37s) Loss: 0.6753(0.5185) Grad: 53896.7539  LR: 0.00001090  \n","Epoch: [2][3100/3386] Elapsed 13m 1s (remain 1m 11s) Loss: 0.4582(0.5187) Grad: 127908.1953  LR: 0.00001066  \n","Epoch: [2][3200/3386] Elapsed 13m 26s (remain 0m 46s) Loss: 0.5173(0.5184) Grad: 30843.6094  LR: 0.00001043  \n","Epoch: [2][3300/3386] Elapsed 13m 51s (remain 0m 21s) Loss: 0.4053(0.5182) Grad: 12906.9238  LR: 0.00001020  \n","Epoch: [2][3385/3386] Elapsed 14m 13s (remain 0m 0s) Loss: 0.4835(0.5183) Grad: 20134.2207  LR: 0.00001000  \n","EVAL: [0/1173] Elapsed 0m 0s (remain 13m 3s) Loss: 0.6345(0.6345) \n","EVAL: [100/1173] Elapsed 0m 9s (remain 1m 43s) Loss: 0.4470(0.5203) \n","EVAL: [200/1173] Elapsed 0m 18s (remain 1m 31s) Loss: 0.4692(0.5348) \n","EVAL: [300/1173] Elapsed 0m 28s (remain 1m 21s) Loss: 0.5022(0.5385) \n","EVAL: [400/1173] Elapsed 0m 37s (remain 1m 11s) Loss: 0.4239(0.5451) \n","EVAL: [500/1173] Elapsed 0m 46s (remain 1m 2s) Loss: 0.6608(0.5460) \n","EVAL: [600/1173] Elapsed 0m 55s (remain 0m 52s) Loss: 0.6648(0.5483) \n","EVAL: [700/1173] Elapsed 1m 4s (remain 0m 43s) Loss: 0.5321(0.5470) \n","EVAL: [800/1173] Elapsed 1m 14s (remain 0m 34s) Loss: 0.3373(0.5503) \n","EVAL: [900/1173] Elapsed 1m 23s (remain 0m 25s) Loss: 0.5840(0.5505) \n","EVAL: [1000/1173] Elapsed 1m 32s (remain 0m 15s) Loss: 0.6324(0.5524) \n","EVAL: [1100/1173] Elapsed 1m 41s (remain 0m 6s) Loss: 0.4094(0.5507) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5183  avg_val_loss: 0.5522  time: 962s\n","Epoch 2 - Score: 0.8341\n","Epoch 2 - Save Best Score: 0.8341 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1172/1173] Elapsed 1m 48s (remain 0m 0s) Loss: 0.6720(0.5522) \n","Epoch: [3][0/3386] Elapsed 0m 0s (remain 49m 19s) Loss: 0.3767(0.3767) Grad: 22667.5566  LR: 0.00001000  \n","Epoch: [3][100/3386] Elapsed 0m 27s (remain 14m 49s) Loss: 0.4737(0.5027) Grad: 84356.4844  LR: 0.00000977  \n","Epoch: [3][200/3386] Elapsed 0m 54s (remain 14m 19s) Loss: 0.5758(0.5090) Grad: 26186.9023  LR: 0.00000954  \n","Epoch: [3][300/3386] Elapsed 1m 21s (remain 13m 51s) Loss: 0.4997(0.5052) Grad: 20314.1270  LR: 0.00000931  \n","Epoch: [3][400/3386] Elapsed 1m 47s (remain 13m 18s) Loss: 0.5122(0.5018) Grad: 30135.2207  LR: 0.00000907  \n","Epoch: [3][500/3386] Elapsed 2m 13s (remain 12m 46s) Loss: 0.4213(0.5036) Grad: 10441.6152  LR: 0.00000884  \n","Epoch: [3][600/3386] Elapsed 2m 39s (remain 12m 17s) Loss: 0.4739(0.5041) Grad: 8372.0332  LR: 0.00000861  \n","Epoch: [3][700/3386] Elapsed 3m 5s (remain 11m 49s) Loss: 0.5797(0.5036) Grad: 38586.8320  LR: 0.00000838  \n","Epoch: [3][800/3386] Elapsed 3m 31s (remain 11m 21s) Loss: 0.5145(0.5036) Grad: 23084.5879  LR: 0.00000816  \n","Epoch: [3][900/3386] Elapsed 3m 57s (remain 10m 54s) Loss: 0.5088(0.5033) Grad: 54908.1016  LR: 0.00000793  \n","Epoch: [3][1000/3386] Elapsed 4m 23s (remain 10m 27s) Loss: 0.5135(0.5048) Grad: 21345.1016  LR: 0.00000770  \n","Epoch: [3][1100/3386] Elapsed 4m 49s (remain 10m 0s) Loss: 0.4317(0.5042) Grad: 99235.2656  LR: 0.00000748  \n","Epoch: [3][1200/3386] Elapsed 5m 15s (remain 9m 33s) Loss: 0.4744(0.5045) Grad: 20896.5098  LR: 0.00000725  \n","Epoch: [3][1300/3386] Elapsed 5m 41s (remain 9m 7s) Loss: 0.4786(0.5037) Grad: 149968.3125  LR: 0.00000703  \n","Epoch: [3][1400/3386] Elapsed 6m 7s (remain 8m 40s) Loss: 0.5615(0.5037) Grad: 24910.3965  LR: 0.00000681  \n","Epoch: [3][1500/3386] Elapsed 6m 33s (remain 8m 14s) Loss: 0.6260(0.5034) Grad: 19445.7500  LR: 0.00000659  \n","Epoch: [3][1600/3386] Elapsed 6m 59s (remain 7m 48s) Loss: 0.5508(0.5036) Grad: 7498.9614  LR: 0.00000638  \n","Epoch: [3][1700/3386] Elapsed 7m 26s (remain 7m 22s) Loss: 0.5140(0.5045) Grad: 26451.2285  LR: 0.00000616  \n","Epoch: [3][1800/3386] Elapsed 7m 52s (remain 6m 56s) Loss: 0.6042(0.5049) Grad: 14508.9922  LR: 0.00000595  \n","Epoch: [3][1900/3386] Elapsed 8m 19s (remain 6m 29s) Loss: 0.5568(0.5050) Grad: 11045.1895  LR: 0.00000574  \n","Epoch: [3][2000/3386] Elapsed 8m 44s (remain 6m 3s) Loss: 0.4603(0.5050) Grad: 16289.9268  LR: 0.00000553  \n","Epoch: [3][2100/3386] Elapsed 9m 11s (remain 5m 37s) Loss: 0.5469(0.5042) Grad: 5831.3623  LR: 0.00000532  \n","Epoch: [3][2200/3386] Elapsed 9m 37s (remain 5m 10s) Loss: 0.4961(0.5045) Grad: 13965.3271  LR: 0.00000512  \n","Epoch: [3][2300/3386] Elapsed 10m 3s (remain 4m 44s) Loss: 0.6210(0.5051) Grad: 9398.6309  LR: 0.00000492  \n","Epoch: [3][2400/3386] Elapsed 10m 29s (remain 4m 18s) Loss: 0.5261(0.5041) Grad: 26200.6953  LR: 0.00000472  \n","Epoch: [3][2500/3386] Elapsed 10m 55s (remain 3m 51s) Loss: 0.6201(0.5038) Grad: 13094.4033  LR: 0.00000452  \n","Epoch: [3][2600/3386] Elapsed 11m 21s (remain 3m 25s) Loss: 0.4951(0.5046) Grad: 11181.9766  LR: 0.00000433  \n","Epoch: [3][2700/3386] Elapsed 11m 47s (remain 2m 59s) Loss: 0.3637(0.5045) Grad: 68864.7891  LR: 0.00000414  \n","Epoch: [3][2800/3386] Elapsed 12m 13s (remain 2m 33s) Loss: 0.5008(0.5048) Grad: 12180.0332  LR: 0.00000395  \n","Epoch: [3][2900/3386] Elapsed 12m 39s (remain 2m 7s) Loss: 0.5131(0.5045) Grad: 8789.7256  LR: 0.00000377  \n","Epoch: [3][3000/3386] Elapsed 13m 5s (remain 1m 40s) Loss: 0.6791(0.5040) Grad: 147224.5781  LR: 0.00000359  \n","Epoch: [3][3100/3386] Elapsed 13m 31s (remain 1m 14s) Loss: 0.4613(0.5048) Grad: 97599.1406  LR: 0.00000342  \n","Epoch: [3][3200/3386] Elapsed 13m 57s (remain 0m 48s) Loss: 0.5462(0.5047) Grad: 40617.7812  LR: 0.00000324  \n","Epoch: [3][3300/3386] Elapsed 14m 23s (remain 0m 22s) Loss: 0.4232(0.5038) Grad: 27455.3105  LR: 0.00000307  \n","Epoch: [3][3385/3386] Elapsed 14m 45s (remain 0m 0s) Loss: 0.5121(0.5039) Grad: 9933.9258  LR: 0.00000293  \n","EVAL: [0/1173] Elapsed 0m 0s (remain 13m 32s) Loss: 0.5956(0.5956) \n","EVAL: [100/1173] Elapsed 0m 9s (remain 1m 44s) Loss: 0.4581(0.5285) \n","EVAL: [200/1173] Elapsed 0m 18s (remain 1m 31s) Loss: 0.4853(0.5474) \n","EVAL: [300/1173] Elapsed 0m 28s (remain 1m 21s) Loss: 0.5388(0.5491) \n","EVAL: [400/1173] Elapsed 0m 37s (remain 1m 11s) Loss: 0.4243(0.5577) \n","EVAL: [500/1173] Elapsed 0m 46s (remain 1m 2s) Loss: 0.6627(0.5585) \n","EVAL: [600/1173] Elapsed 0m 55s (remain 0m 52s) Loss: 0.6900(0.5592) \n","EVAL: [700/1173] Elapsed 1m 4s (remain 0m 43s) Loss: 0.5149(0.5579) \n","EVAL: [800/1173] Elapsed 1m 13s (remain 0m 34s) Loss: 0.3292(0.5599) \n","EVAL: [900/1173] Elapsed 1m 22s (remain 0m 24s) Loss: 0.5776(0.5601) \n","EVAL: [1000/1173] Elapsed 1m 31s (remain 0m 15s) Loss: 0.6307(0.5616) \n","EVAL: [1100/1173] Elapsed 1m 41s (remain 0m 6s) Loss: 0.4110(0.5595) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5039  avg_val_loss: 0.5611  time: 993s\n","Epoch 3 - Score: 0.8337\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1172/1173] Elapsed 1m 47s (remain 0m 0s) Loss: 0.6698(0.5611) \n","Epoch: [4][0/3386] Elapsed 0m 0s (remain 49m 50s) Loss: 0.4831(0.4831) Grad: 8312.8320  LR: 0.00000293  \n","Epoch: [4][100/3386] Elapsed 0m 26s (remain 14m 36s) Loss: 0.5454(0.4898) Grad: 12032.4160  LR: 0.00000277  \n","Epoch: [4][200/3386] Elapsed 0m 52s (remain 13m 56s) Loss: 0.4638(0.5028) Grad: 22827.8516  LR: 0.00000261  \n","Epoch: [4][300/3386] Elapsed 1m 18s (remain 13m 27s) Loss: 0.5225(0.4976) Grad: 52632.1484  LR: 0.00000246  \n","Epoch: [4][400/3386] Elapsed 1m 44s (remain 12m 58s) Loss: 0.3899(0.4981) Grad: 23354.5781  LR: 0.00000231  \n","Epoch: [4][500/3386] Elapsed 2m 10s (remain 12m 31s) Loss: 0.5834(0.4970) Grad: 94016.1562  LR: 0.00000216  \n","Epoch: [4][600/3386] Elapsed 2m 36s (remain 12m 4s) Loss: 0.2986(0.4996) Grad: 4272.3965  LR: 0.00000202  \n","Epoch: [4][700/3386] Elapsed 3m 2s (remain 11m 37s) Loss: 0.5657(0.4972) Grad: 213314.2188  LR: 0.00000188  \n","Epoch: [4][800/3386] Elapsed 3m 28s (remain 11m 11s) Loss: 0.4994(0.4970) Grad: 25216.5098  LR: 0.00000175  \n","Epoch: [4][900/3386] Elapsed 3m 53s (remain 10m 44s) Loss: 0.3880(0.4961) Grad: 11604.4570  LR: 0.00000162  \n","Epoch: [4][1000/3386] Elapsed 4m 19s (remain 10m 18s) Loss: 0.5280(0.4970) Grad: 11222.2148  LR: 0.00000149  \n","Epoch: [4][1100/3386] Elapsed 4m 45s (remain 9m 52s) Loss: 0.3237(0.4968) Grad: 17673.3184  LR: 0.00000137  \n","Epoch: [4][1200/3386] Elapsed 5m 11s (remain 9m 26s) Loss: 0.4028(0.4967) Grad: 200812.4844  LR: 0.00000126  \n","Epoch: [4][1300/3386] Elapsed 5m 37s (remain 9m 0s) Loss: 0.5568(0.4962) Grad: 33500.3828  LR: 0.00000115  \n","Epoch: [4][1400/3386] Elapsed 6m 3s (remain 8m 34s) Loss: 0.4133(0.4959) Grad: 22169.5332  LR: 0.00000104  \n","Epoch: [4][1500/3386] Elapsed 6m 29s (remain 8m 8s) Loss: 0.3278(0.4954) Grad: 18052.7695  LR: 0.00000094  \n","Epoch: [4][1600/3386] Elapsed 6m 55s (remain 7m 42s) Loss: 0.5144(0.4950) Grad: 13215.0215  LR: 0.00000085  \n","Epoch: [4][1700/3386] Elapsed 7m 20s (remain 7m 16s) Loss: 0.3152(0.4947) Grad: 4038.9885  LR: 0.00000076  \n","Epoch: [4][1800/3386] Elapsed 7m 46s (remain 6m 50s) Loss: 0.5573(0.4947) Grad: 13599.7744  LR: 0.00000067  \n","Epoch: [4][1900/3386] Elapsed 8m 12s (remain 6m 24s) Loss: 0.5722(0.4949) Grad: 25177.3008  LR: 0.00000059  \n","Epoch: [4][2000/3386] Elapsed 8m 37s (remain 5m 58s) Loss: 0.5524(0.4945) Grad: 35903.5586  LR: 0.00000051  \n","Epoch: [4][2100/3386] Elapsed 9m 3s (remain 5m 32s) Loss: 0.3223(0.4947) Grad: 18212.3906  LR: 0.00000044  \n","Epoch: [4][2200/3386] Elapsed 9m 29s (remain 5m 6s) Loss: 0.5588(0.4944) Grad: 84930.8594  LR: 0.00000038  \n","Epoch: [4][2300/3386] Elapsed 9m 55s (remain 4m 40s) Loss: 0.4903(0.4944) Grad: 62848.5625  LR: 0.00000032  \n","Epoch: [4][2400/3386] Elapsed 10m 20s (remain 4m 14s) Loss: 0.3692(0.4937) Grad: 7630.3535  LR: 0.00000026  \n","Epoch: [4][2500/3386] Elapsed 10m 46s (remain 3m 48s) Loss: 0.3151(0.4933) Grad: 15728.0029  LR: 0.00000021  \n","Epoch: [4][2600/3386] Elapsed 11m 12s (remain 3m 22s) Loss: 0.6277(0.4936) Grad: 48966.3359  LR: 0.00000017  \n","Epoch: [4][2700/3386] Elapsed 11m 38s (remain 2m 57s) Loss: 0.4662(0.4935) Grad: 228735.8438  LR: 0.00000013  \n","Epoch: [4][2800/3386] Elapsed 12m 3s (remain 2m 31s) Loss: 0.3352(0.4932) Grad: 34337.7617  LR: 0.00000009  \n","Epoch: [4][2900/3386] Elapsed 12m 29s (remain 2m 5s) Loss: 0.3740(0.4929) Grad: 51676.8438  LR: 0.00000006  \n","Epoch: [4][3000/3386] Elapsed 12m 55s (remain 1m 39s) Loss: 0.4896(0.4927) Grad: 19560.2109  LR: 0.00000004  \n","Epoch: [4][3100/3386] Elapsed 13m 20s (remain 1m 13s) Loss: 0.3866(0.4930) Grad: 20803.4102  LR: 0.00000002  \n","Epoch: [4][3200/3386] Elapsed 13m 46s (remain 0m 47s) Loss: 0.5581(0.4934) Grad: 45290.1484  LR: 0.00000001  \n","Epoch: [4][3300/3386] Elapsed 14m 11s (remain 0m 21s) Loss: 0.5381(0.4935) Grad: 47085.7852  LR: 0.00000000  \n","Epoch: [4][3385/3386] Elapsed 14m 33s (remain 0m 0s) Loss: 0.5300(0.4935) Grad: 57354.7148  LR: 0.00000000  \n","EVAL: [0/1173] Elapsed 0m 0s (remain 13m 20s) Loss: 0.5930(0.5930) \n","EVAL: [100/1173] Elapsed 0m 9s (remain 1m 44s) Loss: 0.4741(0.5304) \n","EVAL: [200/1173] Elapsed 0m 18s (remain 1m 31s) Loss: 0.4749(0.5483) \n","EVAL: [300/1173] Elapsed 0m 28s (remain 1m 21s) Loss: 0.5400(0.5510) \n","EVAL: [400/1173] Elapsed 0m 37s (remain 1m 11s) Loss: 0.4223(0.5608) \n","EVAL: [500/1173] Elapsed 0m 46s (remain 1m 2s) Loss: 0.6848(0.5612) \n","EVAL: [600/1173] Elapsed 0m 55s (remain 0m 52s) Loss: 0.7024(0.5616) \n","EVAL: [700/1173] Elapsed 1m 4s (remain 0m 43s) Loss: 0.5179(0.5606) \n","EVAL: [800/1173] Elapsed 1m 13s (remain 0m 34s) Loss: 0.3282(0.5627) \n","EVAL: [900/1173] Elapsed 1m 22s (remain 0m 24s) Loss: 0.5780(0.5627) \n","EVAL: [1000/1173] Elapsed 1m 31s (remain 0m 15s) Loss: 0.6319(0.5644) \n","EVAL: [1100/1173] Elapsed 1m 41s (remain 0m 6s) Loss: 0.4173(0.5622) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 4 - avg_train_loss: 0.4935  avg_val_loss: 0.5639  time: 982s\n","Epoch 4 - Score: 0.8325\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1172/1173] Elapsed 1m 47s (remain 0m 0s) Loss: 0.6667(0.5639) \n"]},{"name":"stderr","output_type":"stream","text":["========== fold: 0 result ==========\n","Score: 0.8341\n","========== fold: 1 training ==========\n","Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing DebertaV2Model: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.classifier.weight', 'mask_predictions.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.dense.weight']\n","- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2ForTokenClassification: ['deberta.embeddings.position_embeddings.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.classifer.weight', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifer.bias']\n","- This IS expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing DebertaV2ForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at ../input/deberta-v3-large/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch: [1][0/3451] Elapsed 0m 0s (remain 53m 37s) Loss: 0.7248(0.7248) Grad: 169127.7969  LR: 0.00002000  \n","Epoch: [1][100/3451] Elapsed 0m 26s (remain 14m 33s) Loss: 0.5577(0.6430) Grad: 77452.9297  LR: 0.00002000  \n","Epoch: [1][200/3451] Elapsed 0m 51s (remain 14m 0s) Loss: 0.4576(0.6212) Grad: 28711.6250  LR: 0.00001999  \n","Epoch: [1][300/3451] Elapsed 1m 17s (remain 13m 32s) Loss: 0.3576(0.6077) Grad: 77584.2656  LR: 0.00001998  \n","Epoch: [1][400/3451] Elapsed 1m 43s (remain 13m 7s) Loss: 0.5083(0.5998) Grad: 48017.5000  LR: 0.00001996  \n","Epoch: [1][500/3451] Elapsed 2m 9s (remain 12m 40s) Loss: 0.6492(0.5953) Grad: 19086.4668  LR: 0.00001994  \n","Epoch: [1][600/3451] Elapsed 2m 35s (remain 12m 15s) Loss: 0.5347(0.5885) Grad: 58241.8320  LR: 0.00001991  \n","Epoch: [1][700/3451] Elapsed 3m 0s (remain 11m 47s) Loss: 0.4451(0.5852) Grad: 37152.0938  LR: 0.00001987  \n","Epoch: [1][800/3451] Elapsed 3m 26s (remain 11m 21s) Loss: 0.5340(0.5845) Grad: 55224.5781  LR: 0.00001983  \n","Epoch: [1][900/3451] Elapsed 3m 51s (remain 10m 54s) Loss: 0.7068(0.5817) Grad: 92215.9297  LR: 0.00001979  \n","Epoch: [1][1000/3451] Elapsed 4m 16s (remain 10m 27s) Loss: 0.5151(0.5809) Grad: 58588.3438  LR: 0.00001974  \n","Epoch: [1][1100/3451] Elapsed 4m 41s (remain 10m 0s) Loss: 0.4566(0.5802) Grad: 24695.9707  LR: 0.00001969  \n","Epoch: [1][1200/3451] Elapsed 5m 6s (remain 9m 34s) Loss: 0.5187(0.5800) Grad: 19073.9375  LR: 0.00001963  \n","Epoch: [1][1300/3451] Elapsed 5m 31s (remain 9m 7s) Loss: 0.5864(0.5791) Grad: 30784.6582  LR: 0.00001956  \n","Epoch: [1][1400/3451] Elapsed 5m 56s (remain 8m 42s) Loss: 0.3904(0.5762) Grad: 33635.8555  LR: 0.00001950  \n","Epoch: [1][1500/3451] Elapsed 6m 22s (remain 8m 16s) Loss: 0.6797(0.5751) Grad: 42481.7930  LR: 0.00001942  \n","Epoch: [1][1600/3451] Elapsed 6m 47s (remain 7m 50s) Loss: 0.3938(0.5726) Grad: 38677.0703  LR: 0.00001934  \n","Epoch: [1][1700/3451] Elapsed 7m 12s (remain 7m 25s) Loss: 0.5459(0.5720) Grad: 27121.8379  LR: 0.00001926  \n","Epoch: [1][1800/3451] Elapsed 7m 38s (remain 6m 59s) Loss: 0.6163(0.5711) Grad: 21717.3691  LR: 0.00001917  \n","Epoch: [1][1900/3451] Elapsed 8m 3s (remain 6m 34s) Loss: 0.5537(0.5699) Grad: 15054.0654  LR: 0.00001908  \n","Epoch: [1][2000/3451] Elapsed 8m 29s (remain 6m 9s) Loss: 0.5682(0.5692) Grad: 42584.1055  LR: 0.00001898  \n","Epoch: [1][2100/3451] Elapsed 8m 55s (remain 5m 44s) Loss: 0.4424(0.5682) Grad: 54397.9922  LR: 0.00001888  \n","Epoch: [1][2200/3451] Elapsed 9m 21s (remain 5m 18s) Loss: 0.6546(0.5672) Grad: 12892.7510  LR: 0.00001877  \n","Epoch: [1][2300/3451] Elapsed 9m 46s (remain 4m 53s) Loss: 0.3258(0.5662) Grad: 46683.9727  LR: 0.00001866  \n","Epoch: [1][2400/3451] Elapsed 10m 12s (remain 4m 27s) Loss: 0.5733(0.5651) Grad: 24148.0254  LR: 0.00001854  \n","Epoch: [1][2500/3451] Elapsed 10m 38s (remain 4m 2s) Loss: 0.4942(0.5639) Grad: 51407.4375  LR: 0.00001842  \n","Epoch: [1][2600/3451] Elapsed 11m 4s (remain 3m 37s) Loss: 0.6995(0.5635) Grad: 46245.6562  LR: 0.00001830  \n","Epoch: [1][2700/3451] Elapsed 11m 30s (remain 3m 11s) Loss: 0.6039(0.5629) Grad: 10856.7549  LR: 0.00001817  \n","Epoch: [1][2800/3451] Elapsed 11m 55s (remain 2m 46s) Loss: 0.4767(0.5619) Grad: 33107.8516  LR: 0.00001804  \n","Epoch: [1][2900/3451] Elapsed 12m 21s (remain 2m 20s) Loss: 0.6708(0.5613) Grad: 32896.4648  LR: 0.00001790  \n","Epoch: [1][3000/3451] Elapsed 12m 47s (remain 1m 55s) Loss: 0.4712(0.5610) Grad: 27228.1719  LR: 0.00001776  \n","Epoch: [1][3100/3451] Elapsed 13m 13s (remain 1m 29s) Loss: 0.5407(0.5607) Grad: 22620.5195  LR: 0.00001761  \n","Epoch: [1][3200/3451] Elapsed 13m 39s (remain 1m 4s) Loss: 0.6326(0.5603) Grad: 20811.6387  LR: 0.00001746  \n","Epoch: [1][3300/3451] Elapsed 14m 5s (remain 0m 38s) Loss: 0.9056(0.5598) Grad: 86775.9609  LR: 0.00001731  \n","Epoch: [1][3400/3451] Elapsed 14m 30s (remain 0m 12s) Loss: 0.5505(0.5592) Grad: 41241.5234  LR: 0.00001715  \n","Epoch: [1][3450/3451] Elapsed 14m 43s (remain 0m 0s) Loss: 0.6106(0.5589) Grad: 28170.9629  LR: 0.00001707  \n","EVAL: [0/1108] Elapsed 0m 0s (remain 13m 27s) Loss: 0.6178(0.6178) \n","EVAL: [100/1108] Elapsed 0m 9s (remain 1m 37s) Loss: 0.6151(0.5425) \n","EVAL: [200/1108] Elapsed 0m 18s (remain 1m 25s) Loss: 0.5470(0.5436) \n","EVAL: [300/1108] Elapsed 0m 28s (remain 1m 15s) Loss: 0.4640(0.5585) \n","EVAL: [400/1108] Elapsed 0m 37s (remain 1m 5s) Loss: 0.6175(0.5491) \n","EVAL: [500/1108] Elapsed 0m 46s (remain 0m 55s) Loss: 0.2038(0.5457) \n","EVAL: [600/1108] Elapsed 0m 55s (remain 0m 46s) Loss: 0.6160(0.5470) \n","EVAL: [700/1108] Elapsed 1m 4s (remain 0m 37s) Loss: 0.4974(0.5499) \n","EVAL: [800/1108] Elapsed 1m 13s (remain 0m 28s) Loss: 0.6817(0.5492) \n","EVAL: [900/1108] Elapsed 1m 22s (remain 0m 18s) Loss: 0.6924(0.5500) \n","EVAL: [1000/1108] Elapsed 1m 31s (remain 0m 9s) Loss: 0.6433(0.5527) \n","EVAL: [1100/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.3888(0.5535) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 1 - avg_train_loss: 0.5589  avg_val_loss: 0.5531  time: 985s\n","Epoch 1 - Score: 0.8056\n","Epoch 1 - Save Best Score: 0.8056 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1107/1108] Elapsed 1m 41s (remain 0m 0s) Loss: 0.6723(0.5531) \n","Epoch: [2][0/3451] Elapsed 0m 2s (remain 136m 16s) Loss: 0.3803(0.3803) Grad: 11355.8252  LR: 0.00001707  \n","Epoch: [2][100/3451] Elapsed 0m 28s (remain 16m 1s) Loss: 0.3868(0.5232) Grad: 24979.4922  LR: 0.00001691  \n","Epoch: [2][200/3451] Elapsed 0m 55s (remain 15m 3s) Loss: 0.6158(0.5242) Grad: 23865.9902  LR: 0.00001674  \n","Epoch: [2][300/3451] Elapsed 1m 22s (remain 14m 22s) Loss: 0.7774(0.5240) Grad: 166710.0000  LR: 0.00001657  \n","Epoch: [2][400/3451] Elapsed 1m 48s (remain 13m 42s) Loss: 0.6257(0.5238) Grad: 26093.6016  LR: 0.00001640  \n","Epoch: [2][500/3451] Elapsed 2m 13s (remain 13m 7s) Loss: 0.5129(0.5235) Grad: 17340.2207  LR: 0.00001622  \n","Epoch: [2][600/3451] Elapsed 2m 39s (remain 12m 35s) Loss: 0.3957(0.5248) Grad: 39639.2422  LR: 0.00001604  \n","Epoch: [2][700/3451] Elapsed 3m 5s (remain 12m 6s) Loss: 0.5360(0.5263) Grad: 69573.3281  LR: 0.00001586  \n","Epoch: [2][800/3451] Elapsed 3m 30s (remain 11m 36s) Loss: 0.6304(0.5260) Grad: 16976.2637  LR: 0.00001567  \n","Epoch: [2][900/3451] Elapsed 3m 56s (remain 11m 9s) Loss: 0.5159(0.5271) Grad: 35226.4141  LR: 0.00001548  \n","Epoch: [2][1000/3451] Elapsed 4m 22s (remain 10m 42s) Loss: 0.5776(0.5287) Grad: 51598.5703  LR: 0.00001529  \n","Epoch: [2][1100/3451] Elapsed 4m 48s (remain 10m 15s) Loss: 0.6258(0.5282) Grad: 15456.1953  LR: 0.00001510  \n","Epoch: [2][1200/3451] Elapsed 5m 13s (remain 9m 48s) Loss: 0.6226(0.5287) Grad: 9961.8770  LR: 0.00001490  \n","Epoch: [2][1300/3451] Elapsed 5m 39s (remain 9m 21s) Loss: 0.4079(0.5279) Grad: 61571.4961  LR: 0.00001470  \n","Epoch: [2][1400/3451] Elapsed 6m 5s (remain 8m 55s) Loss: 0.4508(0.5252) Grad: 9005.0615  LR: 0.00001450  \n","Epoch: [2][1500/3451] Elapsed 6m 31s (remain 8m 28s) Loss: 0.5709(0.5241) Grad: 8289.0947  LR: 0.00001430  \n","Epoch: [2][1600/3451] Elapsed 6m 57s (remain 8m 2s) Loss: 0.6029(0.5243) Grad: 30185.7520  LR: 0.00001409  \n","Epoch: [2][1700/3451] Elapsed 7m 22s (remain 7m 35s) Loss: 0.5472(0.5238) Grad: 14802.5850  LR: 0.00001388  \n","Epoch: [2][1800/3451] Elapsed 7m 48s (remain 7m 9s) Loss: 0.5792(0.5237) Grad: 37039.7461  LR: 0.00001367  \n","Epoch: [2][1900/3451] Elapsed 8m 14s (remain 6m 42s) Loss: 0.6700(0.5234) Grad: 75880.3906  LR: 0.00001346  \n","Epoch: [2][2000/3451] Elapsed 8m 39s (remain 6m 16s) Loss: 0.4316(0.5236) Grad: 52280.7109  LR: 0.00001324  \n","Epoch: [2][2100/3451] Elapsed 9m 5s (remain 5m 50s) Loss: 0.4818(0.5234) Grad: 8000.9214  LR: 0.00001303  \n","Epoch: [2][2200/3451] Elapsed 9m 31s (remain 5m 24s) Loss: 0.4669(0.5238) Grad: 10262.1738  LR: 0.00001281  \n","Epoch: [2][2300/3451] Elapsed 9m 56s (remain 4m 58s) Loss: 0.5616(0.5239) Grad: 55319.0469  LR: 0.00001259  \n","Epoch: [2][2400/3451] Elapsed 10m 22s (remain 4m 32s) Loss: 0.5413(0.5234) Grad: 14366.1924  LR: 0.00001237  \n","Epoch: [2][2500/3451] Elapsed 10m 47s (remain 4m 6s) Loss: 0.5758(0.5235) Grad: 13403.6660  LR: 0.00001215  \n","Epoch: [2][2600/3451] Elapsed 11m 13s (remain 3m 40s) Loss: 0.5690(0.5238) Grad: 7097.7173  LR: 0.00001192  \n","Epoch: [2][2700/3451] Elapsed 11m 39s (remain 3m 14s) Loss: 0.5437(0.5237) Grad: 14131.9795  LR: 0.00001170  \n","Epoch: [2][2800/3451] Elapsed 12m 4s (remain 2m 48s) Loss: 0.6807(0.5235) Grad: 48824.4570  LR: 0.00001148  \n","Epoch: [2][2900/3451] Elapsed 12m 30s (remain 2m 22s) Loss: 0.4752(0.5232) Grad: 29084.2578  LR: 0.00001125  \n","Epoch: [2][3000/3451] Elapsed 12m 55s (remain 1m 56s) Loss: 0.4756(0.5227) Grad: 29550.9434  LR: 0.00001102  \n","Epoch: [2][3100/3451] Elapsed 13m 21s (remain 1m 30s) Loss: 0.6013(0.5229) Grad: 114168.7422  LR: 0.00001080  \n","Epoch: [2][3200/3451] Elapsed 13m 47s (remain 1m 4s) Loss: 0.4717(0.5223) Grad: 26774.9668  LR: 0.00001057  \n","Epoch: [2][3300/3451] Elapsed 14m 13s (remain 0m 38s) Loss: 0.6974(0.5225) Grad: 27272.0078  LR: 0.00001034  \n","Epoch: [2][3400/3451] Elapsed 14m 38s (remain 0m 12s) Loss: 0.6395(0.5222) Grad: 83181.9766  LR: 0.00001012  \n","Epoch: [2][3450/3451] Elapsed 14m 51s (remain 0m 0s) Loss: 0.5486(0.5225) Grad: 27994.6836  LR: 0.00001000  \n","EVAL: [0/1108] Elapsed 0m 0s (remain 13m 32s) Loss: 0.6044(0.6044) \n","EVAL: [100/1108] Elapsed 0m 9s (remain 1m 38s) Loss: 0.5833(0.5630) \n","EVAL: [200/1108] Elapsed 0m 19s (remain 1m 25s) Loss: 0.5314(0.5579) \n","EVAL: [300/1108] Elapsed 0m 28s (remain 1m 15s) Loss: 0.4504(0.5689) \n","EVAL: [400/1108] Elapsed 0m 37s (remain 1m 5s) Loss: 0.9558(0.5617) \n","EVAL: [500/1108] Elapsed 0m 46s (remain 0m 56s) Loss: 0.2303(0.5596) \n","EVAL: [600/1108] Elapsed 0m 55s (remain 0m 46s) Loss: 0.6094(0.5604) \n","EVAL: [700/1108] Elapsed 1m 4s (remain 0m 37s) Loss: 0.5310(0.5626) \n","EVAL: [800/1108] Elapsed 1m 13s (remain 0m 28s) Loss: 0.7076(0.5611) \n","EVAL: [900/1108] Elapsed 1m 22s (remain 0m 19s) Loss: 0.7199(0.5618) \n","EVAL: [1000/1108] Elapsed 1m 31s (remain 0m 9s) Loss: 0.7593(0.5637) \n","EVAL: [1100/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.3738(0.5649) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 2 - avg_train_loss: 0.5225  avg_val_loss: 0.5645  time: 993s\n","Epoch 2 - Score: 0.8116\n","Epoch 2 - Save Best Score: 0.8116 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1107/1108] Elapsed 1m 41s (remain 0m 0s) Loss: 0.6651(0.5645) \n","Epoch: [3][0/3451] Elapsed 0m 0s (remain 53m 34s) Loss: 0.6640(0.6640) Grad: 24614.4180  LR: 0.00001000  \n","Epoch: [3][100/3451] Elapsed 0m 27s (remain 15m 26s) Loss: 0.5336(0.5145) Grad: 35579.0781  LR: 0.00000977  \n","Epoch: [3][200/3451] Elapsed 0m 55s (remain 14m 53s) Loss: 0.3774(0.4966) Grad: 17884.7344  LR: 0.00000955  \n","Epoch: [3][300/3451] Elapsed 1m 21s (remain 14m 16s) Loss: 0.4998(0.4962) Grad: 37449.1133  LR: 0.00000932  \n","Epoch: [3][400/3451] Elapsed 1m 47s (remain 13m 39s) Loss: 0.4032(0.4929) Grad: 9331.9121  LR: 0.00000909  \n","Epoch: [3][500/3451] Elapsed 2m 13s (remain 13m 8s) Loss: 0.3762(0.4941) Grad: 11184.0977  LR: 0.00000886  \n","Epoch: [3][600/3451] Elapsed 2m 39s (remain 12m 37s) Loss: 0.4954(0.4951) Grad: 163788.8438  LR: 0.00000864  \n","Epoch: [3][700/3451] Elapsed 3m 5s (remain 12m 7s) Loss: 0.4248(0.4963) Grad: 272924.9375  LR: 0.00000841  \n","Epoch: [3][800/3451] Elapsed 3m 31s (remain 11m 38s) Loss: 0.4348(0.5001) Grad: 74232.1797  LR: 0.00000819  \n","Epoch: [3][900/3451] Elapsed 3m 56s (remain 11m 10s) Loss: 0.5139(0.5022) Grad: 19010.5293  LR: 0.00000797  \n","Epoch: [3][1000/3451] Elapsed 4m 22s (remain 10m 42s) Loss: 0.6046(0.5035) Grad: 251609.3750  LR: 0.00000774  \n","Epoch: [3][1100/3451] Elapsed 4m 48s (remain 10m 14s) Loss: 0.3774(0.5030) Grad: 18244.4766  LR: 0.00000752  \n","Epoch: [3][1200/3451] Elapsed 5m 13s (remain 9m 47s) Loss: 0.3756(0.5018) Grad: 10442.1650  LR: 0.00000730  \n","Epoch: [3][1300/3451] Elapsed 5m 39s (remain 9m 21s) Loss: 0.5663(0.5012) Grad: 27224.1191  LR: 0.00000708  \n","Epoch: [3][1400/3451] Elapsed 6m 5s (remain 8m 54s) Loss: 0.4883(0.5018) Grad: 46656.6914  LR: 0.00000687  \n","Epoch: [3][1500/3451] Elapsed 6m 30s (remain 8m 27s) Loss: 0.4782(0.5028) Grad: 37282.2969  LR: 0.00000665  \n","Epoch: [3][1600/3451] Elapsed 6m 56s (remain 8m 1s) Loss: 0.5478(0.5018) Grad: 32242.7988  LR: 0.00000644  \n","Epoch: [3][1700/3451] Elapsed 7m 22s (remain 7m 34s) Loss: 0.5405(0.5019) Grad: 39426.3320  LR: 0.00000623  \n","Epoch: [3][1800/3451] Elapsed 7m 47s (remain 7m 8s) Loss: 0.5478(0.5018) Grad: 33650.4727  LR: 0.00000602  \n","Epoch: [3][1900/3451] Elapsed 8m 13s (remain 6m 42s) Loss: 0.4746(0.5016) Grad: 70034.0469  LR: 0.00000581  \n","Epoch: [3][2000/3451] Elapsed 8m 39s (remain 6m 16s) Loss: 0.6669(0.5024) Grad: 83648.7109  LR: 0.00000560  \n","Epoch: [3][2100/3451] Elapsed 9m 5s (remain 5m 50s) Loss: 0.3951(0.5023) Grad: 41031.5859  LR: 0.00000540  \n","Epoch: [3][2200/3451] Elapsed 9m 30s (remain 5m 24s) Loss: 0.5104(0.5028) Grad: 59376.4727  LR: 0.00000520  \n","Epoch: [3][2300/3451] Elapsed 9m 56s (remain 4m 58s) Loss: 0.4946(0.5026) Grad: 46895.4453  LR: 0.00000500  \n","Epoch: [3][2400/3451] Elapsed 10m 22s (remain 4m 32s) Loss: 0.4673(0.5040) Grad: 30446.5742  LR: 0.00000481  \n","Epoch: [3][2500/3451] Elapsed 10m 48s (remain 4m 6s) Loss: 0.4078(0.5037) Grad: 28868.2188  LR: 0.00000461  \n","Epoch: [3][2600/3451] Elapsed 11m 14s (remain 3m 40s) Loss: 0.4951(0.5040) Grad: 17437.7754  LR: 0.00000442  \n","Epoch: [3][2700/3451] Elapsed 11m 39s (remain 3m 14s) Loss: 0.4324(0.5036) Grad: 319066.5625  LR: 0.00000424  \n","Epoch: [3][2800/3451] Elapsed 12m 5s (remain 2m 48s) Loss: 0.3996(0.5034) Grad: 95744.8594  LR: 0.00000405  \n","Epoch: [3][2900/3451] Elapsed 12m 30s (remain 2m 22s) Loss: 0.4570(0.5036) Grad: 117508.1172  LR: 0.00000387  \n","Epoch: [3][3000/3451] Elapsed 12m 56s (remain 1m 56s) Loss: 0.5150(0.5029) Grad: 32623.3203  LR: 0.00000369  \n","Epoch: [3][3100/3451] Elapsed 13m 21s (remain 1m 30s) Loss: 0.3154(0.5026) Grad: 19110.8203  LR: 0.00000352  \n","Epoch: [3][3200/3451] Elapsed 13m 47s (remain 1m 4s) Loss: 0.5255(0.5023) Grad: 104713.8281  LR: 0.00000334  \n","Epoch: [3][3300/3451] Elapsed 14m 12s (remain 0m 38s) Loss: 0.6707(0.5019) Grad: 66095.4375  LR: 0.00000318  \n","Epoch: [3][3400/3451] Elapsed 14m 38s (remain 0m 12s) Loss: 0.5462(0.5020) Grad: 92304.6641  LR: 0.00000301  \n","Epoch: [3][3450/3451] Elapsed 14m 51s (remain 0m 0s) Loss: 0.6528(0.5017) Grad: 98334.9766  LR: 0.00000293  \n","EVAL: [0/1108] Elapsed 0m 0s (remain 13m 9s) Loss: 0.8951(0.8951) \n","EVAL: [100/1108] Elapsed 0m 9s (remain 1m 37s) Loss: 0.5811(0.5782) \n","EVAL: [200/1108] Elapsed 0m 18s (remain 1m 24s) Loss: 0.5103(0.5685) \n","EVAL: [300/1108] Elapsed 0m 27s (remain 1m 14s) Loss: 0.4319(0.5822) \n","EVAL: [400/1108] Elapsed 0m 36s (remain 1m 5s) Loss: 0.8951(0.5752) \n","EVAL: [500/1108] Elapsed 0m 46s (remain 0m 55s) Loss: 0.2202(0.5728) \n","EVAL: [600/1108] Elapsed 0m 55s (remain 0m 46s) Loss: 0.6047(0.5738) \n","EVAL: [700/1108] Elapsed 1m 4s (remain 0m 37s) Loss: 0.5111(0.5767) \n","EVAL: [800/1108] Elapsed 1m 13s (remain 0m 28s) Loss: 0.7101(0.5746) \n","EVAL: [900/1108] Elapsed 1m 22s (remain 0m 18s) Loss: 0.7157(0.5751) \n","EVAL: [1000/1108] Elapsed 1m 31s (remain 0m 9s) Loss: 0.6615(0.5745) \n","EVAL: [1100/1108] Elapsed 1m 40s (remain 0m 0s) Loss: 0.3730(0.5765) \n"]},{"name":"stderr","output_type":"stream","text":["Epoch 3 - avg_train_loss: 0.5017  avg_val_loss: 0.5765  time: 992s\n","Epoch 3 - Score: 0.8163\n","Epoch 3 - Save Best Score: 0.8163 Model\n"]},{"name":"stdout","output_type":"stream","text":["EVAL: [1107/1108] Elapsed 1m 41s (remain 0m 0s) Loss: 0.6651(0.5765) \n","Epoch: [4][0/3451] Elapsed 0m 0s (remain 54m 13s) Loss: 0.4096(0.4096) Grad: 125229.2188  LR: 0.00000293  \n","Epoch: [4][100/3451] Elapsed 0m 27s (remain 15m 1s) Loss: 0.5386(0.4982) Grad: 83029.3750  LR: 0.00000277  \n","Epoch: [4][200/3451] Elapsed 0m 54s (remain 14m 36s) Loss: 0.8878(0.4982) Grad: 773618.6875  LR: 0.00000262  \n","Epoch: [4][300/3451] Elapsed 1m 20s (remain 14m 3s) Loss: 0.4192(0.5014) Grad: 17577.1543  LR: 0.00000246  \n","Epoch: [4][400/3451] Elapsed 1m 46s (remain 13m 27s) Loss: 0.5583(0.5020) Grad: 11029.1885  LR: 0.00000232  \n","Epoch: [4][500/3451] Elapsed 2m 11s (remain 12m 54s) Loss: 0.4770(0.5008) Grad: 49753.8398  LR: 0.00000217  \n","Epoch: [4][600/3451] Elapsed 2m 37s (remain 12m 25s) Loss: 0.5067(0.5001) Grad: 97302.5625  LR: 0.00000203  \n","Epoch: [4][700/3451] Elapsed 3m 2s (remain 11m 57s) Loss: 0.5515(0.5003) Grad: 685340.8750  LR: 0.00000190  \n","Epoch: [4][800/3451] Elapsed 3m 28s (remain 11m 29s) Loss: 0.4260(0.4996) Grad: 67163.6328  LR: 0.00000177  \n"]}],"source":["if __name__ == '__main__':\n","    \n","    def get_result(oof_df):\n","        labels = oof_df['score'].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","    \n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_DIR+'oof_df.pkl')\n","        \n","    if CFG.wandb:\n","        wandb.finish()\n","\n","\n","\n","\n","    # Push to LINE\n","    import requests\n","\n","    def send_line_notification(message):\n","        import json\n","        f = open(\"../../line.json\", \"r\")\n","        json_data = json.load(f)\n","        line_token = json_data[\"kagglePush\"]\n","        endpoint = 'https://notify-api.line.me/api/notify'\n","        message = \"\\n{}\".format(message)\n","        payload = {'message': message}\n","        headers = {'Authorization': 'Bearer {}'.format(line_token)}\n","        requests.post(endpoint, data=payload, headers=headers)\n","\n","    if CFG.wandb:\n","        send_line_notification(f\"Training of {CFG.wandbproject+'/'+CFG.wandbgroup+'/'+CFG.wandbname} has been done. See {run.url}\")\n","    else:\n","        send_line_notification(f\"Training of {CFG.wandbproject+'/'+CFG.wandbgroup+'/'+CFG.wandbname} has been done.\")"]}],"metadata":{"accelerator":"GPU","colab":{"background_execution":"on","collapsed_sections":[],"machine_shape":"hm","name":"nb005t-deberta-v3-large.ipynb","toc_visible":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"},"widgets":{"application/vnd.jupyter.widget-state+json":{"0664323959e74973a71bd4e5c6a7b9bf":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_31842e9cd1f94c4399eb2b82965f5816","max":136,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7a1a618887b493583968a8fce9999ce","value":136}},"1461270e1a8d4b6db15e16b8612f5a15":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38fb69f67e494ffcb1ed2ece66bddd90","placeholder":"​","style":"IPY_MODEL_87cb45a776e44ae4beff93b4c2b44a6c","value":" 136/136 [00:00&lt;00:00, 2314.93it/s]"}},"14757135308f4a239f0f327aeb059b3e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_159532d942514366a5833ec0983e2ab9","placeholder":"​","style":"IPY_MODEL_748958d52d60497e9274b0b8a79ac845","value":" 36473/36473 [00:02&lt;00:00, 12444.04it/s]"}},"159532d942514366a5833ec0983e2ab9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c9c568a17334463bfb60d6086954bce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ad0cd49a0c24ed1a4e1c3c538e767ef","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_381ad162b8b646629146d2e31f5d8690","value":36473}},"207b385d10584c718a4f24784c3f6ce3":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"244d8ae2eb7e43b4afe0508aaebfb97c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c91fe2daf6544ccfba05ab04421af028","max":36473,"min":0,"orientation":"horizontal","style":"IPY_MODEL_872654c1df654364b00ea58baa41dd48","value":36473}},"2b9b22c5fbe946d19b10d499a679d06a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31842e9cd1f94c4399eb2b82965f5816":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"381ad162b8b646629146d2e31f5d8690":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"38fb69f67e494ffcb1ed2ece66bddd90":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"39c8e741c9b34af28b7ecca908259684":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"436c77c6f8a74ec486d3732758f8e681":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8d2af96c01bc44edb9922bd8b57c5963","placeholder":"​","style":"IPY_MODEL_39c8e741c9b34af28b7ecca908259684","value":" 36473/36473 [00:03&lt;00:00, 12304.80it/s]"}},"462ece558d6d4f7b936c34ee8c2f771a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59e0b0e4c5fe4535ac52697054b721d5":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ae700b4aafa4e6dafd1022b7c8fb623":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f349d1148fe4f32ab2bacfce00b678f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"684d6b654b0447f182764ae68a1eaa83":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fc83c5657bac4bae8fd8b244ffc1494e","IPY_MODEL_1c9c568a17334463bfb60d6086954bce","IPY_MODEL_436c77c6f8a74ec486d3732758f8e681"],"layout":"IPY_MODEL_462ece558d6d4f7b936c34ee8c2f771a"}},"6cb99871c12c423c9eb64891d426da63":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"748958d52d60497e9274b0b8a79ac845":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ad0cd49a0c24ed1a4e1c3c538e767ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"82b8b44806f94c5cab21b1b4e47f9b3f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cb99871c12c423c9eb64891d426da63","placeholder":"​","style":"IPY_MODEL_59e0b0e4c5fe4535ac52697054b721d5","value":"100%"}},"8612b69581f34e2ca6ba153fc344cf4c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"872654c1df654364b00ea58baa41dd48":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"87cb45a776e44ae4beff93b4c2b44a6c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d2af96c01bc44edb9922bd8b57c5963":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c3a7072463804d449dd65c10f8c38471":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4c02f2f68c64eaaa86d47c76a998923","IPY_MODEL_0664323959e74973a71bd4e5c6a7b9bf","IPY_MODEL_1461270e1a8d4b6db15e16b8612f5a15"],"layout":"IPY_MODEL_5ae700b4aafa4e6dafd1022b7c8fb623"}},"c7a1a618887b493583968a8fce9999ce":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c91fe2daf6544ccfba05ab04421af028":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4c02f2f68c64eaaa86d47c76a998923":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8612b69581f34e2ca6ba153fc344cf4c","placeholder":"​","style":"IPY_MODEL_e9baca19c0264328ba72115ff8febe6f","value":"100%"}},"e56743c49fda4275ab5a671d99b5baea":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_82b8b44806f94c5cab21b1b4e47f9b3f","IPY_MODEL_244d8ae2eb7e43b4afe0508aaebfb97c","IPY_MODEL_14757135308f4a239f0f327aeb059b3e"],"layout":"IPY_MODEL_2b9b22c5fbe946d19b10d499a679d06a"}},"e9baca19c0264328ba72115ff8febe6f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fc83c5657bac4bae8fd8b244ffc1494e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_207b385d10584c718a4f24784c3f6ce3","placeholder":"​","style":"IPY_MODEL_5f349d1148fe4f32ab2bacfce00b678f","value":"100%"}}}}},"nbformat":4,"nbformat_minor":0}